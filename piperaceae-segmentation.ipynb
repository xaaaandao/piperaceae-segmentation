{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import keras.preprocessing.image\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import skimage.morphology\n",
    "import skimage.io\n",
    "import sklearn\n",
    "import sklearn.model_selection  \n",
    "import sklearn.utils\n",
    "import tensorflow\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mask = \"mask\"\n",
    "path_images = \"images\"\n",
    "image_size = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import shutil\n",
    "\n",
    "with open(\"a.txt\") as arquivo:\n",
    "    todas_linhas = arquivo.readlines()\n",
    "    arquivo.close()\n",
    "\n",
    "dir_original = \"images_original\"\n",
    "dir_unet = \"images_unet\"\n",
    "for l in todas_linhas:\n",
    "    l = l.split(\"->\")\n",
    "    origem = l[0]\n",
    "    origem = origem.replace(\"-original.png\", \"-crop-img-masked-original.png\").replace(\"\\n\", \"\")\n",
    "    nome = l[1].split(\"/\")\n",
    "    nome = nome[len(nome)-1]\n",
    "    nome = nome.replace(\".jpeg\", \".png\").replace(\".jpg\", \".png\").replace(\"\\n\", \"\")\n",
    "    # print(origem, f\"images_original/{nome}\")\n",
    "    shutil.copy(origem, f\"images_original/{nome}\")\n",
    "    shutil.copy(origem.replace(\"-original\", \"\"), f\"images_unet/{nome}\")\n",
    "    origem = l[0]\n",
    "    origem = origem.replace(\"-original.png\", \"-mask-unet.png\").replace(\"\\n\", \"\")\n",
    "    # nome = nome[len(nome)-1]\n",
    "    nome = nome.replace(\".png\", \"_mask_unet.png\").replace(\"\\n\", \"\")\n",
    "    print(origem, f\"images_unet/{nome}\")\n",
    "    shutil.copy(origem, f\"images_unet/{nome}\")\n",
    "    # destino = l[1]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "images_unet = \"images_unet\"\n",
    "out = \"unet256\"\n",
    "\n",
    "for arquivo in os.listdir(images_unet):\n",
    "    image = cv2.imread(os.path.join(images_unet, arquivo), cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    cv2.imwrite(os.path.join(out, arquivo), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def get_equivalent():\n",
    "\n",
    "\n",
    "# lista_final = pathlib.Path(\"result/final\").rglob(\"[0-9].*-original.png\")\n",
    "# # print(lista_final.)\n",
    "# for l in lista_final:\n",
    "    # print(l.resolve())\n",
    "    for root, subdirs, files in os.walk(\"result/final\"):\n",
    "        # print(root, subdirs, files)\n",
    "        # list([filter(re.search(), files)])\n",
    "        # print(root, list(filter(re.compile(r'^[0-9]*-original.png$').match, files)))\n",
    "        arq = list(filter(re.compile(r'^[0-9]*-original.png$').match, files))\n",
    "        if len(arq) > 0:\n",
    "            for a in arq:\n",
    "                x.append(os.path.join(root, a))\n",
    "        #  l = list([os.path.join(root, a) for a in arq])\n",
    "\n",
    "    # print(x)        \n",
    "    a = open(\"a.txt\", \"w\")\n",
    "    y = pathlib.Path(\"images\").glob(\"*\")\n",
    "    for i, w in enumerate(y):\n",
    "        for j, u in enumerate(x):\n",
    "            # print(f\"{i}/{j}\")\n",
    "            f = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(w.resolve()))\n",
    "            g = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(u))\n",
    "\n",
    "            comparison = f == g\n",
    "            if comparison.all():\n",
    "                print(f\"{u}->{w.resolve()}\")\n",
    "                a.write(f\"{u}->{w.resolve()}\\n\")\n",
    "\n",
    "    a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AugmentationSequence(tensorflow.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, augmentations):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(numpy.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        aug_x = numpy.zeros(batch_x.shape)\n",
    "        aug_y = numpy.zeros(batch_y.shape)\n",
    "\n",
    "        for idx in range(batch_x.shape[0]):\n",
    "            aug = self.augment(image=batch_x[idx, :, :, :], mask=batch_y[idx, :, :, :])\n",
    "            aug_x[idx, :, :, :] = aug[\"image\"]\n",
    "            aug_y[idx, :, :, :] = aug[\"mask\"]\n",
    "\n",
    "        return aug_x, aug_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, image_size):\n",
    "    return cv2.resize(image, (image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def get_all_images(dir):\n",
    "    return [{\"filename\": file.name, \"file\": cv2.imread(str(file.resolve()), cv2.IMREAD_GRAYSCALE)}\n",
    "            for file in pathlib.Path(dir).rglob(\"*\")]\n",
    "\n",
    "def create_if_not_exists_dir(dir):\n",
    "    if not os.path.isdir(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def only_resize(list_images, output_dir, image_size):\n",
    "    create_if_not_exists_dir(output_dir)\n",
    "    for image in list_images:\n",
    "        cv2.imwrite(os.path.join(output_dir, image[\"filename\"]), resize_image(image[\"file\"], image_size))\n",
    "\n",
    "def resize_all():\n",
    "    for data in [{\"path\": \"new/images\", \"type\": \"images\"}, {\"path\": \"new/mask\", \"type\": \"mask\"}]:\n",
    "            only_resize(get_all_images(data[\"path\"]), data[\"type\"], 400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_mask(filename):\n",
    "    return numpy.float32(skimage.io.imread(filename) / 255)\n",
    "\n",
    "def load_all_masks(path):\n",
    "    return [load_mask(filename) for filename in sorted(pathlib.Path(path).rglob(\"*\"))]\n",
    "\n",
    "def load_image(filename):\n",
    "    return skimage.img_as_float32(skimage.io.imread(filename))\n",
    "\n",
    "def load_all_images(path):\n",
    "    return [load_image(filename) for filename in sorted(pathlib.Path(path).rglob(\"*\"))]\n",
    "\n",
    "def width_height_are_equal_image_size(image, image_size):\n",
    "    return image.shape[0] == image_size and image.shape[1] == image_size\n",
    "\n",
    "def validate_data(path, image_size):\n",
    "    return all(not width_height_are_equal_image_size(skimage.io.imread(filename), image_size) for filename in sorted(pathlib.Path(path).rglob(\"*\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_avx_avx2():\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # INFO messages are not printed\n",
    "\n",
    "def set_gpu():\n",
    "    gpus = tensorflow.config.experimental.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                print(f\"GPU: {gpu.name}\")\n",
    "                tensorflow.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def unet_model(keras=None, img_size=None):\n",
    "\n",
    "    input_img = tensorflow.keras.layers.Input((img_size, img_size, 1), name = \"img\")\n",
    "\n",
    "    # Contract #1\n",
    "    c1 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(input_img)\n",
    "    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tensorflow.keras.layers.Activation(\"relu\")(c1)\n",
    "    c1 = tensorflow.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c1)\n",
    "    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tensorflow.keras.layers.Activation(\"relu\")(c1)\n",
    "    p1 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    # Contract #2\n",
    "    c2 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p1)\n",
    "    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tensorflow.keras.layers.Activation(\"relu\")(c2)\n",
    "    c2 = tensorflow.keras.layers.Dropout(0.2)(c2)\n",
    "    c2 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c2)\n",
    "    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tensorflow.keras.layers.Activation(\"relu\")(c2)\n",
    "    p2 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Contract #3\n",
    "    c3 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p2)\n",
    "    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tensorflow.keras.layers.Activation(\"relu\")(c3)\n",
    "    c3 = tensorflow.keras.layers.Dropout(0.3)(c3)\n",
    "    c3 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c3)\n",
    "    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tensorflow.keras.layers.Activation(\"relu\")(c3)\n",
    "    p3 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Contract #4\n",
    "    c4 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p3)\n",
    "    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tensorflow.keras.layers.Activation(\"relu\")(c4)\n",
    "    c4 = tensorflow.keras.layers.Dropout(0.4)(c4)\n",
    "    c4 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c4)\n",
    "    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tensorflow.keras.layers.Activation(\"relu\")(c4)\n",
    "    p4 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Middle\n",
    "    c5 = tensorflow.keras.layers.Conv2D(256, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p4)\n",
    "    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = tensorflow.keras.layers.Activation(\"relu\")(c5)\n",
    "    c5 = tensorflow.keras.layers.Dropout(0.5)(c5)\n",
    "    c5 = tensorflow.keras.layers.Conv2D(256, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c5)\n",
    "    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = tensorflow.keras.layers.Activation(\"relu\")(c5)\n",
    "\n",
    "    # Expand (upscale) #1\n",
    "    u6 = tensorflow.keras.layers.Conv2DTranspose(128, (3, 3), strides = (2, 2), padding = \"same\")(c5)\n",
    "    u6 = tensorflow.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u6)\n",
    "    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n",
    "    c6 = tensorflow.keras.layers.Activation(\"relu\")(c6)\n",
    "    c6 = tensorflow.keras.layers.Dropout(0.5)(c6)\n",
    "    c6 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c6)\n",
    "    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n",
    "    c6 = tensorflow.keras.layers.Activation(\"relu\")(c6)\n",
    "\n",
    "    # Expand (upscale) #2\n",
    "    u7 = tensorflow.keras.layers.Conv2DTranspose(64, (3, 3), strides = (2, 2), padding = \"same\")(c6)\n",
    "    u7 = tensorflow.keras.layers.concatenate([u7, c3])\n",
    "    c7 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u7)\n",
    "    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n",
    "    c7 = tensorflow.keras.layers.Activation(\"relu\")(c7)\n",
    "    c7 = tensorflow.keras.layers.Dropout(0.5)(c7)\n",
    "    c7 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c7)\n",
    "    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n",
    "    c7 = tensorflow.keras.layers.Activation(\"relu\")(c7)\n",
    "\n",
    "    # Expand (upscale) #3\n",
    "    u8 = tensorflow.keras.layers.Conv2DTranspose(32, (3, 3), strides = (2, 2), padding = \"same\")(c7)\n",
    "    u8 = tensorflow.keras.layers.concatenate([u8, c2])\n",
    "    c8 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u8)\n",
    "    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n",
    "    c8 = tensorflow.keras.layers.Activation(\"relu\")(c8)\n",
    "    c8 = tensorflow.keras.layers.Dropout(0.5)(c8)\n",
    "    c8 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c8)\n",
    "    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n",
    "    c8 = tensorflow.keras.layers.Activation(\"relu\")(c8)\n",
    "\n",
    "    # Expand (upscale) #4\n",
    "    u9 = tensorflow.keras.layers.Conv2DTranspose(16, (3, 3), strides = (2, 2), padding = \"same\")(c8)\n",
    "    u9 = tensorflow.keras.layers.concatenate([u9, c1])\n",
    "    c9 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u9)\n",
    "    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = tensorflow.keras.layers.Activation(\"relu\")(c9)\n",
    "    c9 = tensorflow.keras.layers.Dropout(0.5)(c9)\n",
    "    c9 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c9)\n",
    "    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = tensorflow.keras.layers.Activation(\"relu\")(c9)\n",
    "\n",
    "    output = tensorflow.keras.layers.Conv2D(1, (1, 1), activation = \"sigmoid\")(c9)\n",
    "    model = tensorflow.keras.Model(inputs = [input_img], outputs = [output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance_loss(y_true, y_pred, smooth = 100):\n",
    "    intersection = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true) + tensorflow.keras.backend.abs(y_pred), axis = -1)\n",
    "    jac = (intersection + smooth) / (union - intersection + smooth)\n",
    "    loss = (1 - jac) * smooth\n",
    "    return loss\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    intersection = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true), -1) + tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_pred), -1)\n",
    "    return (2. * intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, mask):\n",
    "    crop_mask = mask > 0\n",
    "    m, n = mask.shape\n",
    "    crop_mask0, crop_mask1 = crop_mask.any(0), crop_mask.any(1)\n",
    "    col_start, col_end = crop_mask0.argmax(), n - crop_mask0[::-1].argmax()\n",
    "    row_start, row_end = crop_mask1.argmax(), m - crop_mask1[::-1].argmax()\n",
    "    return img[row_start:row_end, col_start:col_end], mask[row_start:row_end, col_start:col_end]\n",
    "\n",
    "def process_pred_mask(pred_mask):\n",
    "    open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "    open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "    return skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "\n",
    "def save_image_mask_predmask(filename, image, mask, pred_mask, post_pred_mask, image_original_mask, image_pred_mask):\n",
    "    figure = matplotlib.pyplot.figure(figsize=(15, 10))\n",
    "    figure.add_subplot(2, 3, 1).set_title(\"Original image\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(skimage.img_as_ubyte(image), cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 2).set_title(\"Original mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(skimage.img_as_ubyte(mask), cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 3).set_title(\"Predicted mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(pred_mask, cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 4).set_title(\"Preprocessed mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(post_pred_mask, cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 5).set_title(\"Image original mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(image_original_mask, cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 6).set_title(\"Image pred mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(image_pred_mask, cmap = \"gray\")\n",
    "    figure.savefig(filename)\n",
    "  \n",
    "\n",
    "def save_all_images(X, Y, data_type):\n",
    "    for idx in range(0, X.shape[0]):\n",
    "        test_img = X[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "        test_mask = Y[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "        pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "        image_pred_mask = pred_mask\n",
    "        pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "\n",
    "        open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "        open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "        post_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "        image_out_folder = os.path.join(out_folder, data_type, f\"{idx}\")\n",
    "\n",
    "        # crop_img, crop_mask = crop_image(test_img[0,:,:,0], post_pred_mask) # keep\n",
    "        crop_img_masked = test_img[0,:,:,0] * pred_mask\n",
    "        mask_original = numpy.uint8(test_mask[0,:,:,0] > 0.5)\n",
    "        crop_img_masked_original = test_img[0,:,:,0] * mask_original\n",
    "        crop_img_masked[crop_img_masked == 0] = 1\n",
    "        crop_img_masked_original[crop_img_masked_original == 0] = 1\n",
    "\n",
    "        if not os.path.exists(image_out_folder):\n",
    "            os.makedirs(image_out_folder)\n",
    "\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-original.png\"), skimage.img_as_ubyte(test_img[0,:,:,0]))    \n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-mask-original.png\"), skimage.img_as_ubyte(test_mask[0,:,:,0]))    \n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-mask-unet.png\"), skimage.img_as_ubyte(image_pred_mask))    \n",
    "        # skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-post-pred-mask.png\"), post_pred_mask * 255)    \n",
    "        # skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-crop-img.png\"), skimage.img_as_ubyte(crop_img))\n",
    "        # skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-crop-mask.png\"), crop_mask * 255)    \n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-crop-img-masked.png\"), skimage.img_as_ubyte(crop_img_masked))\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-crop-img-masked-original.png\"), skimage.img_as_ubyte(crop_img_masked_original))    \n",
    "        \n",
    "\n",
    "        save_image_mask_predmask(os.path.join(image_out_folder, f\"{idx}.png\"), test_img[0,:,:,0], test_mask[0,:,:,0], pred_mask, post_pred_mask, crop_img_masked_original, crop_img_masked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if validate_data(path_mask, image_size) and validate_data(path_images, image_size):\n",
    "    raise SystemExit(\"err in input file\")\n",
    "\n",
    "images = load_all_images(path_images)\n",
    "masks = load_all_masks(path_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.datetime.now().strftime('%d-%m-%Y-%H-%M-%S')\n",
    "\n",
    "count_cv = 10\n",
    "sum_iou_train = 0\n",
    "sum_dice_train = 0\n",
    "sum_iou_val = 0\n",
    "sum_dice_val = 0\n",
    "sum_iou_test = 0\n",
    "sum_dice_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(index_cv, X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "    images_test_ids = []\n",
    "\n",
    "    nimages = X_test.shape[0]\n",
    "    for idx in range(nimages):\n",
    "        test_image = X_test[idx,:,:,0]\n",
    "        if any(numpy.array_equal(test_image, x) for x in images):\n",
    "            images_test_ids.append(idx)\n",
    "\n",
    "    learning_rate = 0.05\n",
    "    batch_size = 4\n",
    "    epochs = 200\n",
    "    steps_per_epoch = math.ceil(X_train.shape[0] / batch_size)         \n",
    "\n",
    "    augment = Compose([\n",
    "        HorizontalFlip(),\n",
    "        ShiftScaleRotate(rotate_limit=45, border_mode=cv2.BORDER_CONSTANT),\n",
    "        ElasticTransform(border_mode=cv2.BORDER_CONSTANT),\n",
    "        RandomBrightness(),\n",
    "        RandomContrast(),\n",
    "        RandomGamma()\n",
    "    ])\n",
    "\n",
    "    train_generator = AugmentationSequence(X_train, Y_train, batch_size, augment)   \n",
    "\n",
    "    unet_filename = os.path.join(\"model\", f\"batch{batch_size}+lr{str(learning_rate).replace('.', '_')}+epoch{epochs}+steps{steps_per_epoch}+cv{index_cv}+unet.h5\")\n",
    "\n",
    "    reduce_learning_rate = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor = \"loss\", factor = 0.5, patience = 3, verbose = 1)\n",
    "\n",
    "    checkpointer = tensorflow.keras.callbacks.ModelCheckpoint(unet_filename, verbose = 1, save_best_only = True)\n",
    "\n",
    "    strategy = tensorflow.distribute.MirroredStrategy()\n",
    "\n",
    "    if (os.path.exists(unet_filename)):\n",
    "        model = tensorflow.keras.models.load_model(unet_filename, custom_objects = {\"jaccard_distance_loss\": jaccard_distance_loss,\"dice_coef\": dice_coef})\n",
    "    else:\n",
    "        with strategy.scope():\n",
    "            model = unet_model()\n",
    "            adam_opt = tensorflow.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "            model.compile(optimizer = adam_opt, loss = jaccard_distance_loss, metrics = [dice_coef])\n",
    "        \n",
    "        fit = model.fit(train_generator, \n",
    "            steps_per_epoch = steps_per_epoch, \n",
    "            epochs = epochs,\n",
    "            validation_data = (X_val, Y_val),\n",
    "            callbacks = [checkpointer, reduce_learning_rate]\n",
    "        )\n",
    "    \n",
    "    iou_train, dice_train = model.evaluate(X_train, Y_train, verbose = False)\n",
    "    iou_val, dice_val = model.evaluate(X_val, Y_val, verbose = False)\n",
    "    iou_test, dice_test = model.evaluate(X_test, Y_test, verbose = False)\n",
    "\n",
    "    sum_iou_train += iou_train\n",
    "    sum_dice_train += dice_train\n",
    "    sum_iou_val += iou_val\n",
    "    sum_dice_val += dice_val\n",
    "    sum_iou_test += iou_test\n",
    "    sum_dice_test += dice_val\n",
    "\n",
    "    # print(\"Jaccard distance (IoU) train: %f\" % iou_train)\n",
    "    # print(\"Dice coeffient train: %f\" % dice_train)\n",
    "    # print(\"Jaccard distance (IoU) validation: %f\" % iou_val)\n",
    "    # print(\"Dice coeffient validation: %f\" % dice_val)\n",
    "    # print(\"Jaccard distance (IoU) test: %f\" % iou_test)\n",
    "    # print(\"Dice coeffient test: %f\" % dice_test)\n",
    "\n",
    "    if not os.path.exists(\"result\"):\n",
    "        os.makedirs(\"result\")\n",
    "\n",
    "    out_folder = os.path.join(\"result\", current_datetime, index_cv)\n",
    "\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "    name_outfile = f\"result-{current_datetime}\"\n",
    "    path_outfile = os.path.join(out_folder, name_outfile)\n",
    "\n",
    "    fig = matplotlib.pyplot.figure(constrained_layout=True, figsize=(60, 20))\n",
    "    fig.suptitle(f\"Result {datetime.datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\", fontsize=36, color=\"r\")\n",
    "\n",
    "    subfigs = fig.subfigures(nrows=3, ncols=1)\n",
    "    titles = [\"Original\", \"Mask original\", \"Mask u-net\"]\n",
    "    for i, subfig in enumerate(subfigs):\n",
    "        subfig.suptitle(titles[i], fontsize=28, color=\"r\")\n",
    "\n",
    "        axs = subfig.subplots(nrows=1, ncols=8)\n",
    "        for j, ax in enumerate(axs):\n",
    "            if i == 0:\n",
    "                test_img = X_test[j,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "                ax.imshow(skimage.img_as_ubyte(test_img[0,:,:,0]), cmap = \"gray\")\n",
    "            elif i == 1:\n",
    "                test_mask = Y_test[j,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "                ax.imshow(skimage.img_as_ubyte(test_mask[0,:,:,0]), cmap = \"gray\")\n",
    "            elif i == 2:\n",
    "                test_img = X_test[j,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "                pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "                pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "                ax.imshow(pred_mask, cmap = \"gray\")\n",
    "    fig.savefig(f\"{path_outfile}.png\")\n",
    "\n",
    "    try:\n",
    "        with open(f\"{path_outfile}.txt\", \"w\") as outfile:\n",
    "            outfile.write(f\"unet filename={unet_filename}\\n\")    \n",
    "            outfile.write(f\"index cv={index_cv}\\n\")    \n",
    "            outfile.write(f\"X: {X.shape}, X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\\n\")\n",
    "            outfile.write(f\"learning_rate={learning_rate}, batch_size={batch_size}\\n\")    \n",
    "            outfile.write(f\"epochs={epochs}, steps={steps_per_epoch}\\n\")    \n",
    "            outfile.write(f\"============================================\\n\")    \n",
    "            outfile.write(f\"Jaccard distance (IoU) train: {iou_train}\\n\")\n",
    "            outfile.write(f\"Dice coeffient train: {dice_train}\\n\")\n",
    "            outfile.write(f\"Jaccard distance (IoU) validation: {iou_val}\\n\")\n",
    "            outfile.write(f\"Dice coeffient validation: {dice_val}\\n\")\n",
    "            outfile.write(f\"Jaccard distance (IoU) test: {iou_test}\\n\")\n",
    "            outfile.write(f\"Dice coeffient test: {dice_test}\\n\")\n",
    "            outfile.close()\n",
    "    except:\n",
    "        raise SystemError(f\"fail in create outfile {path_outfile}\")     \n",
    "\n",
    "    save_all_images(X_train, Y_train, \"train\") \n",
    "    save_all_images(X_test, Y_test, \"test\") \n",
    "    save_all_images(X_val, Y_val, \"val\")\n",
    "    print(f\"folder {path_outfile} created\")     \n",
    "    \n",
    "try:\n",
    "    with open(f\"{os.path.join('result', current_datetime)}.txt\", \"w\") as outfile:\n",
    "        outfile.write(f\"Mean Jaccard distance (IoU) train: {sum_iou_train/count_cv}\\n\")\n",
    "        outfile.write(f\"Mean Dice coeffient train: {sum_dice_train/count_cv}\\n\")\n",
    "        outfile.write(f\"Mean Jaccard distance (IoU) validation: {sum_iou_val/count_cv}\\n\")\n",
    "        outfile.write(f\"Mean Dice coeffient validation: {sum_dice_val/count_cv}\\n\")\n",
    "        outfile.write(f\"Mean Jaccard distance (IoU) test: {sum_iou_test/count_cv}\\n\")\n",
    "        outfile.write(f\"Mean Dice coeffient test: {sum_dice_test/count_cv}\\n\")\n",
    "        outfile.close()\n",
    "except:\n",
    "    raise SystemError(f\"fail in create outfile {current_datetime}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Counter({'piper': 75, 'pothomorphe': 75, 'ottonia': 75, 'peperomia': 75, 'manekia': 75})\n",
      "X_train.shape: (270, 400, 400, 1)\n",
      "Y_train.shape: (270, 400, 400, 1)\n",
      "X_val.shape: (30, 400, 400, 1)\n",
      "Y_val.shape: (30, 400, 400, 1)\n",
      "Y_test.shape: (75, 400, 400, 1)\n",
      "X_test.shape: (75, 400, 400, 1)\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xandao/miniconda3/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1613: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/xandao/miniconda3/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1639: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 12:39:15.762484: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_30455\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:66\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_genus(filename):\n",
    "    list_genus = [\"manekia\", \"ottonia\", \"peperomia\", \"piper\", \"pothomorphe\"]\n",
    "    return next((g for g in list_genus if g in filename), ValueError(\"a\"))\n",
    "\n",
    "def get_path_mask(filename):\n",
    "    filename = re.sub(r\".[a-z]*$\", \"\", filename)\n",
    "    list_mask = list([str(file.resolve()) for file in pathlib.Path(path_mask).rglob(\"*\")])\n",
    "    return next((m for m in list_mask if filename in m), ValueError(\"a\"))\n",
    "\n",
    "\n",
    "list_images = list([{\"path_image\": str(file.resolve()), \"path_mask\": get_path_mask(file.name), \"label\": get_genus(str(file.name))} for file in pathlib.Path(path_images).rglob(\"*\")])   \n",
    "indices = sklearn.model_selection.StratifiedShuffleSplit(n_splits=count_cv, test_size=0.2, random_state=1234)\n",
    "\n",
    "\n",
    "\n",
    "X = numpy.array([{\"path_image\": file[\"path_image\"], \"path_mask\": file[\"path_mask\"]} for file in list_images])\n",
    "Y = numpy.array([file[\"label\"] for file in list_images])\n",
    "for i, (train_index, test_index) in enumerate(indices.split(X, Y)):\n",
    "    print(i, Counter(Y))\n",
    "    X_train = numpy.array([load_image(X[i][\"path_image\"]) for i in train_index])\n",
    "    X_train = X_train.reshape(X_train.shape[0], image_size, image_size, 1)\n",
    "    Y_train = numpy.array([load_mask(X[i][\"path_mask\"]) for i in train_index])\n",
    "    Y_train = Y_train.reshape(Y_train.shape[0], image_size, image_size, 1)\n",
    "\n",
    "    X_test = numpy.array([load_image(X[i][\"path_image\"]) for i in test_index])\n",
    "    X_test = X_test.reshape(X_test.shape[0], image_size, image_size, 1)\n",
    "    Y_test = numpy.array([load_mask(X[i][\"path_mask\"]) for i in test_index])\n",
    "    Y_test = Y_test.reshape(Y_test.shape[0], image_size, image_size, 1)\n",
    "\n",
    "    X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(X_train, Y_train, \n",
    "    test_size=0.1, random_state=1234)\n",
    "\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"Y_train.shape: {Y_train.shape}\")\n",
    "    print(f\"X_val.shape: {X_val.shape}\")\n",
    "    print(f\"Y_val.shape: {Y_val.shape}\")\n",
    "    print(f\"Y_test.shape: {Y_test.shape}\")\n",
    "    print(f\"X_test.shape: {X_test.shape}\")\n",
    "    \n",
    "    a(i, X_train, Y_train, X_val, Y_val, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% capture\n",
    "X = numpy.array(images).reshape(len(images), image_size, image_size, 1)\n",
    "Y = numpy.array(masks).reshape(len(masks), image_size, image_size, 1)\n",
    "X, Y = sklearn.utils.shuffle(X, Y, random_state=1234)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.05, random_state=1234)\n",
    "X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(X_train, Y_train, test_size=0.05, random_state=1234)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(f\"images[50].shape: {images[50].shape}\")\n",
    "print(f\"masks[50].shape: {masks[50].shape}\")\n",
    "f = matplotlib.pyplot.figure()\n",
    "f.add_subplot(3, 2, 1)\n",
    "matplotlib.pyplot.imshow(images[50], cmap = \"gray\")\n",
    "f.add_subplot(3, 2, 2)\n",
    "matplotlib.pyplot.imshow(masks[50], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74]\n"
     ]
    }
   ],
   "source": [
    "images_test_ids = []\n",
    "\n",
    "nimages = X_test.shape[0]\n",
    "for idx in range(nimages):\n",
    "\ttest_image = X_test[idx,:,:,0]\n",
    "\tif any(numpy.array_equal(test_image, x) for x in images):\n",
    "\t\timages_test_ids.append(idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "steps_per_epoch = math.ceil(X_train.shape[0] / batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xandao/miniconda3/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1613: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/xandao/miniconda3/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1639: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "augment = Compose([\n",
    "        HorizontalFlip(),\n",
    "        ShiftScaleRotate(rotate_limit=45, border_mode=cv2.BORDER_CONSTANT),\n",
    "        ElasticTransform(border_mode=cv2.BORDER_CONSTANT),\n",
    "        RandomBrightness(),\n",
    "        RandomContrast(),\n",
    "        RandomGamma()\n",
    "    ])\n",
    "\n",
    "train_generator = AugmentationSequence(X_train, Y_train, batch_size, augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "X_aug, Y_aug = train_generator.__getitem__(20)\n",
    "f = matplotlib.pyplot.figure(figsize=(10, 10))\n",
    "f.add_subplot(4, 2, 1)\n",
    "matplotlib.pyplot.imshow(X_aug[0,:,:,0], cmap = \"gray\")\n",
    "f.add_subplot(4, 2, 2)\n",
    "matplotlib.pyplot.imshow(Y_aug[0,:,:,0], cmap = \"gray\")\n",
    "\n",
    "f.add_subplot(4, 2, 3)\n",
    "matplotlib.pyplot.imshow(X_aug[1,:,:,0], cmap = \"gray\")\n",
    "f.add_subplot(4, 2, 4)\n",
    "matplotlib.pyplot.imshow(Y_aug[1,:,:,0], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_filename = os.path.join(\"model\", f\"batch{batch_size}+lr{str(learning_rate).replace('.', '_')}+epoch{epochs}+steps{steps_per_epoch}+unet.h5\")\n",
    "# unet_filename = os.path.join(\"model\", \"batch4+lr0_05+epoch200+steps85+unet.h5\")\n",
    "\n",
    "reduce_learning_rate = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor = \"loss\", factor = 0.5, patience = 3, verbose = 1)\n",
    "\n",
    "checkpointer = tensorflow.keras.callbacks.ModelCheckpoint(unet_filename, verbose = 1, save_best_only = True)\n",
    "\n",
    "strategy = tensorflow.distribute.MirroredStrategy()\n",
    "\n",
    "if (os.path.exists(unet_filename)):\n",
    "\tmodel = tensorflow.keras.models.load_model(unet_filename, custom_objects = {\"jaccard_distance_loss\": jaccard_distance_loss,\"dice_coef\": dice_coef})\n",
    "else:\n",
    "\twith strategy.scope():\n",
    "\t\tmodel = unet_model()\n",
    "\t\tadam_opt = tensorflow.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "\t\tmodel.compile(optimizer = adam_opt, loss = jaccard_distance_loss, metrics = [dice_coef])\n",
    "    \n",
    "\tfit = model.fit(train_generator, \n",
    "\t\tsteps_per_epoch = steps_per_epoch, \n",
    "\t\tepochs = epochs,\n",
    "\t\tvalidation_data = (X_val, Y_val),\n",
    "\t\tcallbacks = [checkpointer, reduce_learning_rate]\n",
    "\t)\n",
    "  \n",
    "iou_train, dice_train = model.evaluate(X_train, Y_train, verbose = False)\n",
    "iou_val, dice_val = model.evaluate(X_val, Y_val, verbose = False)\n",
    "iou_test, dice_test = model.evaluate(X_test, Y_test, verbose = False)\n",
    "\n",
    "print(\"Jaccard distance (IoU) train: %f\" % iou_train)\n",
    "print(\"Dice coeffient train: %f\" % dice_train)\n",
    "print(\"Jaccard distance (IoU) validation: %f\" % iou_val)\n",
    "print(\"Dice coeffient validation: %f\" % dice_val)\n",
    "print(\"Jaccard distance (IoU) test: %f\" % iou_test)\n",
    "print(\"Dice coeffient test: %f\" % dice_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "idx = 15\n",
    "test_img = X_test[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "test_mask = Y_test[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "post_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "\n",
    "crop_img, crop_mask = crop_image(test_img[0,:,:,0], post_pred_mask)\n",
    "\n",
    "crop_img_masked = crop_img * crop_mask\n",
    "\n",
    "# row, column\n",
    "f = matplotlib.pyplot.figure(figsize=(10, 10))\n",
    "f.add_subplot(2, 2, 1)\n",
    "matplotlib.pyplot.imshow(skimage.img_as_ubyte(test_img[0,:,:,0]), cmap = \"gray\")\n",
    "f.add_subplot(2, 2, 2)\n",
    "matplotlib.pyplot.imshow(post_pred_mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"result\"):\n",
    "    os.makedirs(\"result\")\n",
    "\n",
    "current_datetime = datetime.datetime.now().strftime('%d-%m-%Y-%H-%M-%S')\n",
    "out_folder = os.path.join(\"result\", current_datetime)\n",
    "\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "\n",
    "name_outfile = f\"result-{current_datetime}\"\n",
    "path_outfile = os.path.join(out_folder, name_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outfile path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure with eight test images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = matplotlib.pyplot.figure(constrained_layout=True, figsize=(60, 20))\n",
    "fig.suptitle(f\"Result {datetime.datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\", fontsize=36, color=\"r\")\n",
    "\n",
    "subfigs = fig.subfigures(nrows=3, ncols=1)\n",
    "titles = [\"Original\", \"Mask original\", \"Mask u-net\"]\n",
    "for i, subfig in enumerate(subfigs):\n",
    "    subfig.suptitle(titles[i], fontsize=28, color=\"r\")\n",
    "\n",
    "    axs = subfig.subplots(nrows=1, ncols=8)\n",
    "    for j, ax in enumerate(axs):\n",
    "        if i == 0:\n",
    "            test_img = X_test[j,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "            ax.imshow(skimage.img_as_ubyte(test_img[0,:,:,0]), cmap = \"gray\")\n",
    "        elif i == 1:\n",
    "            test_mask = Y_test[j,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "            ax.imshow(skimage.img_as_ubyte(test_mask[0,:,:,0]), cmap = \"gray\")\n",
    "        elif i == 2:\n",
    "            test_img = X_test[j,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "            pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "            pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "            ax.imshow(pred_mask, cmap = \"gray\")\n",
    "fig.savefig(f\"{path_outfile}.png\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(f\"{path_outfile}.txt\", \"w\") as outfile:\n",
    "        outfile.write(f\"unet filename={unet_filename}\\n\")    \n",
    "        outfile.write(f\"X: {X.shape}, X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\\n\")\n",
    "        outfile.write(f\"learning_rate={learning_rate}, batch_size={batch_size}\\n\")    \n",
    "        outfile.write(f\"epochs={epochs}, steps={steps_per_epoch}\\n\")    \n",
    "        outfile.write(f\"============================================\\n\")    \n",
    "        outfile.write(f\"Jaccard distance (IoU) train: {iou_train}\\n\")\n",
    "        outfile.write(f\"Dice coeffient train: {dice_train}\\n\")\n",
    "        outfile.write(f\"Jaccard distance (IoU) validation: {iou_val}\\n\")\n",
    "        outfile.write(f\"Dice coeffient validation: {dice_val}\\n\")\n",
    "        outfile.write(f\"Jaccard distance (IoU) test: {iou_test}\\n\")\n",
    "        outfile.write(f\"Dice coeffient test: {dice_test}\\n\")\n",
    "        outfile.close()\n",
    "except:\n",
    "    raise SystemError(f\"fail in create outfile {path_outfile}\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate mask of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_images(X_train, Y_train, \"train\") \n",
    "save_all_images(X_test, Y_test, \"test\") \n",
    "save_all_images(X_val, Y_val, \"val\")\n",
    "print(f\"folder {path_outfile} created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "53ce972a288a646521e393254486dd3d4e40ae124f0f9a66da52dff344d61cdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
