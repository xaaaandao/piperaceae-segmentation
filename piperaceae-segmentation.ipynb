{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import os\n",
    "import pathlib\n",
    "import PIL\n",
    "import skimage.morphology\n",
    "import skimage.io\n",
    "import sklearn\n",
    "import sklearn.model_selection  \n",
    "import sklearn.utils\n",
    "import tensorflow\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma\n",
    ")\n",
    "from keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AugmentationSequence(tensorflow.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, augmentations):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(numpy.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        aug_x = numpy.zeros(batch_x.shape)\n",
    "        aug_y = numpy.zeros(batch_y.shape)\n",
    "\n",
    "        for idx in range(batch_x.shape[0]):\n",
    "            aug = self.augment(image=batch_x[idx, :, :, :], mask=batch_y[idx, :, :, :])\n",
    "            aug_x[idx, :, :, :] = aug[\"image\"]\n",
    "            aug_y[idx, :, :, :] = aug[\"mask\"]\n",
    "\n",
    "        return aug_x, aug_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, image_size):\n",
    "    return cv2.resize(image, (image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def return_all_images(dir):\n",
    "    return [{\"filename\": file.name, \"file\": cv2.imread(str(file.resolve()), cv2.IMREAD_GRAYSCALE)}\n",
    "            for file in pathlib.Path(dir).rglob(\"*\")]\n",
    "\n",
    "\n",
    "def create_if_not_exists_dir(dir):\n",
    "    if not os.path.isdir(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def only_resize(list_images, output_dir, image_size):\n",
    "    create_if_not_exists_dir(output_dir)\n",
    "    for image in list_images:\n",
    "        cv2.imwrite(os.path.join(output_dir, image[\"filename\"]), resize_image(image[\"file\"], image_size))\n",
    "\n",
    "def resize_all():\n",
    "    list_images = return_all_images(\"new/images\")\n",
    "    list_mask = return_all_images(\"new/mask\")\n",
    "    only_resize(list_images, \"images\", 400)\n",
    "    only_resize(list_mask, \"mask\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_mask(filename):\n",
    "    return numpy.float32(skimage.io.imread(filename) / 255)\n",
    "\n",
    "def load_all_masks(path):\n",
    "    return [load_mask(filename) for filename in sorted(pathlib.Path(path).rglob(\"*\"))]\n",
    "\n",
    "def load_image(filename):\n",
    "    return skimage.img_as_float32(skimage.io.imread(filename))\n",
    "\n",
    "def load_all_images(path):\n",
    "    return [load_image(filename) for filename in sorted(pathlib.Path(path).rglob(\"*\"))]\n",
    "\n",
    "def width_height_are_equal_image_size(image, image_size):\n",
    "    return image.shape[0] == image_size and image.shape[1] == image_size\n",
    "\n",
    "def validate_data(path, image_size):\n",
    "    return all(not width_height_are_equal_image_size(skimage.io.imread(filename), image_size) for filename in sorted(pathlib.Path(path).rglob(\"*\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function of GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_avx_avx2():\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # INFO messages are not printed\n",
    "\n",
    "def set_gpu():\n",
    "    gpus = tensorflow.config.experimental.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                print(f\"GPU: {gpu.name}\")\n",
    "                tensorflow.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def unet_model(keras=None, img_size=None):\n",
    "\n",
    "    input_img = tensorflow.keras.layers.Input((img_size, img_size, 1), name = \"img\")\n",
    "\n",
    "    # Contract #1\n",
    "    c1 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(input_img)\n",
    "    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tensorflow.keras.layers.Activation(\"relu\")(c1)\n",
    "    c1 = tensorflow.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c1)\n",
    "    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tensorflow.keras.layers.Activation(\"relu\")(c1)\n",
    "    p1 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    # Contract #2\n",
    "    c2 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p1)\n",
    "    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tensorflow.keras.layers.Activation(\"relu\")(c2)\n",
    "    c2 = tensorflow.keras.layers.Dropout(0.2)(c2)\n",
    "    c2 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c2)\n",
    "    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tensorflow.keras.layers.Activation(\"relu\")(c2)\n",
    "    p2 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Contract #3\n",
    "    c3 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p2)\n",
    "    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tensorflow.keras.layers.Activation(\"relu\")(c3)\n",
    "    c3 = tensorflow.keras.layers.Dropout(0.3)(c3)\n",
    "    c3 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c3)\n",
    "    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tensorflow.keras.layers.Activation(\"relu\")(c3)\n",
    "    p3 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Contract #4\n",
    "    c4 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p3)\n",
    "    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tensorflow.keras.layers.Activation(\"relu\")(c4)\n",
    "    c4 = tensorflow.keras.layers.Dropout(0.4)(c4)\n",
    "    c4 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c4)\n",
    "    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tensorflow.keras.layers.Activation(\"relu\")(c4)\n",
    "    p4 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Middle\n",
    "    c5 = tensorflow.keras.layers.Conv2D(256, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p4)\n",
    "    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = tensorflow.keras.layers.Activation(\"relu\")(c5)\n",
    "    c5 = tensorflow.keras.layers.Dropout(0.5)(c5)\n",
    "    c5 = tensorflow.keras.layers.Conv2D(256, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c5)\n",
    "    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = tensorflow.keras.layers.Activation(\"relu\")(c5)\n",
    "\n",
    "    # Expand (upscale) #1\n",
    "    u6 = tensorflow.keras.layers.Conv2DTranspose(128, (3, 3), strides = (2, 2), padding = \"same\")(c5)\n",
    "    u6 = tensorflow.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u6)\n",
    "    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n",
    "    c6 = tensorflow.keras.layers.Activation(\"relu\")(c6)\n",
    "    c6 = tensorflow.keras.layers.Dropout(0.5)(c6)\n",
    "    c6 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c6)\n",
    "    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n",
    "    c6 = tensorflow.keras.layers.Activation(\"relu\")(c6)\n",
    "\n",
    "    # Expand (upscale) #2\n",
    "    u7 = tensorflow.keras.layers.Conv2DTranspose(64, (3, 3), strides = (2, 2), padding = \"same\")(c6)\n",
    "    u7 = tensorflow.keras.layers.concatenate([u7, c3])\n",
    "    c7 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u7)\n",
    "    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n",
    "    c7 = tensorflow.keras.layers.Activation(\"relu\")(c7)\n",
    "    c7 = tensorflow.keras.layers.Dropout(0.5)(c7)\n",
    "    c7 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c7)\n",
    "    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n",
    "    c7 = tensorflow.keras.layers.Activation(\"relu\")(c7)\n",
    "\n",
    "    # Expand (upscale) #3\n",
    "    u8 = tensorflow.keras.layers.Conv2DTranspose(32, (3, 3), strides = (2, 2), padding = \"same\")(c7)\n",
    "    u8 = tensorflow.keras.layers.concatenate([u8, c2])\n",
    "    c8 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u8)\n",
    "    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n",
    "    c8 = tensorflow.keras.layers.Activation(\"relu\")(c8)\n",
    "    c8 = tensorflow.keras.layers.Dropout(0.5)(c8)\n",
    "    c8 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c8)\n",
    "    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n",
    "    c8 = tensorflow.keras.layers.Activation(\"relu\")(c8)\n",
    "\n",
    "    # Expand (upscale) #4\n",
    "    u9 = tensorflow.keras.layers.Conv2DTranspose(16, (3, 3), strides = (2, 2), padding = \"same\")(c8)\n",
    "    u9 = tensorflow.keras.layers.concatenate([u9, c1])\n",
    "    c9 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u9)\n",
    "    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = tensorflow.keras.layers.Activation(\"relu\")(c9)\n",
    "    c9 = tensorflow.keras.layers.Dropout(0.5)(c9)\n",
    "    c9 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c9)\n",
    "    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = tensorflow.keras.layers.Activation(\"relu\")(c9)\n",
    "\n",
    "    output = tensorflow.keras.layers.Conv2D(1, (1, 1), activation = \"sigmoid\")(c9)\n",
    "    model = tensorflow.keras.Model(inputs = [input_img], outputs = [output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance_loss(y_true, y_pred, smooth = 100):\n",
    "    intersection = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true) + tensorflow.keras.backend.abs(y_pred), axis = -1)\n",
    "    jac = (intersection + smooth) / (union - intersection + smooth)\n",
    "    loss = (1 - jac) * smooth\n",
    "    return loss\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    intersection = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true), -1) + tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_pred), -1)\n",
    "    return (2. * intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, mask):\n",
    "  crop_mask = mask > 0\n",
    "  m, n = mask.shape\n",
    "  crop_mask0, crop_mask1 = crop_mask.any(0), crop_mask.any(1)\n",
    "  col_start, col_end = crop_mask0.argmax(), n - crop_mask0[::-1].argmax()\n",
    "  row_start, row_end = crop_mask1.argmax(), m - crop_mask1[::-1].argmax()\n",
    "  return img[row_start:row_end, col_start:col_end], mask[row_start:row_end, col_start:col_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pred_mask(pred_mask):\n",
    "    pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "    open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "    open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "    return skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "\n",
    "def save_image_mask_predmask(filename, image, mask, pred_mask, post_pred_mask):\n",
    "    figure = matplotlib.pyplot.figure(figsize=(30, 10))\n",
    "    figure.add_subplot(1, 4, 1)\n",
    "    matplotlib.pyplot.imshow(skimage.img_as_ubyte(image), cmap = \"gray\")\n",
    "    figure.add_subplot(1, 4, 2)\n",
    "    matplotlib.pyplot.imshow(skimage.img_as_ubyte(mask), cmap = \"gray\")\n",
    "    figure.add_subplot(1, 4, 3)\n",
    "    matplotlib.pyplot.imshow(pred_mask, cmap = \"gray\")\n",
    "    figure.add_subplot(1, 4, 4)\n",
    "    matplotlib.pyplot.imshow(post_pred_mask, cmap = \"gray\")\n",
    "    figure.savefig(os.path.join(filename, f\"{i}.png\"))\n",
    "\n",
    "def save_image_postpredmask(filename, post_pred_mask):\n",
    "    image_with_channel_color = numpy.expand_dims(post_pred_mask, axis=2)\n",
    "    image = array_to_img(image_with_channel_color)\n",
    "    image.save(filename)\n",
    "\n",
    "def save_mask(filename, image):\n",
    "    skimage.io.imsave(filename, image)    \n",
    "\n",
    "def save_all_images(X, Y, data_type):\n",
    "    for i in range(0, X.shape[0]):\n",
    "        image = X[i,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "        mask = Y[i,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "        pred_mask = model.predict(image)[0,:,:,0]\n",
    "        post_pred_mask = process_pred_mask(pred_mask)\n",
    "\n",
    "        image_out_folder = os.path.join(out_folder, data_type, f\"{i}\")\n",
    "\n",
    "        if not os.path.exists(image_out_folder):\n",
    "            os.makedirs(image_out_folder)\n",
    "\n",
    "        save_mask(os.path.join(image_out_folder, f\"{i}-original.png\"), skimage.img_as_ubyte(image[0,:,:,0]))    \n",
    "        save_mask(os.path.join(image_out_folder, f\"{i}-mask.png\"), skimage.img_as_ubyte(mask[0,:,:,0]))    \n",
    "        save_mask(os.path.join(image_out_folder, f\"{i}-pred-mask.png\"), skimage.img_as_ubyte(pred_mask))\n",
    "        save_image_postpredmask(os.path.join(image_out_folder, f\"{i}post-pred-mask.png\"), post_pred_mask)\n",
    "\n",
    "\n",
    "        save_image_mask_predmask(image_out_folder, image[0,:,:,0], mask[0,:,:,0], pred_mask, post_pred_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_mask = \"mask\"\n",
    "path_images = \"images\"\n",
    "image_size = 400\n",
    "\n",
    "if validate_data(path_mask, image_size) and validate_data(path_images, image_size):\n",
    "    raise SystemExit(\"err in input file\")\n",
    "\n",
    "images = load_all_images(path_images)\n",
    "masks = load_all_masks(path_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.array(images).reshape(len(images), image_size, image_size, 1)\n",
    "Y = numpy.array(masks).reshape(len(masks), image_size, image_size, 1)\n",
    "X, Y = sklearn.utils.shuffle(X, Y, random_state=1234)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.05, random_state=1234)\n",
    "X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(X_train, Y_train, test_size=0.05, random_state=1234)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"images[50].shape: {images[50].shape}\")\n",
    "print(f\"masks[50].shape: {masks[50].shape}\")\n",
    "f = matplotlib.pyplot.figure()\n",
    "f.add_subplot(3, 2, 1)\n",
    "matplotlib.pyplot.imshow(images[50], cmap = \"gray\")\n",
    "f.add_subplot(3, 2, 2)\n",
    "matplotlib.pyplot.imshow(masks[50], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test_ids = []\n",
    "\n",
    "nimages = X_test.shape[0]\n",
    "for idx in range(nimages):\n",
    "\ttest_image = X_test[idx,:,:,0]\n",
    "\tif any(numpy.array_equal(test_image, x) for x in images):\n",
    "\t\timages_test_ids.append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "steps_per_epoch = math.ceil(X_train.shape[0] / batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = Compose([\n",
    "        HorizontalFlip(),\n",
    "        ShiftScaleRotate(rotate_limit=45, border_mode=cv2.BORDER_CONSTANT),\n",
    "        ElasticTransform(border_mode=cv2.BORDER_CONSTANT),\n",
    "        RandomBrightness(),\n",
    "        RandomContrast(),\n",
    "        RandomGamma()\n",
    "    ])\n",
    "\n",
    "train_generator = AugmentationSequence(X_train, Y_train, batch_size, augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug, Y_aug = train_generator.__getitem__(20)\n",
    "f = matplotlib.pyplot.figure()\n",
    "f.add_subplot(4, 2, 1)\n",
    "matplotlib.pyplot.imshow(X_aug[0,:,:,0], cmap = \"gray\")\n",
    "f.add_subplot(4, 2, 2)\n",
    "matplotlib.pyplot.imshow(Y_aug[0,:,:,0], cmap = \"gray\")\n",
    "\n",
    "f.add_subplot(4, 2, 3)\n",
    "matplotlib.pyplot.imshow(X_aug[1,:,:,0], cmap = \"gray\")\n",
    "f.add_subplot(4, 2, 4)\n",
    "matplotlib.pyplot.imshow(Y_aug[1,:,:,0], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_filename = os.path.join(\"model\", f\"batch{batch_size}+lr{str(learning_rate).replace('.', '_')}+epoch{epochs}+steps{steps_per_epoch}+unet.h5\")\n",
    "\n",
    "reduce_learning_rate = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor = \"loss\", factor = 0.5, patience = 3, verbose = 1)\n",
    "\n",
    "checkpointer = tensorflow.keras.callbacks.ModelCheckpoint(unet_filename, verbose = 1, save_best_only = True)\n",
    "\n",
    "strategy = tensorflow.distribute.MirroredStrategy()\n",
    "\n",
    "if (os.path.exists(unet_filename)):\n",
    "\tmodel = tensorflow.keras.models.load_model(unet_filename, custom_objects = {\"jaccard_distance_loss\": jaccard_distance_loss,\"dice_coef\": dice_coef})\n",
    "else:\n",
    "\twith strategy.scope():\n",
    "\t\tmodel = unet_model()\n",
    "\t\tadam_opt = tensorflow.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "\t\tmodel.compile(optimizer = adam_opt, loss = jaccard_distance_loss, metrics = [dice_coef])\n",
    "    \n",
    "\tfit = model.fit(train_generator, \n",
    "\t\tsteps_per_epoch = steps_per_epoch, \n",
    "\t\tepochs = epochs,\n",
    "\t\tvalidation_data = (X_val, Y_val),\n",
    "\t\tcallbacks = [checkpointer, reduce_learning_rate]\n",
    "\t)\n",
    "  \n",
    "iou_train, dice_train = model.evaluate(X_train, Y_train, verbose = False)\n",
    "iou_val, dice_val = model.evaluate(X_val, Y_val, verbose = False)\n",
    "iou_test, dice_test = model.evaluate(X_test, Y_test, verbose = False)\n",
    "\n",
    "print(\"Jaccard distance (IoU) train: %f\" % iou_train)\n",
    "print(\"Dice coeffient train: %f\" % dice_train)\n",
    "print(\"Jaccard distance (IoU) validation: %f\" % iou_val)\n",
    "print(\"Dice coeffient validation: %f\" % dice_val)\n",
    "print(\"Jaccard distance (IoU) test: %f\" % iou_test)\n",
    "print(\"Dice coeffient test: %f\" % dice_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 15\n",
    "test_img = X_test[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "test_mask = Y_test[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "post_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "\n",
    "crop_img, crop_mask = crop_image(test_img[0,:,:,0], post_pred_mask)\n",
    "\n",
    "crop_img_masked = crop_img * crop_mask\n",
    "\n",
    "# row, column\n",
    "f = matplotlib.pyplot.figure(figsize=(10, 10))\n",
    "f.add_subplot(2, 2, 1)\n",
    "matplotlib.pyplot.imshow(skimage.img_as_ubyte(test_img[0,:,:,0]), cmap = \"gray\")\n",
    "f.add_subplot(2, 2, 2)\n",
    "matplotlib.pyplot.imshow(post_pred_mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"result\"):\n",
    "    os.makedirs(\"result\")\n",
    "\n",
    "current_datetime = datetime.datetime.now().strftime('%d-%m-%Y-%H-%M-%S')\n",
    "out_folder = os.path.join(\"result\", current_datetime)\n",
    "\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)\n",
    "\n",
    "name_outfile = f\"result-{current_datetime}\"\n",
    "path_outfile = os.path.join(out_folder, name_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outfile path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure with eight test images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = matplotlib.pyplot.figure(constrained_layout=True, figsize=(60, 20))\n",
    "fig.suptitle(f\"Result {datetime.datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\", fontsize=36, color=\"r\")\n",
    "\n",
    "subfigs = fig.subfigures(nrows=3, ncols=1)\n",
    "titles =  [\"Original\", \"Mask original\", \"Mask u-net\"]\n",
    "for i, subfig in enumerate(subfigs):\n",
    "    subfig.suptitle(titles[i], fontsize=28, color=\"r\")\n",
    "\n",
    "    axs = subfig.subplots(nrows=1, ncols=8)\n",
    "    for j, ax in enumerate(axs):\n",
    "        if i == 0:\n",
    "            test_img = X_test[j,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "            ax.imshow(skimage.img_as_ubyte(test_img[0,:,:,0]), cmap = \"gray\")\n",
    "        elif i == 1:\n",
    "            test_mask = Y_test[j,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "            ax.imshow(skimage.img_as_ubyte(test_mask[0,:,:,0]), cmap = \"gray\")\n",
    "        elif i == 2:\n",
    "            test_img = X_test[j,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "            pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "            pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "            ax.imshow(pred_mask, cmap = \"gray\")\n",
    "fig.savefig(f\"{path_outfile}.png\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(f\"{path_outfile}.txt\", \"w\") as outfile:\n",
    "        outfile.write(f\"unet filename={unet_filename}\\n\")    \n",
    "        outfile.write(f\"X: {X.shape}, X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\\n\")\n",
    "        outfile.write(f\"learning_rate={learning_rate}, batch_size={batch_size}\\n\")    \n",
    "        outfile.write(f\"epochs={epochs}, steps={steps_per_epoch}\\n\")    \n",
    "        outfile.write(f\"============================================\\n\")    \n",
    "        outfile.write(f\"Jaccard distance (IoU) train: {iou_train}\\n\")\n",
    "        outfile.write(f\"Dice coeffient train: {dice_train}\\n\")\n",
    "        outfile.write(f\"Jaccard distance (IoU) validation: {iou_val}\\n\")\n",
    "        outfile.write(f\"Dice coeffient validation: {dice_val}\\n\")\n",
    "        outfile.write(f\"Jaccard distance (IoU) test: {iou_test}\\n\")\n",
    "        outfile.write(f\"Dice coeffient test: {dice_test}\\n\")\n",
    "        outfile.close()\n",
    "except:\n",
    "    raise SystemError(f\"fail in create outfile {path_outfile}\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate mask of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_images(X_test, Y_test, \"test\") \n",
    "save_all_images(X_val, Y_val, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, X_test.shape[0]):\n",
    "    test_img = X_test[i,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "    test_mask = Y_test[i,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "    pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "    image_pred_mask = pred_mask\n",
    "    pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "    open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "    open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "    post_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "    image_out_folder = os.path.join(out_folder, \"test\", f\"{i}\")\n",
    "\n",
    "    if not os.path.exists(image_out_folder):\n",
    "        os.makedirs(image_out_folder)\n",
    "\n",
    "    skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-original.png\"), skimage.img_as_ubyte(test_img[0,:,:,0]))    \n",
    "    skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-mask-original.png\"), skimage.img_as_ubyte(test_mask[0,:,:,0]))    \n",
    "    skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-mask-unet.png\"), skimage.img_as_ubyte(image_pred_mask))    \n",
    "\n",
    "    f = matplotlib.pyplot.figure(figsize=(30, 10))\n",
    "    f.add_subplot(1, 3, 1)\n",
    "    matplotlib.pyplot.imshow(skimage.img_as_ubyte(test_img[0,:,:,0]), cmap = \"gray\")\n",
    "    f.add_subplot(1, 3, 2)\n",
    "    matplotlib.pyplot.imshow(skimage.img_as_ubyte(test_mask[0,:,:,0]), cmap = \"gray\")\n",
    "    f.add_subplot(1, 3, 3)\n",
    "    matplotlib.pyplot.imshow(post_pred_mask, cmap = \"gray\")\n",
    "    f.savefig(os.path.join(image_out_folder, f\"{i}.png\"))\n",
    "\n",
    "\n",
    "# for i in X_val.shape[0]:\n",
    "#     val_img = X_val[i,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "#     val_mask = Y_val[i,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "#     pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "#     pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "#     open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "#     open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "#     post_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "53ce972a288a646521e393254486dd3d4e40ae124f0f9a66da52dff344d61cdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
