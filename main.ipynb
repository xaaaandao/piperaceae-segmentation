{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import collections\n",
    "import datetime\n",
    "import keras.backend\n",
    "import keras.preprocessing.image\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import re\n",
    "import skimage.morphology\n",
    "import skimage.io\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.utils\n",
    "import tensorflow\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "outputs": [],
   "source": [
    "def create_if_not_exists_dir(dir):\n",
    "    if not os.path.isdir(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "dir_base = \"/home/xandao/herbario/code/piperaceae-segmentation\"\n",
    "current_datetime = datetime.datetime.now().strftime('%d-%m-%Y-%H-%M-%S')\n",
    "path_model = os.path.join(dir_base, \"model\")\n",
    "path_result = os.path.join(dir_base, \"result\")\n",
    "path_out = os.path.join(path_result, current_datetime)\n",
    "path_images = os.path.join(dir_base, \"images\")\n",
    "path_mask = os.path.join(dir_base, \"mask\")\n",
    "\n",
    "for path in [path_model, path_result, path_out, path_images, path_mask]:\n",
    "    create_if_not_exists_dir(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "outputs": [],
   "source": [
    "cross_validation = 10\n",
    "test_size = 0.2\n",
    "val_size = 0.1\n",
    "learning_rate = 0.05\n",
    "batch_size = 4\n",
    "epochs = 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "outputs": [],
   "source": [
    "image_size = 400"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "outputs": [],
   "source": [
    "sum_iou_train = 0\n",
    "sum_dice_train = 0\n",
    "sum_iou_val = 0\n",
    "sum_dice_val = 0\n",
    "sum_iou_test = 0\n",
    "sum_dice_test = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [],
   "source": [
    "class AugmentationSequence(tensorflow.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, augmentations):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(numpy.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        aug_x = numpy.zeros(batch_x.shape)\n",
    "        aug_y = numpy.zeros(batch_y.shape)\n",
    "\n",
    "        for idx in range(batch_x.shape[0]):\n",
    "            aug = self.augment(image=batch_x[idx, :, :, :], mask=batch_y[idx, :, :, :])\n",
    "            aug_x[idx, :, :, :] = aug[\"image\"]\n",
    "            aug_y[idx, :, :, :] = aug[\"mask\"]\n",
    "\n",
    "        return aug_x, aug_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [],
   "source": [
    "def resize_image(image, image_size):\n",
    "    return cv2.resize(image, (image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def get_all_images(dir):\n",
    "    return [{\"filename\": file.name, \"file\": cv2.imread(str(file.resolve()), cv2.IMREAD_GRAYSCALE)}\n",
    "            for file in pathlib.Path(dir).rglob(\"*\")]\n",
    "\n",
    "def only_resize(list_images, output_dir, image_size):\n",
    "    create_if_not_exists_dir(output_dir)\n",
    "    for image in list_images:\n",
    "        cv2.imwrite(os.path.join(output_dir, image[\"filename\"]), resize_image(image[\"file\"], image_size))\n",
    "\n",
    "def resize_all():\n",
    "    for data in [{\"path\": \"new/images\", \"type\": \"images\"}, {\"path\": \"new/mask\", \"type\": \"mask\"}]:\n",
    "            only_resize(get_all_images(data[\"path\"]), data[\"type\"], 400)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [],
   "source": [
    "def load_mask(filename):\n",
    "    return numpy.float32(skimage.io.imread(filename) / 255)\n",
    "\n",
    "def load_all_masks(path):\n",
    "    return [load_mask(filename) for filename in sorted(pathlib.Path(path).rglob(\"*\"))]\n",
    "\n",
    "def load_image(filename):\n",
    "    return skimage.img_as_float32(skimage.io.imread(filename))\n",
    "\n",
    "def load_all_images(path):\n",
    "    return [load_image(filename) for filename in sorted(pathlib.Path(path).rglob(\"*\"))]\n",
    "\n",
    "def width_height_are_equal_image_size(image, image_size):\n",
    "    return image.shape[0] == image_size and image.shape[1] == image_size\n",
    "\n",
    "def validate_data(path, image_size):\n",
    "    return all(not width_height_are_equal_image_size(skimage.io.imread(filename), image_size) for filename in sorted(pathlib.Path(path).rglob(\"*\")))\n",
    "\n",
    "if validate_data(path_mask, image_size) and validate_data(path_images, image_size):\n",
    "    raise SystemExit(\"err in input file\")\n",
    "\n",
    "images = load_all_images(path_images)\n",
    "masks = load_all_masks(path_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [],
   "source": [
    "def set_avx_avx2():\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # INFO messages are not printed\n",
    "\n",
    "def set_gpu():\n",
    "    gpus = tensorflow.config.experimental.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                print(f\"GPU: {gpu.name}\")\n",
    "                tensorflow.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [],
   "source": [
    "def unet_model(keras=None, img_size=None):\n",
    "\n",
    "    input_img = tensorflow.keras.layers.Input((img_size, img_size, 1), name = \"img\")\n",
    "\n",
    "    # Contract #1\n",
    "    c1 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(input_img)\n",
    "    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tensorflow.keras.layers.Activation(\"relu\")(c1)\n",
    "    c1 = tensorflow.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c1)\n",
    "    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tensorflow.keras.layers.Activation(\"relu\")(c1)\n",
    "    p1 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    # Contract #2\n",
    "    c2 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p1)\n",
    "    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tensorflow.keras.layers.Activation(\"relu\")(c2)\n",
    "    c2 = tensorflow.keras.layers.Dropout(0.2)(c2)\n",
    "    c2 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c2)\n",
    "    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tensorflow.keras.layers.Activation(\"relu\")(c2)\n",
    "    p2 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Contract #3\n",
    "    c3 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p2)\n",
    "    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tensorflow.keras.layers.Activation(\"relu\")(c3)\n",
    "    c3 = tensorflow.keras.layers.Dropout(0.3)(c3)\n",
    "    c3 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c3)\n",
    "    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tensorflow.keras.layers.Activation(\"relu\")(c3)\n",
    "    p3 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Contract #4\n",
    "    c4 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p3)\n",
    "    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tensorflow.keras.layers.Activation(\"relu\")(c4)\n",
    "    c4 = tensorflow.keras.layers.Dropout(0.4)(c4)\n",
    "    c4 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c4)\n",
    "    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tensorflow.keras.layers.Activation(\"relu\")(c4)\n",
    "    p4 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Middle\n",
    "    c5 = tensorflow.keras.layers.Conv2D(256, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p4)\n",
    "    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = tensorflow.keras.layers.Activation(\"relu\")(c5)\n",
    "    c5 = tensorflow.keras.layers.Dropout(0.5)(c5)\n",
    "    c5 = tensorflow.keras.layers.Conv2D(256, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c5)\n",
    "    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = tensorflow.keras.layers.Activation(\"relu\")(c5)\n",
    "\n",
    "    # Expand (upscale) #1\n",
    "    u6 = tensorflow.keras.layers.Conv2DTranspose(128, (3, 3), strides = (2, 2), padding = \"same\")(c5)\n",
    "    u6 = tensorflow.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u6)\n",
    "    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n",
    "    c6 = tensorflow.keras.layers.Activation(\"relu\")(c6)\n",
    "    c6 = tensorflow.keras.layers.Dropout(0.5)(c6)\n",
    "    c6 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c6)\n",
    "    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n",
    "    c6 = tensorflow.keras.layers.Activation(\"relu\")(c6)\n",
    "\n",
    "    # Expand (upscale) #2\n",
    "    u7 = tensorflow.keras.layers.Conv2DTranspose(64, (3, 3), strides = (2, 2), padding = \"same\")(c6)\n",
    "    u7 = tensorflow.keras.layers.concatenate([u7, c3])\n",
    "    c7 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u7)\n",
    "    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n",
    "    c7 = tensorflow.keras.layers.Activation(\"relu\")(c7)\n",
    "    c7 = tensorflow.keras.layers.Dropout(0.5)(c7)\n",
    "    c7 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c7)\n",
    "    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n",
    "    c7 = tensorflow.keras.layers.Activation(\"relu\")(c7)\n",
    "\n",
    "    # Expand (upscale) #3\n",
    "    u8 = tensorflow.keras.layers.Conv2DTranspose(32, (3, 3), strides = (2, 2), padding = \"same\")(c7)\n",
    "    u8 = tensorflow.keras.layers.concatenate([u8, c2])\n",
    "    c8 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u8)\n",
    "    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n",
    "    c8 = tensorflow.keras.layers.Activation(\"relu\")(c8)\n",
    "    c8 = tensorflow.keras.layers.Dropout(0.5)(c8)\n",
    "    c8 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c8)\n",
    "    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n",
    "    c8 = tensorflow.keras.layers.Activation(\"relu\")(c8)\n",
    "\n",
    "    # Expand (upscale) #4\n",
    "    u9 = tensorflow.keras.layers.Conv2DTranspose(16, (3, 3), strides = (2, 2), padding = \"same\")(c8)\n",
    "    u9 = tensorflow.keras.layers.concatenate([u9, c1])\n",
    "    c9 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u9)\n",
    "    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = tensorflow.keras.layers.Activation(\"relu\")(c9)\n",
    "    c9 = tensorflow.keras.layers.Dropout(0.5)(c9)\n",
    "    c9 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c9)\n",
    "    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = tensorflow.keras.layers.Activation(\"relu\")(c9)\n",
    "\n",
    "    output = tensorflow.keras.layers.Conv2D(1, (1, 1), activation = \"sigmoid\")(c9)\n",
    "    model = tensorflow.keras.Model(inputs = [input_img], outputs = [output])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [],
   "source": [
    "def jaccard_distance_loss(y_true, y_pred, smooth = 100):\n",
    "    intersection = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true) + tensorflow.keras.backend.abs(y_pred), axis = -1)\n",
    "    jac = (intersection + smooth) / (union - intersection + smooth)\n",
    "    loss = (1 - jac) * smooth\n",
    "    return loss\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    intersection = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true), -1) + tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_pred), -1)\n",
    "    return (2. * intersection + smooth) / (union + smooth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [],
   "source": [
    "def crop_image(img, mask):\n",
    "    crop_mask = mask > 0\n",
    "    m, n = mask.shape\n",
    "    crop_mask0, crop_mask1 = crop_mask.any(0), crop_mask.any(1)\n",
    "    col_start, col_end = crop_mask0.argmax(), n - crop_mask0[::-1].argmax()\n",
    "    row_start, row_end = crop_mask1.argmax(), m - crop_mask1[::-1].argmax()\n",
    "    return img[row_start:row_end, col_start:col_end], mask[row_start:row_end, col_start:col_end]\n",
    "\n",
    "def process_pred_mask(pred_mask):\n",
    "    open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "    open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "    return skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "\n",
    "def save_image_mask_predmask(filename, image, mask, pred_mask, post_pred_mask, image_original_mask, image_pred_mask):\n",
    "    figure = matplotlib.pyplot.figure(figsize=(15, 10))\n",
    "    figure.add_subplot(2, 3, 1).set_title(\"Original image\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(skimage.img_as_ubyte(image), cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 2).set_title(\"Original mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(skimage.img_as_ubyte(mask), cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 3).set_title(\"Predicted mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(pred_mask, cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 4).set_title(\"Preprocessed mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(post_pred_mask, cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 5).set_title(\"Image original mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(image_original_mask, cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 6).set_title(\"Image pred mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(image_pred_mask, cmap = \"gray\")\n",
    "    figure.savefig(filename)\n",
    "\n",
    "\n",
    "def save_images(X, Y, data_type, model, out_folder):\n",
    "    for idx in range(0, X.shape[0]):\n",
    "        test_img = X[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "        test_mask = Y[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "        pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "        image_pred_mask = pred_mask\n",
    "        pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "\n",
    "        open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "        open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "        post_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "        image_out_folder = os.path.join(out_folder, data_type, f\"{idx}\")\n",
    "\n",
    "        # crop_img, crop_mask = crop_image(test_img[0,:,:,0], post_pred_mask) # keep\n",
    "        crop_img_masked = test_img[0,:,:,0] * pred_mask\n",
    "        mask_original = numpy.uint8(test_mask[0,:,:,0] > 0.5)\n",
    "        crop_img_masked_original = test_img[0,:,:,0] * mask_original\n",
    "        crop_img_masked[crop_img_masked == 0] = 1\n",
    "        crop_img_masked_original[crop_img_masked_original == 0] = 1\n",
    "\n",
    "        create_if_not_exists_dir(image_out_folder)\n",
    "\n",
    "        print(os.path.join(image_out_folder, f\"{idx}-original.png\"))\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-original.png\"), skimage.img_as_ubyte(test_img[0,:,:,0]))\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-mask-original.png\"), skimage.img_as_ubyte(test_mask[0,:,:,0]))\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-mask-unet.png\"), skimage.img_as_ubyte(image_pred_mask))\n",
    "        # skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-post-pred-mask.png\"), post_pred_mask * 255)\n",
    "        # skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-crop-img.png\"), skimage.img_as_ubyte(crop_img))\n",
    "        # skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-crop-mask.png\"), crop_mask * 255)\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-crop-img-masked.png\"), skimage.img_as_ubyte(crop_img_masked))\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-crop-img-masked-original.png\"), skimage.img_as_ubyte(crop_img_masked_original))\n",
    "\n",
    "        print(os.path.join(image_out_folder, f\"{idx}.png\"))\n",
    "        save_image_mask_predmask(os.path.join(image_out_folder, f\"{idx}.png\"), test_img[0,:,:,0], test_mask[0,:,:,0], pred_mask, post_pred_mask, crop_img_masked_original, crop_img_masked)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [],
   "source": [
    "%%capture\n",
    "X = numpy.array(images).reshape(len(images), image_size, image_size, 1)\n",
    "Y = numpy.array(masks).reshape(len(masks), image_size, image_size, 1)\n",
    "X, Y = sklearn.utils.shuffle(X, Y, random_state=1234)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.05, random_state=1234)\n",
    "X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(X_train, Y_train, test_size=0.05, random_state=1234)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"X: {X.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(f\"images[50].shape: {images[50].shape}\")\n",
    "print(f\"masks[50].shape: {masks[50].shape}\")\n",
    "f = matplotlib.pyplot.figure()\n",
    "f.add_subplot(3, 2, 1)\n",
    "matplotlib.pyplot.imshow(images[50], cmap = \"gray\")\n",
    "f.add_subplot(3, 2, 2)\n",
    "matplotlib.pyplot.imshow(masks[50], cmap = \"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [357]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X_aug, Y_aug \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_generator\u001B[49m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;241m20\u001B[39m)\n\u001B[1;32m      2\u001B[0m f \u001B[38;5;241m=\u001B[39m matplotlib\u001B[38;5;241m.\u001B[39mpyplot\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m10\u001B[39m))\n\u001B[1;32m      3\u001B[0m f\u001B[38;5;241m.\u001B[39madd_subplot(\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "X_aug, Y_aug = train_generator.__getitem__(20)\n",
    "f = matplotlib.pyplot.figure(figsize=(10, 10))\n",
    "f.add_subplot(4, 2, 1)\n",
    "matplotlib.pyplot.imshow(X_aug[0,:,:,0], cmap = \"gray\")\n",
    "f.add_subplot(4, 2, 2)\n",
    "matplotlib.pyplot.imshow(Y_aug[0,:,:,0], cmap = \"gray\")\n",
    "\n",
    "f.add_subplot(4, 2, 3)\n",
    "matplotlib.pyplot.imshow(X_aug[1,:,:,0], cmap = \"gray\")\n",
    "f.add_subplot(4, 2, 4)\n",
    "matplotlib.pyplot.imshow(Y_aug[1,:,:,0], cmap = \"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [],
   "source": [
    "def set_idx(X_test):\n",
    "    images_test_ids = []\n",
    "    nimages = X_test.shape[0]\n",
    "    for idx in range(nimages):\n",
    "        test_image = X_test[idx, :, :, 0]\n",
    "        if any(numpy.array_equal(test_image, x) for x in images):\n",
    "            images_test_ids.append(idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [],
   "source": [
    "def cfg_model(X_train, Y_train, index_cv):\n",
    "    steps_per_epoch = math.ceil(X_train.shape[0] / batch_size)\n",
    "    augment = Compose([\n",
    "        HorizontalFlip(),\n",
    "        ShiftScaleRotate(rotate_limit=45, border_mode=cv2.BORDER_CONSTANT),\n",
    "        ElasticTransform(border_mode=cv2.BORDER_CONSTANT),\n",
    "        RandomBrightness(),\n",
    "        RandomContrast(),\n",
    "        RandomGamma()\n",
    "    ])\n",
    "    train_generator = AugmentationSequence(X_train, Y_train, batch_size, augment)\n",
    "    unet_filename = os.path.join(path_model,\n",
    "                                 f\"batch{batch_size}+lr{str(learning_rate).replace('.', '_')}+epoch{epochs}+steps{steps_per_epoch}+cv{index_cv}+unet.h5\")\n",
    "    reduce_learning_rate = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=3,\n",
    "                                                                        verbose=1)\n",
    "    checkpointer = tensorflow.keras.callbacks.ModelCheckpoint(unet_filename, verbose=1, save_best_only=True)\n",
    "    strategy = tensorflow.distribute.MirroredStrategy()\n",
    "    return checkpointer, reduce_learning_rate, steps_per_epoch, strategy, train_generator, unet_filename"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [],
   "source": [
    "def calculate_iou_dice(X_test, X_train, X_val, Y_test, Y_train, Y_val, model):\n",
    "    iou_train, dice_train = model.evaluate(X_train, Y_train, verbose=False)\n",
    "    iou_val, dice_val = model.evaluate(X_val, Y_val, verbose=False)\n",
    "    iou_test, dice_test = model.evaluate(X_test, Y_test, verbose=False)\n",
    "    return dice_test, dice_train, dice_val, iou_test, iou_train, iou_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [],
   "source": [
    "%%capture\n",
    "idx = 15\n",
    "test_img = X_test[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "test_mask = Y_test[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "post_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "\n",
    "crop_img, crop_mask = crop_image(test_img[0,:,:,0], post_pred_mask)\n",
    "\n",
    "crop_img_masked = crop_img * crop_mask\n",
    "\n",
    "# row, column\n",
    "f = matplotlib.pyplot.figure(figsize=(10, 10))\n",
    "f.add_subplot(2, 2, 1)\n",
    "matplotlib.pyplot.imshow(skimage.img_as_ubyte(test_img[0,:,:,0]), cmap = \"gray\")\n",
    "f.add_subplot(2, 2, 2)\n",
    "matplotlib.pyplot.imshow(post_pred_mask, cmap = \"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "outputs": [],
   "source": [
    "def create_figure_with_three_columns(X_test, Y_test, model, path_outfile_index_cv):\n",
    "    fig = matplotlib.pyplot.figure(constrained_layout=True, figsize=(60, 20))\n",
    "    fig.suptitle(f\"Result {datetime.datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\", fontsize=36, color=\"r\")\n",
    "    subfigs = fig.subfigures(nrows=3, ncols=1)\n",
    "    titles = [\"Original\", \"Mask original\", \"Mask u-net\"]\n",
    "    for i, subfig in enumerate(subfigs):\n",
    "        subfig.suptitle(titles[i], fontsize=28, color=\"r\")\n",
    "\n",
    "        axs = subfig.subplots(nrows=1, ncols=8)\n",
    "        for j, ax in enumerate(axs):\n",
    "            if i == 0:\n",
    "                test_img = X_test[j, :, :, :].reshape((1, image_size, image_size, 1))\n",
    "                ax.imshow(skimage.img_as_ubyte(test_img[0, :, :, 0]), cmap=\"gray\")\n",
    "            elif i == 1:\n",
    "                test_mask = Y_test[j, :, :, :].reshape((1, image_size, image_size, 1))\n",
    "                ax.imshow(skimage.img_as_ubyte(test_mask[0, :, :, 0]), cmap=\"gray\")\n",
    "            elif i == 2:\n",
    "                test_img = X_test[j, :, :, :].reshape((1, image_size, image_size, 1))\n",
    "                pred_mask = model.predict(test_img)[0, :, :, 0]\n",
    "                pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "                ax.imshow(pred_mask, cmap=\"gray\")\n",
    "    print(f\"b->{path_outfile_index_cv}.png\")\n",
    "    fig.savefig(f\"{path_outfile_index_cv}.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "outputs": [],
   "source": [
    "def create_outfile_cv(X_test, X_train, X_val, dice_test, dice_train, dice_val, index_cv, iou_test, iou_train, iou_val,\n",
    "                      path_outfile_index_cv, steps_per_epoch, unet_filename):\n",
    "    print(f\"c->{path_outfile_index_cv}.txt\")\n",
    "    try:\n",
    "        with open(f\"{path_outfile_index_cv}.txt\", \"w\") as outfile:\n",
    "            outfile.write(f\"unet filename={unet_filename}\\n\")\n",
    "            outfile.write(f\"index cv={index_cv}\\n\")\n",
    "            outfile.write(f\"X: {X.shape}, X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\\n\")\n",
    "            outfile.write(f\"learning_rate={learning_rate}, batch_size={batch_size}\\n\")\n",
    "            outfile.write(f\"epochs={epochs}, steps={steps_per_epoch}\\n\")\n",
    "            outfile.write(f\"============================================\\n\")\n",
    "            outfile.write(f\"Jaccard distance (IoU) train: {iou_train}\\n\")\n",
    "            outfile.write(f\"Dice coeffient train: {dice_train}\\n\")\n",
    "            outfile.write(f\"Jaccard distance (IoU) validation: {iou_val}\\n\")\n",
    "            outfile.write(f\"Dice coeffient validation: {dice_val}\\n\")\n",
    "            outfile.write(f\"Jaccard distance (IoU) test: {iou_test}\\n\")\n",
    "            outfile.write(f\"Dice coeffient test: {dice_test}\\n\")\n",
    "            outfile.close()\n",
    "    except:\n",
    "        raise SystemError(f\"fail in create outfile {path_outfile_index_cv}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [],
   "source": [
    "def save_all_images(X_test, X_train, X_val, Y_test, Y_train, Y_val, model, out_folder_index_cv, path_outfile_index_cv):\n",
    "    # save_images(X_train, Y_train, \"train\", model, out_folder_index_cv)\n",
    "    # save_images(X_test, Y_test, \"test\", model, out_folder_index_cv)\n",
    "    save_images(X_val, Y_val, \"val\", model, out_folder_index_cv)\n",
    "    print(f\"folder {path_outfile_index_cv} created\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# TODO adicionar titulo\n",
    "def plot_loss_graph(model, path_outfile):\n",
    "    print(os.path.exists(path_outfile))\n",
    "    fig, ax = matplotlib.pyplot.subplots(1, figsize=(10,10))\n",
    "    ax.plot(model.history[\"loss\"], label=\"Train\")\n",
    "    ax.plot(model.history[\"val_loss\"], label=\"Validation\")\n",
    "    ax.plot(model.history[\"lr\"], label=\"Learning rate\")\n",
    "    fig.suptitle(\"Train, Validation and Learning Rate\", fontsize=20)\n",
    "    ax.set_ylabel(\"Loss\", fontsize=16)\n",
    "    ax.set_xlabel(\"Epoch\", fontsize=16)\n",
    "    ax.legend()\n",
    "    fig.savefig(f\"{path_outfile}-lossgraph.png\")\n",
    "    print(f\"save in {path_outfile}-lossgraph.png\")\n",
    "\n",
    "\n",
    "# f = open(\"/home/xandao/herbario/code/piperaceae-segmentation/result/07-07-2022-15-40-05/cv-0/result-07-07-2022-15-40-05-fit.pckl\", \"rb\")\n",
    "# history = pickle.load(f)\n",
    "# f.close()\n",
    "# print(history)\n",
    "# plot_loss_graph(history, path_out)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (270, 400, 400, 1)\n",
      "Y_train.shape: (270, 400, 400, 1)\n",
      "X_val.shape: (30, 400, 400, 1)\n",
      "Y_val.shape: (30, 400, 400, 1)\n",
      "Y_test.shape: (75, 400, 400, 1)\n",
      "X_test.shape: (75, 400, 400, 1)\n",
      "/home/xandao/herbario/code/piperaceae-segmentation/result/07-07-2022-16-52-24/cv-0 /home/xandao/herbario/code/piperaceae-segmentation/result/07-07-2022-16-52-24/cv-0/result-07-07-2022-16-52-24\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xandao/miniconda3/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1613: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/xandao/miniconda3/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1639: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xandao/herbario/code/piperaceae-segmentation/model/batch4+lr0_05+epoch200+steps68+cv0+unet.h5\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 16:52:29.737593: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_498147\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\023FlatMapDataset:6450\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - ETA: 0s - loss: 0.1247 - dice_coef: 0.9318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 16:52:57.766704: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_505928\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\023FlatMapDataset:6475\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.20406, saving model to /home/xandao/herbario/code/piperaceae-segmentation/model/batch4+lr0_05+epoch200+steps68+cv0+unet.h5\n",
      "68/68 [==============================] - 30s 359ms/step - loss: 0.1247 - dice_coef: 0.9318 - val_loss: 0.2041 - val_dice_coef: 0.8948 - lr: 0.0500\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0832 - dice_coef: 0.9563\n",
      "Epoch 2: val_loss did not improve from 0.20406\n",
      "68/68 [==============================] - 23s 330ms/step - loss: 0.0832 - dice_coef: 0.9563 - val_loss: 0.2042 - val_dice_coef: 0.8947 - lr: 0.0500\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0744 - dice_coef: 0.9608\n",
      "Epoch 3: val_loss improved from 0.20406 to 0.16549, saving model to /home/xandao/herbario/code/piperaceae-segmentation/model/batch4+lr0_05+epoch200+steps68+cv0+unet.h5\n",
      "68/68 [==============================] - 20s 296ms/step - loss: 0.0744 - dice_coef: 0.9608 - val_loss: 0.1655 - val_dice_coef: 0.9147 - lr: 0.0500\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0716 - dice_coef: 0.9623\n",
      "Epoch 4: val_loss improved from 0.16549 to 0.08924, saving model to /home/xandao/herbario/code/piperaceae-segmentation/model/batch4+lr0_05+epoch200+steps68+cv0+unet.h5\n",
      "68/68 [==============================] - 24s 349ms/step - loss: 0.0716 - dice_coef: 0.9623 - val_loss: 0.0892 - val_dice_coef: 0.9534 - lr: 0.0500\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0709 - dice_coef: 0.9627\n",
      "Epoch 5: val_loss did not improve from 0.08924\n",
      "68/68 [==============================] - 23s 333ms/step - loss: 0.0709 - dice_coef: 0.9627 - val_loss: 0.2007 - val_dice_coef: 0.8969 - lr: 0.0500\n",
      "Epoch 6/200\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0723 - dice_coef: 0.9620\n",
      "Epoch 6: val_loss improved from 0.08924 to 0.03801, saving model to /home/xandao/herbario/code/piperaceae-segmentation/model/batch4+lr0_05+epoch200+steps68+cv0+unet.h5\n",
      "68/68 [==============================] - 23s 333ms/step - loss: 0.0717 - dice_coef: 0.9623 - val_loss: 0.0380 - val_dice_coef: 0.9791 - lr: 0.0500\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0647 - dice_coef: 0.9658\n",
      "Epoch 7: val_loss did not improve from 0.03801\n",
      "68/68 [==============================] - 23s 335ms/step - loss: 0.0647 - dice_coef: 0.9658 - val_loss: 0.0532 - val_dice_coef: 0.9714 - lr: 0.0500\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0704 - dice_coef: 0.9629\n",
      "Epoch 8: val_loss did not improve from 0.03801\n",
      "68/68 [==============================] - 23s 333ms/step - loss: 0.0704 - dice_coef: 0.9629 - val_loss: 0.3699 - val_dice_coef: 0.8129 - lr: 0.0500\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0755 - dice_coef: 0.9603\n",
      "Epoch 9: val_loss improved from 0.03801 to 0.03615, saving model to /home/xandao/herbario/code/piperaceae-segmentation/model/batch4+lr0_05+epoch200+steps68+cv0+unet.h5\n",
      "68/68 [==============================] - 23s 334ms/step - loss: 0.0755 - dice_coef: 0.9603 - val_loss: 0.0362 - val_dice_coef: 0.9802 - lr: 0.0500\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0626 - dice_coef: 0.9668\n",
      "Epoch 10: val_loss did not improve from 0.03615\n",
      "68/68 [==============================] - 20s 292ms/step - loss: 0.0626 - dice_coef: 0.9668 - val_loss: 0.2041 - val_dice_coef: 0.8948 - lr: 0.0500\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0586 - dice_coef: 0.9688\n",
      "Epoch 11: val_loss did not improve from 0.03615\n",
      "68/68 [==============================] - 20s 288ms/step - loss: 0.0586 - dice_coef: 0.9688 - val_loss: 0.2041 - val_dice_coef: 0.8948 - lr: 0.0500\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0627 - dice_coef: 0.9668\n",
      "Epoch 12: val_loss did not improve from 0.03615\n",
      "68/68 [==============================] - 23s 341ms/step - loss: 0.0627 - dice_coef: 0.9668 - val_loss: 0.0458 - val_dice_coef: 0.9753 - lr: 0.0500\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0675 - dice_coef: 0.9644\n",
      "Epoch 13: val_loss did not improve from 0.03615\n",
      "68/68 [==============================] - 24s 346ms/step - loss: 0.0675 - dice_coef: 0.9644 - val_loss: 0.1127 - val_dice_coef: 0.9403 - lr: 0.0500\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0743 - dice_coef: 0.9609\n",
      "Epoch 14: val_loss did not improve from 0.03615\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "68/68 [==============================] - 24s 356ms/step - loss: 0.0743 - dice_coef: 0.9609 - val_loss: 0.0609 - val_dice_coef: 0.9676 - lr: 0.0500\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0674 - dice_coef: 0.9645\n",
      "Epoch 15: val_loss did not improve from 0.03615\n",
      "68/68 [==============================] - 23s 335ms/step - loss: 0.0674 - dice_coef: 0.9645 - val_loss: 0.2041 - val_dice_coef: 0.8948 - lr: 0.0250\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0674 - dice_coef: 0.9644\n",
      "Epoch 16: val_loss did not improve from 0.03615\n",
      "68/68 [==============================] - 20s 298ms/step - loss: 0.0674 - dice_coef: 0.9644 - val_loss: 0.3173 - val_dice_coef: 0.8349 - lr: 0.0250\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0614 - dice_coef: 0.9675\n",
      "Epoch 17: val_loss improved from 0.03615 to 0.03606, saving model to /home/xandao/herbario/code/piperaceae-segmentation/model/batch4+lr0_05+epoch200+steps68+cv0+unet.h5\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "68/68 [==============================] - 24s 347ms/step - loss: 0.0614 - dice_coef: 0.9675 - val_loss: 0.0361 - val_dice_coef: 0.9799 - lr: 0.0250\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0696 - dice_coef: 0.9633\n",
      "Epoch 18: val_loss improved from 0.03606 to 0.03396, saving model to /home/xandao/herbario/code/piperaceae-segmentation/model/batch4+lr0_05+epoch200+steps68+cv0+unet.h5\n",
      "68/68 [==============================] - 22s 327ms/step - loss: 0.0696 - dice_coef: 0.9633 - val_loss: 0.0340 - val_dice_coef: 0.9813 - lr: 0.0125\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0630 - dice_coef: 0.9666\n",
      "Epoch 19: val_loss did not improve from 0.03396\n",
      "68/68 [==============================] - 24s 351ms/step - loss: 0.0630 - dice_coef: 0.9666 - val_loss: 0.0346 - val_dice_coef: 0.9809 - lr: 0.0125\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0592 - dice_coef: 0.9686\n",
      "Epoch 20: val_loss did not improve from 0.03396\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "68/68 [==============================] - 21s 313ms/step - loss: 0.0592 - dice_coef: 0.9686 - val_loss: 0.0497 - val_dice_coef: 0.9732 - lr: 0.0125\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0586 - dice_coef: 0.9688\n",
      "Epoch 21: val_loss did not improve from 0.03396\n",
      "68/68 [==============================] - 23s 341ms/step - loss: 0.0586 - dice_coef: 0.9688 - val_loss: 0.0371 - val_dice_coef: 0.9797 - lr: 0.0063\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0541 - dice_coef: 0.9711\n",
      "Epoch 22: val_loss did not improve from 0.03396\n",
      "68/68 [==============================] - 23s 335ms/step - loss: 0.0541 - dice_coef: 0.9711 - val_loss: 0.1086 - val_dice_coef: 0.9436 - lr: 0.0063\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0533 - dice_coef: 0.9715\n",
      "Epoch 23: val_loss did not improve from 0.03396\n",
      "68/68 [==============================] - 22s 321ms/step - loss: 0.0533 - dice_coef: 0.9715 - val_loss: 0.0496 - val_dice_coef: 0.9733 - lr: 0.0063\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0461 - dice_coef: 0.9752\n",
      "Epoch 24: val_loss did not improve from 0.03396\n",
      "68/68 [==============================] - 23s 331ms/step - loss: 0.0461 - dice_coef: 0.9752 - val_loss: 0.0711 - val_dice_coef: 0.9625 - lr: 0.0063\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0447 - dice_coef: 0.9759\n",
      "Epoch 25: val_loss did not improve from 0.03396\n",
      "68/68 [==============================] - 21s 300ms/step - loss: 0.0447 - dice_coef: 0.9759 - val_loss: 0.0397 - val_dice_coef: 0.9783 - lr: 0.0063\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.0474 - dice_coef: 0.9745\n",
      "Epoch 26: val_loss did not improve from 0.03396\n",
      "68/68 [==============================] - 22s 319ms/step - loss: 0.0474 - dice_coef: 0.9745 - val_loss: 0.0372 - val_dice_coef: 0.9796 - lr: 0.0063\n",
      "Epoch 27/200\n",
      "29/68 [===========>..................] - ETA: 16s - loss: 0.0459 - dice_coef: 0.9753"
     ]
    }
   ],
   "source": [
    "def get_genus(filename):\n",
    "    list_genus = [\"manekia\", \"ottonia\", \"peperomia\", \"piper\", \"pothomorphe\"]\n",
    "    return next((g for g in list_genus if g in filename), ValueError(\"a\"))\n",
    "\n",
    "def get_path_mask(filename):\n",
    "    filename = re.sub(r\".[a-z]*$\", \"\", filename)\n",
    "    list_mask = list([str(file.resolve()) for file in pathlib.Path(path_mask).rglob(\"*\")])\n",
    "    return next((m for m in list_mask if filename in m), ValueError(\"a\"))\n",
    "\n",
    "def format_data(X, Y):\n",
    "    return X.reshape(X.shape[0], image_size, image_size, 1), Y.reshape(Y.shape[0], image_size, image_size, 1)\n",
    "\n",
    "def calculate_mean_metrics(path_result):\n",
    "    try:\n",
    "        # create file /home/xandao/herbario/code/piperaceae-segmentation/result/07-07-2022-13-57-38.txt\n",
    "        print(f\"create file {os.path.join(path_result, current_datetime)}-mean.txt\")\n",
    "        with open(f\"{os.path.join(path_result, current_datetime)}.txt\", \"w\") as outfile:\n",
    "            outfile.write(f\"Mean Jaccard distance (IoU) train: {sum_iou_train / cross_validation}\\n\")\n",
    "            outfile.write(f\"Mean Dice coeffient train: {sum_dice_train / cross_validation}\\n\")\n",
    "            outfile.write(f\"Mean Jaccard distance (IoU) validation: {sum_iou_val / cross_validation}\\n\")\n",
    "            outfile.write(f\"Mean Dice coeffient validation: {sum_dice_val / cross_validation}\\n\")\n",
    "            outfile.write(f\"Mean Jaccard distance (IoU) test: {sum_iou_test / cross_validation}\\n\")\n",
    "            outfile.write(f\"Mean Dice coeffient test: {sum_dice_test / cross_validation}\\n\")\n",
    "            outfile.close()\n",
    "    except:\n",
    "        raise SystemError(f\"fail in create outfile {current_datetime}\")\n",
    "\n",
    "def a(index_cv, X_train, Y_train, X_val, Y_val, X_test, Y_test, sum_iou_train, sum_dice_train, sum_iou_val, sum_dice_val, sum_iou_test, sum_dice_test):\n",
    "    out_folder_index_cv = os.path.join(path_out, f\"cv-{index_cv}\")\n",
    "    create_if_not_exists_dir(out_folder_index_cv)\n",
    "    path_outfile_index_cv = os.path.join(out_folder_index_cv, f\"result-{current_datetime}\")\n",
    "    print(out_folder_index_cv, path_outfile_index_cv)\n",
    "\n",
    "    set_idx(X_test)\n",
    "    checkpointer, reduce_learning_rate, steps_per_epoch, strategy, train_generator, unet_filename = cfg_model(X_train,\n",
    "                                                                                                              Y_train,\n",
    "                                                                                                              index_cv)\n",
    "    print(unet_filename)\n",
    "    model = None\n",
    "    fit = None\n",
    "\n",
    "    if os.path.exists(unet_filename):\n",
    "        model = tensorflow.keras.models.load_model(unet_filename, custom_objects = {\"jaccard_distance_loss\": jaccard_distance_loss,\"dice_coef\": dice_coef})\n",
    "    else:\n",
    "        with strategy.scope():\n",
    "            model = unet_model()\n",
    "            adam_opt = tensorflow.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "            model.compile(optimizer = adam_opt, loss = jaccard_distance_loss, metrics = [dice_coef])\n",
    "\n",
    "        fit = model.fit(train_generator,\n",
    "            steps_per_epoch = steps_per_epoch,\n",
    "            epochs = epochs,\n",
    "            validation_data = (X_val, Y_val),\n",
    "            callbacks = [checkpointer, reduce_learning_rate]\n",
    "        )\n",
    "        import json\n",
    "        # Get the dictionary containing each metric and the loss for each epoch\n",
    "        # history_dict = fit.history\n",
    "        # # Save it under the form of a json file\n",
    "        # json.dump(str(history_dict), open(os.path.join(path_result, f\"{path_outfile_index_cv}-fit.json\"), 'w'))\n",
    "\n",
    "        f = open(os.path.join(path_result, f\"{path_outfile_index_cv}-fit.pckl\"), \"wb\")\n",
    "        pickle.dump(fit.history, f)\n",
    "        f.close()\n",
    "\n",
    "\n",
    "        plot_loss_graph(fit, path_outfile_index_cv)\n",
    "\n",
    "    dice_test, dice_train, dice_val, iou_test, iou_train, iou_val = calculate_iou_dice(X_test, X_train, X_val, Y_test,\n",
    "                                                                                       Y_train, Y_val, model)\n",
    "\n",
    "    sum_iou_train += iou_train\n",
    "    sum_dice_train += dice_train\n",
    "    sum_iou_val += iou_val\n",
    "    sum_dice_val += dice_val\n",
    "    sum_iou_test += iou_test\n",
    "    sum_dice_test += dice_test\n",
    "\n",
    "    # create_figure_with_three_columns(X_test, Y_test, model, path_outfile_index_cv)\n",
    "\n",
    "    create_outfile_cv(X_test, X_train, X_val, dice_test, dice_train, dice_val, index_cv, iou_test, iou_train, iou_val,\n",
    "                      path_outfile_index_cv, steps_per_epoch, unet_filename)\n",
    "\n",
    "    # save_all_images(X_test, X_train, X_val, Y_test, Y_train, Y_val, model, out_folder_index_cv, path_outfile_index_cv)\n",
    "\n",
    "\n",
    "list_images = list([{\"path_image\": str(file.resolve()), \"path_mask\": get_path_mask(file.name), \"label\": get_genus(str(file.name))} for file in pathlib.Path(path_images).rglob(\"*\")])\n",
    "indices = sklearn.model_selection.StratifiedShuffleSplit(n_splits=cross_validation, test_size=test_size, random_state=1234)\n",
    "\n",
    "X = numpy.array([{\"path_image\": file[\"path_image\"], \"path_mask\": file[\"path_mask\"]} for file in list_images])\n",
    "Y = numpy.array([file[\"label\"] for file in list_images])\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(indices.split(X, Y)):\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    X_train = numpy.array([load_image(X[i][\"path_image\"]) for i in train_index])\n",
    "    X_train = X_train.reshape(X_train.shape[0], image_size, image_size, 1)\n",
    "    Y_train = numpy.array([load_mask(X[i][\"path_mask\"]) for i in train_index])\n",
    "    Y_train = Y_train.reshape(Y_train.shape[0], image_size, image_size, 1)\n",
    "\n",
    "    X_test = numpy.array([load_image(X[i][\"path_image\"]) for i in test_index])\n",
    "    X_test = X_test.reshape(X_test.shape[0], image_size, image_size, 1)\n",
    "    Y_test = numpy.array([load_mask(X[i][\"path_mask\"]) for i in test_index])\n",
    "    Y_test = Y_test.reshape(Y_test.shape[0], image_size, image_size, 1)\n",
    "\n",
    "    X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(X_train, Y_train, test_size=val_size, random_state=1234)\n",
    "\n",
    "    print(f\"X_train.shape: {X_train.shape}\")\n",
    "    print(f\"Y_train.shape: {Y_train.shape}\")\n",
    "    print(f\"X_val.shape: {X_val.shape}\")\n",
    "    print(f\"Y_val.shape: {Y_val.shape}\")\n",
    "    print(f\"Y_test.shape: {Y_test.shape}\")\n",
    "    print(f\"X_test.shape: {X_test.shape}\")\n",
    "\n",
    "    a(i, X_train, Y_train, X_val, Y_val, X_test, Y_test, sum_iou_train, sum_dice_train, sum_iou_val, sum_dice_val, sum_iou_test, sum_dice_test)\n",
    "\n",
    "print(\"a\")\n",
    "# # aqui eh a media\n",
    "calculate_mean_metrics(path_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}