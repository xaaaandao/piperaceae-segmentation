{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import collections\n",
    "import datetime\n",
    "import itertools\n",
    "import keras.backend\n",
    "import keras.preprocessing.image\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import re\n",
    "import skimage.morphology\n",
    "import skimage.io\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.utils\n",
    "import tensorflow\n",
    "import time\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def create_if_not_exists_dir(dir):\n",
    "    if not os.path.isdir(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "dir_base = \"/home/xandao/herbario/code/piperaceae-segmentation\"\n",
    "current_datetime = datetime.datetime.now().strftime('%d-%m-%Y-%H-%M-%S')\n",
    "path_model = os.path.join(dir_base, \"model\")\n",
    "path_result = os.path.join(dir_base, \"result\")\n",
    "path_out = os.path.join(path_result, current_datetime)\n",
    "path_images = os.path.join(dir_base, \"images\")\n",
    "path_mask = os.path.join(dir_base, \"mask\")\n",
    "\n",
    "for path in [path_model, path_result, path_out, path_images, path_mask]:\n",
    "    create_if_not_exists_dir(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "cross_validation = 10\n",
    "test_size = 0.15\n",
    "val_size = 0.05\n",
    "learning_rate = 0.05\n",
    "batch_size = 4\n",
    "epochs = 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "image_size = 400"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "mean_time_train = 0\n",
    "sum_iou_train = 0\n",
    "sum_dice_train = 0\n",
    "sum_iou_val = 0\n",
    "sum_dice_val = 0\n",
    "sum_iou_test = 0\n",
    "sum_dice_test = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class AugmentationSequence(tensorflow.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, augmentations):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(numpy.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        aug_x = numpy.zeros(batch_x.shape)\n",
    "        aug_y = numpy.zeros(batch_y.shape)\n",
    "\n",
    "        for idx in range(batch_x.shape[0]):\n",
    "            aug = self.augment(image=batch_x[idx, :, :, :], mask=batch_y[idx, :, :, :])\n",
    "            aug_x[idx, :, :, :] = aug[\"image\"]\n",
    "            aug_y[idx, :, :, :] = aug[\"mask\"]\n",
    "\n",
    "        return aug_x, aug_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def resize_image(image, image_size):\n",
    "    return cv2.resize(image, (image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def get_all_images(dir):\n",
    "    return [{\"filename\": file.name, \"file\": cv2.imread(str(file.resolve()), cv2.IMREAD_GRAYSCALE)}\n",
    "            for file in pathlib.Path(dir).rglob(\"*\")]\n",
    "\n",
    "def only_resize(list_images, output_dir, image_size):\n",
    "    create_if_not_exists_dir(output_dir)\n",
    "    for image in list_images:\n",
    "        cv2.imwrite(os.path.join(output_dir, image[\"filename\"]), resize_image(image[\"file\"], image_size))\n",
    "\n",
    "def resize_all():\n",
    "    for data in [{\"path\": \"new/images\", \"type\": \"images\"}, {\"path\": \"new/mask\", \"type\": \"mask\"}]:\n",
    "            only_resize(get_all_images(data[\"path\"]), data[\"type\"], 400)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (375,), Y.shape: (375,)\n"
     ]
    }
   ],
   "source": [
    "def load_mask(filename):\n",
    "    return numpy.float32(skimage.io.imread(filename) / 255)\n",
    "\n",
    "def load_all_masks(path):\n",
    "    return [load_mask(filename) for filename in sorted(pathlib.Path(path).rglob(\"*\"))]\n",
    "\n",
    "def load_image(filename):\n",
    "    return skimage.img_as_float32(skimage.io.imread(filename))\n",
    "\n",
    "def load_all_images(path):\n",
    "    return [load_image(filename) for filename in sorted(pathlib.Path(path).rglob(\"*\"))]\n",
    "\n",
    "def width_height_are_equal_image_size(image, image_size):\n",
    "    return image.shape[0] == image_size and image.shape[1] == image_size\n",
    "\n",
    "def validate_data(path, image_size):\n",
    "    return all(not width_height_are_equal_image_size(skimage.io.imread(filename), image_size) for filename in sorted(pathlib.Path(path).rglob(\"*\")))\n",
    "\n",
    "if validate_data(path_mask, image_size) and validate_data(path_images, image_size):\n",
    "    raise SystemExit(\"err in input file\")\n",
    "\n",
    "def get_genus(filename):\n",
    "    list_genus = [\"manekia\", \"ottonia\", \"peperomia\", \"piper\", \"pothomorphe\"]\n",
    "    return next((g for g in list_genus if g in filename), ValueError(\"a\"))\n",
    "\n",
    "def get_path_mask(filename):\n",
    "    filename = re.sub(r\".[a-z]*$\", \"\", filename)\n",
    "    list_mask = list([str(file.resolve()) for file in pathlib.Path(path_mask).rglob(\"*\")])\n",
    "    return next((m for m in list_mask if filename in m), ValueError(\"a\"))\n",
    "\n",
    "def format_data(X, Y):\n",
    "    return X.reshape(X.shape[0], image_size, image_size, 1), Y.reshape(Y.shape[0], image_size, image_size, 1)\n",
    "\n",
    "list_images = list([{\"path_image\": str(file.resolve()), \"path_mask\": get_path_mask(file.name), \"label\": get_genus(str(file.name))} for file in pathlib.Path(path_images).rglob(\"*\")])\n",
    "indices = sklearn.model_selection.StratifiedShuffleSplit(n_splits=cross_validation, test_size=test_size, random_state=1234)\n",
    "\n",
    "X = numpy.array([{\"path_image\": file[\"path_image\"], \"path_mask\": file[\"path_mask\"]} for file in list_images])\n",
    "Y = numpy.array([file[\"label\"] for file in list_images])\n",
    "\n",
    "print(f\"X.shape: {X.shape}, Y.shape: {Y.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "def set_avx_avx2():\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # INFO messages are not printed\n",
    "\n",
    "def set_gpu():\n",
    "    gpus = tensorflow.config.experimental.list_physical_devices(\"GPU\")\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                print(f\"GPU: {gpu.name}\")\n",
    "                tensorflow.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "set_avx_avx2()\n",
    "set_gpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# U-net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def unet_model(keras=None, img_size=None):\n",
    "\n",
    "    input_img = tensorflow.keras.layers.Input((img_size, img_size, 1), name = \"img\")\n",
    "\n",
    "    # Contract #1\n",
    "    c1 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(input_img)\n",
    "    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tensorflow.keras.layers.Activation(\"relu\")(c1)\n",
    "    c1 = tensorflow.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c1)\n",
    "    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tensorflow.keras.layers.Activation(\"relu\")(c1)\n",
    "    p1 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    # Contract #2\n",
    "    c2 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p1)\n",
    "    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tensorflow.keras.layers.Activation(\"relu\")(c2)\n",
    "    c2 = tensorflow.keras.layers.Dropout(0.2)(c2)\n",
    "    c2 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c2)\n",
    "    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tensorflow.keras.layers.Activation(\"relu\")(c2)\n",
    "    p2 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Contract #3\n",
    "    c3 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p2)\n",
    "    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tensorflow.keras.layers.Activation(\"relu\")(c3)\n",
    "    c3 = tensorflow.keras.layers.Dropout(0.3)(c3)\n",
    "    c3 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c3)\n",
    "    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tensorflow.keras.layers.Activation(\"relu\")(c3)\n",
    "    p3 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Contract #4\n",
    "    c4 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p3)\n",
    "    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tensorflow.keras.layers.Activation(\"relu\")(c4)\n",
    "    c4 = tensorflow.keras.layers.Dropout(0.4)(c4)\n",
    "    c4 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c4)\n",
    "    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tensorflow.keras.layers.Activation(\"relu\")(c4)\n",
    "    p4 = tensorflow.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Middle\n",
    "    c5 = tensorflow.keras.layers.Conv2D(256, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(p4)\n",
    "    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = tensorflow.keras.layers.Activation(\"relu\")(c5)\n",
    "    c5 = tensorflow.keras.layers.Dropout(0.5)(c5)\n",
    "    c5 = tensorflow.keras.layers.Conv2D(256, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c5)\n",
    "    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = tensorflow.keras.layers.Activation(\"relu\")(c5)\n",
    "\n",
    "    # Expand (upscale) #1\n",
    "    u6 = tensorflow.keras.layers.Conv2DTranspose(128, (3, 3), strides = (2, 2), padding = \"same\")(c5)\n",
    "    u6 = tensorflow.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u6)\n",
    "    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n",
    "    c6 = tensorflow.keras.layers.Activation(\"relu\")(c6)\n",
    "    c6 = tensorflow.keras.layers.Dropout(0.5)(c6)\n",
    "    c6 = tensorflow.keras.layers.Conv2D(128, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c6)\n",
    "    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n",
    "    c6 = tensorflow.keras.layers.Activation(\"relu\")(c6)\n",
    "\n",
    "    # Expand (upscale) #2\n",
    "    u7 = tensorflow.keras.layers.Conv2DTranspose(64, (3, 3), strides = (2, 2), padding = \"same\")(c6)\n",
    "    u7 = tensorflow.keras.layers.concatenate([u7, c3])\n",
    "    c7 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u7)\n",
    "    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n",
    "    c7 = tensorflow.keras.layers.Activation(\"relu\")(c7)\n",
    "    c7 = tensorflow.keras.layers.Dropout(0.5)(c7)\n",
    "    c7 = tensorflow.keras.layers.Conv2D(64, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c7)\n",
    "    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n",
    "    c7 = tensorflow.keras.layers.Activation(\"relu\")(c7)\n",
    "\n",
    "    # Expand (upscale) #3\n",
    "    u8 = tensorflow.keras.layers.Conv2DTranspose(32, (3, 3), strides = (2, 2), padding = \"same\")(c7)\n",
    "    u8 = tensorflow.keras.layers.concatenate([u8, c2])\n",
    "    c8 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u8)\n",
    "    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n",
    "    c8 = tensorflow.keras.layers.Activation(\"relu\")(c8)\n",
    "    c8 = tensorflow.keras.layers.Dropout(0.5)(c8)\n",
    "    c8 = tensorflow.keras.layers.Conv2D(32, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c8)\n",
    "    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n",
    "    c8 = tensorflow.keras.layers.Activation(\"relu\")(c8)\n",
    "\n",
    "    # Expand (upscale) #4\n",
    "    u9 = tensorflow.keras.layers.Conv2DTranspose(16, (3, 3), strides = (2, 2), padding = \"same\")(c8)\n",
    "    u9 = tensorflow.keras.layers.concatenate([u9, c1])\n",
    "    c9 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(u9)\n",
    "    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = tensorflow.keras.layers.Activation(\"relu\")(c9)\n",
    "    c9 = tensorflow.keras.layers.Dropout(0.5)(c9)\n",
    "    c9 = tensorflow.keras.layers.Conv2D(16, (3, 3), kernel_initializer = \"he_uniform\", padding = \"same\")(c9)\n",
    "    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = tensorflow.keras.layers.Activation(\"relu\")(c9)\n",
    "\n",
    "    output = tensorflow.keras.layers.Conv2D(1, (1, 1), activation = \"sigmoid\")(c9)\n",
    "    model = tensorflow.keras.Model(inputs = [input_img], outputs = [output])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def jaccard_distance_loss(y_true, y_pred, smooth = 100):\n",
    "    intersection = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true) + tensorflow.keras.backend.abs(y_pred), axis = -1)\n",
    "    jac = (intersection + smooth) / (union - intersection + smooth)\n",
    "    loss = (1 - jac) * smooth\n",
    "    return loss\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    intersection = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_true), -1) + tensorflow.keras.backend.sum(tensorflow.keras.backend.abs(y_pred), -1)\n",
    "    return (2. * intersection + smooth) / (union + smooth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def crop_image(img, mask):\n",
    "    crop_mask = mask > 0\n",
    "    m, n = mask.shape\n",
    "    crop_mask0, crop_mask1 = crop_mask.any(0), crop_mask.any(1)\n",
    "    col_start, col_end = crop_mask0.argmax(), n - crop_mask0[::-1].argmax()\n",
    "    row_start, row_end = crop_mask1.argmax(), m - crop_mask1[::-1].argmax()\n",
    "    return img[row_start:row_end, col_start:col_end], mask[row_start:row_end, col_start:col_end]\n",
    "\n",
    "def process_pred_mask(pred_mask):\n",
    "    open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "    open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "    return skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "\n",
    "def save_image_mask_predmask(filename, image, mask, pred_mask, post_pred_mask, image_original_mask, image_pred_mask):\n",
    "    figure = matplotlib.pyplot.figure(figsize=(15, 10))\n",
    "    figure.add_subplot(2, 3, 1).set_title(\"Original image\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(skimage.img_as_ubyte(image), cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 2).set_title(\"Original mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(skimage.img_as_ubyte(mask), cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 3).set_title(\"Predicted mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(pred_mask, cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 4).set_title(\"Preprocessed mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(post_pred_mask, cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 5).set_title(\"Image original mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(image_original_mask, cmap = \"gray\")\n",
    "    figure.add_subplot(2, 3, 6).set_title(\"Image pred mask\", fontdict = {\"fontsize\":18})\n",
    "    matplotlib.pyplot.imshow(image_pred_mask, cmap = \"gray\")\n",
    "    print(f\"{filename} created\")\n",
    "    figure.savefig(filename)\n",
    "\n",
    "\n",
    "def save_images(X, Y, data_type, model, out_folder):\n",
    "    for idx in range(0, X.shape[0]):\n",
    "        test_img = X[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "        test_mask = Y[idx,:,:,:].reshape((1, image_size, image_size, 1))\n",
    "        pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "        image_pred_mask = pred_mask\n",
    "        pred_mask = numpy.uint8(pred_mask > 0.5)\n",
    "\n",
    "        post_pred_mask = process_pred_mask(pred_mask)\n",
    "        image_out_folder = os.path.join(out_folder, data_type, f\"{idx}\")\n",
    "\n",
    "        # crop_img, crop_mask = crop_image(test_img[0,:,:,0], post_pred_mask) # keep\n",
    "        image_mask_unet = test_img[0,:,:,0] * pred_mask\n",
    "        mask_original = numpy.uint8(test_mask[0,:,:,0] > 0.5)\n",
    "        image_mask_original = test_img[0,:,:,0] * mask_original\n",
    "        image_mask_unet[image_mask_unet == 0] = 1\n",
    "        image_mask_original[image_mask_original == 0] = 1\n",
    "\n",
    "        create_if_not_exists_dir(image_out_folder)\n",
    "\n",
    "        print(f\"{os.path.join(image_out_folder, f'{idx}-original.png')} created\")\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-original.png\"), skimage.img_as_ubyte(test_img[0,:,:,0]))\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-mask-original.png\"), skimage.img_as_ubyte(test_mask[0,:,:,0]))\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-mask-unet.png\"), skimage.img_as_ubyte(image_pred_mask))\n",
    "        # skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-post-pred-mask.png\"), post_pred_mask * 255)\n",
    "        # skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-crop-img.png\"), skimage.img_as_ubyte(crop_img))\n",
    "        # skimage.io.imsave(os.path.join(image_out_folder, f\"{i}-crop-mask.png\"), crop_mask * 255)\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-image-mask-unet.png\"), skimage.img_as_ubyte(image_mask_unet))\n",
    "        skimage.io.imsave(os.path.join(image_out_folder, f\"{idx}-image-mask-original.png\"), skimage.img_as_ubyte(image_mask_original))\n",
    "\n",
    "        save_image_mask_predmask(os.path.join(image_out_folder, f\"{idx}.png\"), test_img[0,:,:,0], test_mask[0,:,:,0], pred_mask, post_pred_mask, image_mask_original, image_mask_unet)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "images = load_all_images(path_images)\n",
    "\n",
    "def set_idx(X_test):\n",
    "    images_test_ids = []\n",
    "    for idx in range(X_test.shape[0]):\n",
    "        test_image = X_test[idx, :, :, 0]\n",
    "        if any(numpy.array_equal(test_image, x) for x in images):\n",
    "            images_test_ids.append(idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def cfg_model(X_train, Y_train, index_cv):\n",
    "    steps_per_epoch = math.ceil(X_train.shape[0] / batch_size)\n",
    "    augment = Compose([\n",
    "        HorizontalFlip(),\n",
    "        ShiftScaleRotate(rotate_limit=45, border_mode=cv2.BORDER_CONSTANT),\n",
    "        ElasticTransform(border_mode=cv2.BORDER_CONSTANT),\n",
    "        RandomBrightness(),\n",
    "        RandomContrast(),\n",
    "        RandomGamma()\n",
    "    ])\n",
    "    train_generator = AugmentationSequence(X_train, Y_train, batch_size, augment)\n",
    "    unet_filename = os.path.join(path_model,\n",
    "                                 f\"batch{batch_size}+lr{str(learning_rate).replace('.', '_')}+epoch{epochs}+steps{steps_per_epoch}+cv{index_cv}+unet.h5\")\n",
    "    reduce_learning_rate = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=3,\n",
    "                                                                        verbose=1)\n",
    "    checkpointer = tensorflow.keras.callbacks.ModelCheckpoint(unet_filename, verbose=1, save_best_only=True)\n",
    "    strategy = tensorflow.distribute.MirroredStrategy()\n",
    "    return checkpointer, reduce_learning_rate, steps_per_epoch, strategy, train_generator, unet_filename"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def calculate_iou_dice(X_test, X_train, X_val, Y_test, Y_train, Y_val, model):\n",
    "    iou_train, dice_train = model.evaluate(X_train, Y_train, verbose=False)\n",
    "    iou_val, dice_val = model.evaluate(X_val, Y_val, verbose=False)\n",
    "    iou_test, dice_test = model.evaluate(X_test, Y_test, verbose=False)\n",
    "    return dice_test, dice_train, dice_val, iou_test, iou_train, iou_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def create_figure_with_three_columns(X_test, Y_test, model, index_cv, path):\n",
    "    fig = matplotlib.pyplot.figure(constrained_layout=True, figsize=(60, 20))\n",
    "    fig.suptitle(f\"Result {datetime.datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\", fontsize=36, color=\"r\")\n",
    "    subfigs = fig.subfigures(nrows=3, ncols=1)\n",
    "    titles = [\"Original\", \"Mask original\", \"Mask u-net\"]\n",
    "    for i, subfig in enumerate(subfigs):\n",
    "        subfig.suptitle(titles[i], fontsize=28, color=\"r\")\n",
    "        axs = subfig.subplots(nrows=1, ncols=8)\n",
    "        for j, ax in enumerate(axs):\n",
    "            if i == 0:\n",
    "                test_img = X_test[j, :, :, :].reshape((1, image_size, image_size, 1))\n",
    "                ax.imshow(skimage.img_as_ubyte(test_img[0, :, :, 0]), cmap=\"gray\")\n",
    "            elif i == 1:\n",
    "                test_mask = Y_test[j, :, :, :].reshape((1, image_size, image_size, 1))\n",
    "                ax.imshow(skimage.img_as_ubyte(test_mask[0, :, :, 0]), cmap=\"gray\")\n",
    "            elif i == 2:\n",
    "                test_img = X_test[j, :, :, :].reshape((1, image_size, image_size, 1))\n",
    "                pred_mask = model.predict(test_img)[0, :, :, 0]\n",
    "                ax.imshow(pred_mask, cmap=\"gray\")\n",
    "    print(f\"{os.path.join(path, f'cv-{index_cv}-compartive.png')} created\")\n",
    "    fig.savefig(os.path.join(path, f\"cv-{index_cv}-compartive.png\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def create_outfile_cv(X_test, X_train, X_val, dice_test, dice_train, dice_val, index_cv, iou_test, iou_train, iou_val, path, steps_per_epoch, unet_filename, elapsed_time):\n",
    "    try:\n",
    "        print(f\"{os.path.join(path, f'cv-{index_cv}-result.txt')} created\")\n",
    "        with open(os.path.join(path, f\"cv-{index_cv}-result.txt\"), \"w\") as file:\n",
    "            file.write(f\"unet filename={unet_filename}\\n\")\n",
    "            file.write(f\"index cv={index_cv}\\n\")\n",
    "            file.write(f\"elapsed time={elapsed_time}\\n\")\n",
    "            file.write(f\"X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\\n\")\n",
    "            file.write(f\"learning_rate={learning_rate}, batch_size={batch_size}\\n\")\n",
    "            file.write(f\"epochs={epochs}, steps={steps_per_epoch}\\n\")\n",
    "            file.write(f\"============================================\\n\")\n",
    "            file.write(f\"Jaccard distance (IoU) train: {iou_train}\\n\")\n",
    "            file.write(f\"Dice coeffient train: {dice_train}\\n\")\n",
    "            file.write(f\"Jaccard distance (IoU) validation: {iou_val}\\n\")\n",
    "            file.write(f\"Dice coeffient validation: {dice_val}\\n\")\n",
    "            file.write(f\"Jaccard distance (IoU) test: {iou_test}\\n\")\n",
    "            file.write(f\"Dice coeffient test: {dice_test}\\n\")\n",
    "            file.close()\n",
    "    except:\n",
    "        raise SystemError(f\"fail in create outfile {os.path.join(path, f'cv-{str(index_cv)}.txt')}\")\n",
    "\n",
    "def calculate_mean_metrics(path):\n",
    "    try:\n",
    "        print(f\"{os.path.join(path, '-mean')}.txt created\")\n",
    "        with open(f\"{os.path.join(path, '-mean')}.txt\", \"w\") as outfile:\n",
    "            outfile.write(f\"Mean Jaccard distance (IoU) train: {sum_iou_train / cross_validation}\\n\")\n",
    "            outfile.write(f\"Mean Dice coeffient train: {sum_dice_train / cross_validation}\\n\")\n",
    "            outfile.write(f\"Mean Jaccard distance (IoU) validation: {sum_iou_val / cross_validation}\\n\")\n",
    "            outfile.write(f\"Mean Dice coeffient validation: {sum_dice_val / cross_validation}\\n\")\n",
    "            outfile.write(f\"Mean Jaccard distance (IoU) test: {sum_iou_test / cross_validation}\\n\")\n",
    "            outfile.write(f\"Mean Dice coeffient test: {sum_dice_test / cross_validation}\\n\")\n",
    "            outfile.close()\n",
    "    except:\n",
    "        raise SystemError(f\"fail in create outfile {os.path.join(path, 'mean')}.txt\")\n",
    "\n",
    "def images_used(X, path, type):\n",
    "     try:\n",
    "        print(f\"{os.path.join(path, f'{type}images-used.csv')} created\")\n",
    "        with open(os.path.join(path, f\"{type}images-used.csv\"), \"w\") as file:\n",
    "            file.write(\"path_image;path_mask\\n\")\n",
    "            for x in X:\n",
    "                file.write(f\"\\\"{list(x.values())[0]}\\\";\\\"{list(x.values())[1]}\\\"\\n\")\n",
    "            file.close()\n",
    "     except:\n",
    "         raise SystemExit(f\"error in create file\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def save_all_images(X_test, X_train, X_val, Y_test, Y_train, Y_val, model, out_folder_index_cv):\n",
    "    save_images(X_train, Y_train, \"train\", model, out_folder_index_cv)\n",
    "    save_images(X_test, Y_test, \"test\", model, out_folder_index_cv)\n",
    "    save_images(X_val, Y_val, \"val\", model, out_folder_index_cv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def plot_loss_graph(model, index_cv, path):\n",
    "    fig, ax = matplotlib.pyplot.subplots(1, figsize=(10, 10))\n",
    "    ax.plot(model.history[\"loss\"], label=\"Train\", linewidth=2, marker=\"o\")\n",
    "    ax.plot(model.history[\"val_loss\"], label=\"Validation\", linewidth=2, marker=\"o\")\n",
    "    ax.plot(model.history[\"lr\"], label=\"Learning rate\", linewidth=2, marker=\"o\")\n",
    "    fig.suptitle(\"Train, Validation and Learning Rate\", color=\"r\", fontsize=20, fontweight=\"bold\", verticalalignment=\"center\")\n",
    "    ax.set_ylabel(\"Loss\", color=\"r\", fontsize=16)\n",
    "    ax.set_xlabel(\"Epoch\", color=\"r\", fontsize=16)\n",
    "    ax.legend()\n",
    "    print(f\"{os.path.join(path, f'cv-{index_cv}-lossgraph.png')} created\")\n",
    "    fig.savefig(os.path.join(path, f\"cv-{index_cv}-lossgraph.png\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def save_fit_history(fit, index_cv, path):\n",
    "    try:\n",
    "        with open(os.path.join(path, f\"cv{index_cv}-fit.pckl\"), \"wb\") as file:\n",
    "            pickle.dump(fit.history, file)\n",
    "            file.close()\n",
    "    except:\n",
    "        raise SystemExit(f\"error in create cv{index_cv}-fit.pckl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import sys\n",
    "def train_test(index_cv, X_train, Y_train, X_val, Y_val, X_test, Y_test, sum_iou_train, sum_dice_train, sum_iou_val, sum_dice_val, sum_iou_test, sum_dice_test, path):\n",
    "    print(f\"cv -> {index_cv}\")\n",
    "    print(f\"X_train.shape: {X_train.shape}, Y_train.shape: {Y_train.shape}\")\n",
    "    print(f\"X_val.shape: {X_val.shape}, Y_val.shape: {Y_val.shape}\")\n",
    "    print(f\"X_test.shape: {X_test.shape}, Y_test.shape: {Y_test.shape}\")\n",
    "\n",
    "    set_idx(X_test)\n",
    "    checkpointer, reduce_learning_rate, steps_per_epoch, strategy, train_generator, unet_filename = cfg_model(X_train, Y_train, index_cv)\n",
    "\n",
    "    elapsed_time = None\n",
    "    model = None\n",
    "    fit = None\n",
    "\n",
    "    if os.path.exists(unet_filename):\n",
    "        model = tensorflow.keras.models.load_model(unet_filename, custom_objects = {\"jaccard_distance_loss\": jaccard_distance_loss,\"dice_coef\": dice_coef})\n",
    "    else:\n",
    "        with strategy.scope():\n",
    "            model = unet_model()\n",
    "            adam_opt = tensorflow.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "            model.compile(optimizer = adam_opt, loss = jaccard_distance_loss, metrics = [dice_coef])\n",
    "\n",
    "        start_time = time.time()\n",
    "        fit = model.fit(train_generator,\n",
    "            steps_per_epoch = steps_per_epoch,\n",
    "            epochs = epochs,\n",
    "            validation_data = (X_val, Y_val),\n",
    "            callbacks = [checkpointer, reduce_learning_rate]\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"time elapsed {time.strftime('%H:%M:%S', time.gmtime(elapsed_time))}\")\n",
    "\n",
    "        save_fit_history(fit, index_cv, path)\n",
    "        plot_loss_graph(fit, index_cv, path)\n",
    "\n",
    "\n",
    "    dice_test, dice_train, dice_val, iou_test, iou_train, iou_val = calculate_iou_dice(X_test, X_train, X_val, Y_test,Y_train, Y_val, model)\n",
    "\n",
    "    sum_iou_train += iou_train\n",
    "    sum_dice_train += dice_train\n",
    "    sum_iou_val += iou_val\n",
    "    sum_dice_val += dice_val\n",
    "    sum_iou_test += iou_test\n",
    "    sum_dice_test += dice_test\n",
    "\n",
    "    create_figure_with_three_columns(X_test, Y_test, model, index_cv, path)\n",
    "\n",
    "    create_outfile_cv(X_test, X_train, X_val, dice_test, dice_train, dice_val, index_cv, iou_test, iou_train, iou_val, path, steps_per_epoch, unet_filename, elapsed_time)\n",
    "\n",
    "    save_all_images(X_test, X_train, X_val, Y_test, Y_train, Y_val, model, path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def load_data(X, Y, path, type):\n",
    "    images_used(X, path, type)\n",
    "    X = numpy.array(list([load_image(x[\"path_image\"]) for x in X]))\n",
    "    Y = numpy.array(list([load_mask(y[\"path_mask\"]) for y in Y]))\n",
    "    return X.reshape(X.shape[0], image_size, image_size, 1), Y.reshape(Y.shape[0], image_size, image_size, 1)\n",
    "\n",
    "def load_all_data(X_train, X_val, X_test, path):\n",
    "    X_train, Y_train = load_data(X_train, numpy.copy(X_train), path, \"train\")\n",
    "    X_val, Y_val = load_data(X_val, numpy.copy(X_val), path, \"val\")\n",
    "    X_test, Y_test = load_data(X_test, numpy.copy(X_test), path, \"test\")\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def test_cross_validation():\n",
    "    for i, (train_index, test_index) in enumerate(indices.split(X, Y)):\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "        out_folder_index_cv = os.path.join(path_out, f\"cv-{i}\")\n",
    "        create_if_not_exists_dir(out_folder_index_cv)\n",
    "\n",
    "        X_train, Y_train = X[train_index], X[train_index]\n",
    "        X_test, Y_test = X[test_index], X[test_index]\n",
    "        X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(X_train, Y_train, test_size=val_size, random_state=1234)\n",
    "        X_train, Y_train, X_val, Y_val, X_test, Y_test = load_all_data(X_train, X_val, X_test, out_folder_index_cv)\n",
    "\n",
    "        train_test(i, X_train, Y_train, X_val, Y_val, X_test, Y_test, sum_iou_train, sum_dice_train, sum_iou_val, sum_dice_val, sum_iou_test, sum_dice_test, out_folder_index_cv)\n",
    "\n",
    "    calculate_mean_metrics(path_out)\n",
    "\n",
    "def without_cross_validation():\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    index_cv=999\n",
    "    out_folder_index_cv = os.path.join(path_out, f\"cv-{str(index_cv)}\")\n",
    "    create_if_not_exists_dir(out_folder_index_cv)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=test_size, random_state=1234)\n",
    "    X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(X_train, Y_train, test_size=val_size, random_state=1234)\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = load_all_data(X_train, X_val, X_test, out_folder_index_cv)\n",
    "\n",
    "    train_test(index_cv, X_train, Y_train, X_val, Y_val, X_test, Y_test, sum_iou_train, sum_dice_train, sum_iou_val, sum_dice_val, sum_iou_test, sum_dice_test, out_folder_index_cv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xandao/herbario/code/piperaceae-segmentation/result/10-07-2022-00-13-33/cv-999/trainimages-used.csv created\n",
      "/home/xandao/herbario/code/piperaceae-segmentation/result/10-07-2022-00-13-33/cv-999/valimages-used.csv created\n",
      "/home/xandao/herbario/code/piperaceae-segmentation/result/10-07-2022-00-13-33/cv-999/testimages-used.csv created\n",
      "cv -> 999\n",
      "X_train.shape: (302, 400, 400, 1), Y_train.shape: (302, 400, 400, 1)\n",
      "X_val.shape: (16, 400, 400, 1), Y_val.shape: (16, 400, 400, 1)\n",
      "X_test.shape: (57, 400, 400, 1), Y_test.shape: (57, 400, 400, 1)\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 00:13:39.727653: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_31005\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\023FlatMapDataset:5405\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - ETA: 0s - loss: 0.2432 - dice_coef: 0.8615"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 00:14:09.450721: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_38543\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\023FlatMapDataset:5430\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.21652, saving model to /home/xandao/herbario/code/piperaceae-segmentation/model/batch16+lr0_05+epoch4+steps19+cv999+unet.h5\n",
      "19/19 [==============================] - 31s 1s/step - loss: 0.2432 - dice_coef: 0.8615 - val_loss: 0.2165 - val_dice_coef: 0.8887 - lr: 0.0500\n",
      "Epoch 2/4\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0962 - dice_coef: 0.9504\n",
      "Epoch 2: val_loss did not improve from 0.21652\n",
      "19/19 [==============================] - 26s 1s/step - loss: 0.0962 - dice_coef: 0.9504 - val_loss: 0.2165 - val_dice_coef: 0.8887 - lr: 0.0500\n",
      "Epoch 3/4\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0709 - dice_coef: 0.9624\n",
      "Epoch 3: val_loss improved from 0.21652 to 0.19687, saving model to /home/xandao/herbario/code/piperaceae-segmentation/model/batch16+lr0_05+epoch4+steps19+cv999+unet.h5\n",
      "19/19 [==============================] - 27s 1s/step - loss: 0.0709 - dice_coef: 0.9624 - val_loss: 0.1969 - val_dice_coef: 0.8983 - lr: 0.0500\n",
      "Epoch 4/4\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.0676 - dice_coef: 0.9642\n",
      "Epoch 4: val_loss improved from 0.19687 to 0.16879, saving model to /home/xandao/herbario/code/piperaceae-segmentation/model/batch16+lr0_05+epoch4+steps19+cv999+unet.h5\n",
      "19/19 [==============================] - 26s 1s/step - loss: 0.0676 - dice_coef: 0.9642 - val_loss: 0.1688 - val_dice_coef: 0.9120 - lr: 0.0500\n",
      "time elapsed 00:01:50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'middle' is not a valid value for align; supported values are 'top', 'bottom', 'center', 'baseline', 'center_baseline'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [48]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m     test_cross_validation()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m----> 4\u001B[0m     \u001B[43mwithout_cross_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [47]\u001B[0m, in \u001B[0;36mwithout_cross_validation\u001B[0;34m()\u001B[0m\n\u001B[1;32m     25\u001B[0m X_train, X_val, Y_train, Y_val \u001B[38;5;241m=\u001B[39m sklearn\u001B[38;5;241m.\u001B[39mmodel_selection\u001B[38;5;241m.\u001B[39mtrain_test_split(X_train, Y_train, test_size\u001B[38;5;241m=\u001B[39mval_size, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1234\u001B[39m)\n\u001B[1;32m     26\u001B[0m X_train, Y_train, X_val, Y_val, X_test, Y_test \u001B[38;5;241m=\u001B[39m load_all_data(X_train, X_val, X_test, out_folder_index_cv)\n\u001B[0;32m---> 28\u001B[0m \u001B[43mtrain_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex_cv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msum_iou_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msum_dice_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msum_iou_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msum_dice_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msum_iou_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msum_dice_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_folder_index_cv\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [45]\u001B[0m, in \u001B[0;36mtrain_test\u001B[0;34m(index_cv, X_train, Y_train, X_val, Y_val, X_test, Y_test, sum_iou_train, sum_dice_train, sum_iou_val, sum_dice_val, sum_iou_test, sum_dice_test, path)\u001B[0m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime elapsed \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m'\u001B[39m, time\u001B[38;5;241m.\u001B[39mgmtime(elapsed_time))\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     33\u001B[0m     save_fit_history(fit, index_cv, path)\n\u001B[0;32m---> 34\u001B[0m     \u001B[43mplot_loss_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_cv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m dice_test, dice_train, dice_val, iou_test, iou_train, iou_val \u001B[38;5;241m=\u001B[39m calculate_iou_dice(X_test, X_train, X_val, Y_test,Y_train, Y_val, model)\n\u001B[1;32m     39\u001B[0m sum_iou_train \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m iou_train\n",
      "Input \u001B[0;32mIn [43]\u001B[0m, in \u001B[0;36mplot_loss_graph\u001B[0;34m(model, index_cv, path)\u001B[0m\n\u001B[1;32m      4\u001B[0m ax\u001B[38;5;241m.\u001B[39mplot(model\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation\u001B[39m\u001B[38;5;124m\"\u001B[39m, linewidth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mo\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m ax\u001B[38;5;241m.\u001B[39mplot(model\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLearning rate\u001B[39m\u001B[38;5;124m\"\u001B[39m, linewidth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mo\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m \u001B[43mfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msuptitle\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTrain, Validation and Learning Rate\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfontsize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfontweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbold\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverticalalignment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmiddle\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m ax\u001B[38;5;241m.\u001B[39mset_ylabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss\u001B[39m\u001B[38;5;124m\"\u001B[39m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m, fontsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n\u001B[1;32m      8\u001B[0m ax\u001B[38;5;241m.\u001B[39mset_xlabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch\u001B[39m\u001B[38;5;124m\"\u001B[39m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m, fontsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/figure.py:410\u001B[0m, in \u001B[0;36mFigureBase.suptitle\u001B[0;34m(self, t, **kwargs)\u001B[0m\n\u001B[1;32m    403\u001B[0m \u001B[38;5;129m@docstring\u001B[39m\u001B[38;5;241m.\u001B[39mSubstitution(x0\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, y0\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.98\u001B[39m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msuptitle\u001B[39m\u001B[38;5;124m'\u001B[39m, ha\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcenter\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    404\u001B[0m                         va\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtop\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    405\u001B[0m \u001B[38;5;129m@docstring\u001B[39m\u001B[38;5;241m.\u001B[39mcopy(_suplabels)\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msuptitle\u001B[39m(\u001B[38;5;28mself\u001B[39m, t, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    407\u001B[0m     \u001B[38;5;66;03m# docstring from _suplabels...\u001B[39;00m\n\u001B[1;32m    408\u001B[0m     info \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_suptitle\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx0\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124my0\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0.98\u001B[39m,\n\u001B[1;32m    409\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mha\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcenter\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mva\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtop\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrotation\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0\u001B[39m}\n\u001B[0;32m--> 410\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_suplabels\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/figure.py:390\u001B[0m, in \u001B[0;36mFigureBase._suplabels\u001B[0;34m(self, t, info, **kwargs)\u001B[0m\n\u001B[1;32m    387\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfontweight\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[1;32m    388\u001B[0m         kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m mpl\u001B[38;5;241m.\u001B[39mrcParams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfigure.titleweight\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m--> 390\u001B[0m sup \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m suplab \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    392\u001B[0m     suplab\u001B[38;5;241m.\u001B[39mset_text(t)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/figure.py:1170\u001B[0m, in \u001B[0;36mFigureBase.text\u001B[0;34m(self, x, y, s, fontdict, **kwargs)\u001B[0m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m \u001B[38;5;124;03mAdd text to figure.\u001B[39;00m\n\u001B[1;32m   1133\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1163\u001B[0m \u001B[38;5;124;03m.pyplot.text\u001B[39;00m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1165\u001B[0m effective_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   1166\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtransform\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransSubfigure,\n\u001B[1;32m   1167\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(fontdict \u001B[38;5;28;01mif\u001B[39;00m fontdict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}),\n\u001B[1;32m   1168\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   1169\u001B[0m }\n\u001B[0;32m-> 1170\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[43mText\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43meffective_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1171\u001B[0m text\u001B[38;5;241m.\u001B[39mset_figure(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1172\u001B[0m text\u001B[38;5;241m.\u001B[39mstale_callback \u001B[38;5;241m=\u001B[39m _stale_figure_callback\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/text.py:149\u001B[0m, in \u001B[0;36mText.__init__\u001B[0;34m(self, x, y, text, color, verticalalignment, horizontalalignment, multialignment, fontproperties, rotation, linespacing, rotation_mode, usetex, wrap, transform_rotates_text, parse_math, **kwargs)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_parse_math(parse_math)\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_wrap(wrap)\n\u001B[0;32m--> 149\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_verticalalignment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mverticalalignment\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_horizontalalignment(horizontalalignment)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_multialignment \u001B[38;5;241m=\u001B[39m multialignment\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/text.py:1203\u001B[0m, in \u001B[0;36mText.set_verticalalignment\u001B[0;34m(self, align)\u001B[0m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_verticalalignment\u001B[39m(\u001B[38;5;28mself\u001B[39m, align):\n\u001B[1;32m   1196\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1197\u001B[0m \u001B[38;5;124;03m    Set the vertical alignment.\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;124;03m    align : {'center', 'top', 'bottom', 'baseline', 'center_baseline'}\u001B[39;00m\n\u001B[1;32m   1202\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1203\u001B[0m     \u001B[43m_api\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_in_list\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1204\u001B[0m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtop\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbottom\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcenter\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbaseline\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcenter_baseline\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1205\u001B[0m \u001B[43m        \u001B[49m\u001B[43malign\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malign\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1206\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_verticalalignment \u001B[38;5;241m=\u001B[39m align\n\u001B[1;32m   1207\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/_api/__init__.py:129\u001B[0m, in \u001B[0;36mcheck_in_list\u001B[0;34m(_values, _print_supported_values, **kwargs)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _print_supported_values:\n\u001B[1;32m    128\u001B[0m     msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m; supported values are \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28mrepr\u001B[39m, values))\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 129\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n",
      "\u001B[0;31mValueError\u001B[0m: 'middle' is not a valid value for align; supported values are 'top', 'bottom', 'center', 'baseline', 'center_baseline'"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if cross_validation > 1:\n",
    "    test_cross_validation()\n",
    "else:\n",
    "    without_cross_validation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}