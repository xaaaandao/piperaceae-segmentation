{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import collections\n",
    "import cv2\n",
    "import datetime\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import sklearn.model_selection\n",
    "import tensorflow\n",
    "import time\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma\n",
    ")\n",
    "from IPython.display import Markdown as md\n",
    "from markdownTable import markdownTable\n",
    "\n",
    "from files import create_folder, save_fit_history, save_lossgraph, save_figs\n",
    "from metrics import dice_coef, jaccard_distance\n",
    "from model import evaluate, unet_model, get_loss_function\n",
    "from AugmentationSequence import AugmentationSequence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "gpus = tensorflow.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            print(f\"GPU: {gpu.name}\")\n",
    "            tensorflow.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"channel\": 3,\n",
    "    \"batch_size\": 4,\n",
    "    \"fold\": 5,\n",
    "    \"epochs\": 75,\n",
    "    \"image_size\": 400,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"random_state\": 1234,\n",
    "    \"test_size\": 0.2,\n",
    "    \"val_size\": 0.05,\n",
    "    \"path_dataset\": \"dataset\",\n",
    "    \"path_out\": \"out\",\n",
    "    \"loss_function\": \"dice\"\n",
    "}\n",
    "images_folder = os.path.join(cfg[\"path_dataset\"], \"original\")\n",
    "masks_folder = os.path.join(cfg[\"path_dataset\"], \"mask\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 375 375\n"
     ]
    }
   ],
   "source": [
    "list_labels = list([])\n",
    "list_images = list([])\n",
    "list_images_names = list([])\n",
    "for file in pathlib.Path(masks_folder).rglob(\"*\"):\n",
    "    mask = skimage.io.imread(str(file.resolve()))\n",
    "    mask = numpy.float32(mask > 200)\n",
    "    list_labels.append(mask)\n",
    "\n",
    "    image = skimage.io.imread(os.path.join(images_folder, file.name))\n",
    "    image = skimage.transform.resize(image, (cfg[\"image_size\"], cfg[\"image_size\"]), anti_aliasing=True)\n",
    "    image = numpy.float32(image)\n",
    "    list_images.append(image)\n",
    "\n",
    "    list_images_names.append(str(file.stem))\n",
    "\n",
    "print(len(list_labels), len(list_images), len(list_images_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 400, 400, 3) (375, 400, 400, 1)\n"
     ]
    }
   ],
   "source": [
    "x = numpy.array(list_images).reshape((len(list_images), cfg[\"image_size\"], cfg[\"image_size\"], cfg[\"channel\"]))\n",
    "y = numpy.array(list_labels).reshape((len(list_labels), cfg[\"image_size\"], cfg[\"image_size\"], 1))\n",
    "\n",
    "print(x.shape, y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n",
      "Counter({0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1, 45: 1, 46: 1, 47: 1, 48: 1, 49: 1, 50: 1, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 1, 57: 1, 58: 1, 59: 1, 60: 1, 61: 1, 62: 1, 63: 1, 64: 1, 65: 1, 66: 1, 67: 1, 68: 1, 69: 1, 70: 1, 71: 1, 72: 1, 73: 1, 74: 1, 75: 1, 76: 1, 77: 1, 78: 1, 79: 1, 80: 1, 81: 1, 82: 1, 83: 1, 84: 1, 85: 1, 86: 1, 87: 1, 88: 1, 89: 1, 90: 1, 91: 1, 92: 1, 93: 1, 94: 1, 95: 1, 96: 1, 97: 1, 98: 1, 99: 1, 100: 1, 101: 1, 102: 1, 103: 1, 104: 1, 105: 1, 106: 1, 107: 1, 108: 1, 109: 1, 110: 1, 111: 1, 112: 1, 113: 1, 114: 1, 115: 1, 116: 1, 117: 1, 118: 1, 119: 1, 120: 1, 121: 1, 122: 1, 123: 1, 124: 1, 125: 1, 126: 1, 127: 1, 128: 1, 129: 1, 130: 1, 131: 1, 132: 1, 133: 1, 134: 1, 135: 1, 136: 1, 137: 1, 138: 1, 139: 1, 140: 1, 141: 1, 142: 1, 143: 1, 144: 1, 145: 1, 146: 1, 147: 1, 148: 1, 149: 1, 150: 1, 151: 1, 152: 1, 153: 1, 154: 1, 155: 1, 156: 1, 157: 1, 158: 1, 159: 1, 160: 1, 161: 1, 162: 1, 163: 1, 164: 1, 165: 1, 166: 1, 167: 1, 168: 1, 169: 1, 170: 1, 171: 1, 172: 1, 173: 1, 174: 1, 175: 1, 176: 1, 177: 1, 178: 1, 179: 1, 180: 1, 181: 1, 182: 1, 183: 1, 184: 1, 185: 1, 186: 1, 187: 1, 188: 1, 189: 1, 190: 1, 191: 1, 192: 1, 193: 1, 194: 1, 195: 1, 196: 1, 197: 1, 198: 1, 199: 1, 200: 1, 201: 1, 202: 1, 203: 1, 204: 1, 205: 1, 206: 1, 207: 1, 208: 1, 209: 1, 210: 1, 211: 1, 212: 1, 213: 1, 214: 1, 215: 1, 216: 1, 217: 1, 218: 1, 219: 1, 220: 1, 221: 1, 222: 1, 223: 1, 224: 1, 225: 1, 226: 1, 227: 1, 228: 1, 229: 1, 230: 1, 231: 1, 232: 1, 233: 1, 234: 1, 235: 1, 236: 1, 237: 1, 238: 1, 239: 1, 240: 1, 241: 1, 242: 1, 243: 1, 244: 1, 245: 1, 246: 1, 247: 1, 248: 1, 249: 1, 250: 1, 251: 1, 252: 1, 253: 1, 254: 1, 255: 1, 256: 1, 257: 1, 258: 1, 259: 1, 260: 1, 261: 1, 262: 1, 263: 1, 264: 1, 265: 1, 266: 1, 267: 1, 268: 1, 269: 1, 270: 1, 271: 1, 272: 1, 273: 1, 274: 1, 275: 1, 276: 1, 277: 1, 278: 1, 279: 1, 280: 1, 281: 1, 282: 1, 283: 1, 284: 1, 285: 1, 286: 1, 287: 1, 288: 1, 289: 1, 290: 1, 291: 1, 292: 1, 293: 1, 294: 1, 295: 1, 296: 1, 297: 1, 298: 1, 299: 1, 300: 1, 301: 1, 302: 1, 303: 1, 304: 1, 305: 1, 306: 1, 307: 1, 308: 1, 309: 1, 310: 1, 311: 1, 312: 1, 313: 1, 314: 1, 315: 1, 316: 1, 317: 1, 318: 1, 319: 1, 320: 1, 321: 1, 322: 1, 323: 1, 324: 1, 325: 1, 326: 1, 327: 1, 328: 1, 329: 1, 330: 1, 331: 1, 332: 1, 333: 1, 334: 1, 335: 1, 336: 1, 337: 1, 338: 1, 339: 1, 340: 1, 341: 1, 342: 1, 343: 1, 344: 1, 345: 1, 346: 1, 347: 1, 348: 1, 349: 1, 350: 1, 351: 1, 352: 1, 353: 1, 354: 1, 355: 1, 356: 1, 357: 1, 358: 1, 359: 1, 360: 1, 361: 1, 362: 1, 363: 1, 364: 1, 365: 1, 366: 1, 367: 1, 368: 1, 369: 1, 370: 1, 371: 1, 372: 1, 373: 1, 374: 1})\n"
     ]
    }
   ],
   "source": [
    "kf = sklearn.model_selection.KFold(n_splits=cfg[\"fold\"], shuffle=True, random_state=cfg[\"random_state\"])\n",
    "l = list([])\n",
    "for (train_index, test_index) in kf.split(x):\n",
    "    l = l + test_index.tolist()\n",
    "print(len(list(set(l))))\n",
    "print(collections.Counter(sorted(l)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 400, 400, 3)\n",
      "(15, 400, 400, 3)\n",
      "(75, 400, 400, 3)\n",
      "(375, 400, 400, 3)\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xandao\\anaconda3\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1613: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "C:\\Users\\xandao\\anaconda3\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1639: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.5177 - dice_coef: 0.4816 - jaccard_distance: 0.3241 - precision: 0.4401 - recall: 0.9420\n",
      "Epoch 1: val_loss improved from inf to 0.98885, saving model to out\\06-08-2022-10-35-05\\0\\unet.h5\n",
      "36/36 [==============================] - 88s 2s/step - loss: 0.5177 - dice_coef: 0.4816 - jaccard_distance: 0.3241 - precision: 0.4401 - recall: 0.9420 - val_loss: 0.9889 - val_dice_coef: 0.0111 - val_jaccard_distance: 0.0056 - val_precision: 1.0000 - val_recall: 4.8321e-05 - lr: 0.0010\n",
      "out\\06-08-2022-10-35-05\\0\\fold0-fit.pckl created\n",
      "out\\06-08-2022-10-35-05\\0\\fold0-lossgraph.png created\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "list_evaluate = list([])\n",
    "current_datetime = datetime.datetime.now().strftime('%d-%m-%Y-%H-%M-%S')\n",
    "path = os.path.join(cfg[\"path_out\"], current_datetime)\n",
    "create_folder(list([path]))\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(x_train, y_train, test_size=cfg[\"val_size\"], random_state=cfg[\"random_state\"])\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(x_val.shape)\n",
    "    print(x_test.shape)\n",
    "    print(x.shape)\n",
    "\n",
    "    path_fold = os.path.join(path, str(fold))\n",
    "    create_folder(list([path_fold]))\n",
    "\n",
    "    augment = Compose([\n",
    "        HorizontalFlip(),\n",
    "        ShiftScaleRotate(rotate_limit=45, border_mode=cv2.BORDER_CONSTANT),\n",
    "        ElasticTransform(border_mode=cv2.BORDER_CONSTANT),\n",
    "        RandomBrightness(),\n",
    "        RandomContrast(),\n",
    "        RandomGamma()\n",
    "    ])\n",
    "    steps_per_epoch = math.ceil(x_train.shape[0] / cfg[\"batch_size\"])\n",
    "    train_generator = AugmentationSequence(x_train, y_train, cfg[\"batch_size\"], augment)\n",
    "    reduce_learning_rate = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=3, verbose=1)\n",
    "    filename_model = os.path.join(path_fold, \"unet.h5\")\n",
    "    checkpointer = tensorflow.keras.callbacks.ModelCheckpoint(filename_model, verbose=1, save_best_only=True)\n",
    "    strategy = tensorflow.distribute.MirroredStrategy()\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = unet_model(cfg)\n",
    "        adam_opt = tensorflow.keras.optimizers.Adam(learning_rate=cfg[\"learning_rate\"])\n",
    "        model.compile(optimizer=adam_opt, loss=get_loss_function(cfg[\"loss_function\"]),\n",
    "                      metrics=[dice_coef, jaccard_distance, tensorflow.keras.metrics.Precision(),\n",
    "                               tensorflow.keras.metrics.Recall()])\n",
    "\n",
    "    tensorflow.keras.backend.clear_session()\n",
    "    start_time = time.time()\n",
    "    fit = model.fit(train_generator,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              epochs=cfg[\"epochs\"],\n",
    "              validation_data=(x_val, y_val),\n",
    "               callbacks=[checkpointer, reduce_learning_rate]\n",
    "              )\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    save_fit_history(fold, fit, path_fold)\n",
    "    save_lossgraph(fold, fit, path_fold)\n",
    "    list_evaluate.append(evaluate(end_time, fold, model, x_train, x_val, x_test, y_train, y_val, y_test))\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "    # model = tensorflow.keras.models.load_model(\"unet.h5\", custom_objects = {\"jaccard_distance_loss\": jaccard_distance_loss, \"dice_coef\": dice_coef, \"jaccard_distance\": jaccard_distance })\n",
    "\n",
    "    save_figs(list_images_names, model, path_fold, x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    \"batch_size\": cfg[\"batch_size\"],\n",
    "    \"epochs\": cfg[\"epochs\"],\n",
    "    \"learning_rate\": cfg[\"learning_rate\"],\n",
    "    \"loss_function\": cfg[\"loss_function\"],\n",
    "}\n",
    "\n",
    "image_cfg = {\n",
    "    \"channel\": cfg[\"channel\"],\n",
    "    \"image_size\": cfg[\"image_size\"],\n",
    "}\n",
    "\n",
    "test_cfg = {\n",
    "    \"fold\": cfg[\"fold\"],\n",
    "    \"test_size\": cfg[\"test_size\"],\n",
    "    \"val_size\": cfg[\"val_size\"],\n",
    "    \"random_state\": cfg[\"random_state\"],\n",
    "}\n",
    "\n",
    "other_cfg = {\n",
    "    \"path_dataset\": cfg[\"path_dataset\"],\n",
    "    \"path_out\": cfg[\"path_out\"]\n",
    "}\n",
    "\n",
    "filename_cfg = os.path.join(path, \"cfg.md\")\n",
    "with open(filename_cfg, \"w\") as file:\n",
    "    file.write(\"### model\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([model_cfg])).getMarkdown()))\n",
    "    file.write(\"\\n\\n### image\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([image_cfg])).getMarkdown()))\n",
    "    file.write(\"\\n\\n### test\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([test_cfg])).getMarkdown()))\n",
    "    file.write(\"\\n\\n### other\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([other_cfg])).getMarkdown()))\n",
    "    file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "```\n+--------------------------------------------------------------------------------------------------+\n|    loss_train    |     dice_train    |   jaccard_train   |  precision_train |    recall_train    |\n+------------------+-------------------+-------------------+------------------+--------------------+\n|0.9222040772438049|0.07752200216054916|0.04064466431736946|0.7976624369621277|0.025603370741009712|\n+--------------------------------------------------------------------------------------------------+\n```"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mean(key, list_evaluate):\n",
    "    return numpy.mean(list([evaluate[key] for evaluate in list_evaluate]))\n",
    "\n",
    "def get_std(key, list_evaluate):\n",
    "    return numpy.std(list([evaluate[key] for evaluate in list_evaluate]))\n",
    "\n",
    "mean_metrics_train = {\n",
    "    \"loss_train\": get_mean(\"loss_train\", list_evaluate),\n",
    "    \"dice_train\": get_mean(\"dice_train\", list_evaluate),\n",
    "    \"jaccard_train\": get_mean(\"jaccard_train\", list_evaluate),\n",
    "    \"precision_train\": get_mean(\"precision_train\", list_evaluate),\n",
    "    \"recall_train\": get_mean(\"recall_train\", list_evaluate)\n",
    "}\n",
    "\n",
    "std_metrics_train = {\n",
    "    \"loss_train\": get_std(\"loss_train\", list_evaluate),\n",
    "    \"dice_train\": get_std(\"dice_train\", list_evaluate),\n",
    "    \"jaccard_train\": get_std(\"jaccard_train\", list_evaluate),\n",
    "    \"precision_train\": get_std(\"precision_train\", list_evaluate),\n",
    "    \"recall_train\": get_std(\"recall_train\", list_evaluate)\n",
    "}\n",
    "\n",
    "mean_metrics_val = {\n",
    "    \"loss_val\": get_mean(\"loss_val\", list_evaluate),\n",
    "    \"dice_val\": get_mean(\"dice_val\", list_evaluate),\n",
    "    \"jaccard_val\": get_mean(\"jaccard_val\", list_evaluate),\n",
    "    \"precision_val\": get_mean(\"precision_val\", list_evaluate),\n",
    "    \"recall_val\": get_mean(\"recall_val\", list_evaluate)\n",
    "}\n",
    "\n",
    "std_metrics_val = {\n",
    "    \"loss_val\": get_std(\"loss_val\", list_evaluate),\n",
    "    \"dice_val\": get_std(\"dice_val\", list_evaluate),\n",
    "    \"jaccard_val\": get_std(\"jaccard_val\", list_evaluate),\n",
    "    \"precision_val\": get_std(\"precision_val\", list_evaluate),\n",
    "    \"recall_val\": get_std(\"recall_val\", list_evaluate)\n",
    "}\n",
    "\n",
    "mean_metrics_test = {\n",
    "    \"loss_test\": get_mean(\"loss_test\", list_evaluate),\n",
    "    \"dice_test\": get_mean(\"dice_test\", list_evaluate),\n",
    "    \"jaccard_test\": get_mean(\"jaccard_test\", list_evaluate),\n",
    "    \"precision_test\": get_mean(\"precision_test\", list_evaluate),\n",
    "    \"recall_test\": get_mean(\"recall_test\", list_evaluate)\n",
    "}\n",
    "\n",
    "std_metrics_test = {\n",
    "    \"loss_test\": get_std(\"loss_test\", list_evaluate),\n",
    "    \"dice_test\": get_std(\"dice_test\", list_evaluate),\n",
    "    \"jaccard_test\": get_std(\"jaccard_test\", list_evaluate),\n",
    "    \"precision_test\": get_std(\"precision_test\", list_evaluate),\n",
    "    \"recall_test\": get_std(\"recall_test\", list_evaluate)\n",
    "}\n",
    "\n",
    "filename_mean_std = os.path.join(path, \"mean_std.md\")\n",
    "with open(filename_mean_std, \"w\") as file:\n",
    "    file.write(\"### train\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([mean_metrics_train])).getMarkdown()))\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([std_metrics_train])).getMarkdown()))\n",
    "    file.write(\"\\n\\n### val\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([mean_metrics_val])).getMarkdown()))\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([std_metrics_val])).getMarkdown()))\n",
    "    file.write(\"\\n\\n### test\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([mean_metrics_test])).getMarkdown()))\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([std_metrics_test])).getMarkdown()))\n",
    "    file.close()\n",
    "\n",
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([mean_metrics_train])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "```\n+----------------------------------------------------------------+\n|loss_train|dice_train|jaccard_train|precision_train|recall_train|\n+----------+----------+-------------+---------------+------------+\n|    0.0   |    0.0   |     0.0     |      0.0      |     0.0    |\n+----------------------------------------------------------------+\n```"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([std_metrics_train])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "```\n+-------------------------------------------------------------------------------------------------+\n|     loss_val     |      dice_val      |     jaccard_val    |precision_val|      recall_val      |\n+------------------+--------------------+--------------------+-------------+----------------------+\n|0.9888513088226318|0.011148706078529358|0.005606691353023052|     1.0     |4.8321380745619535e-05|\n+-------------------------------------------------------------------------------------------------+\n```"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([mean_metrics_val])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "```\n+-------------------------------------------------------------+\n| loss_test| dice_test|jaccard_test|precision_test|recall_test|\n+----------+----------+------------+--------------+-----------+\n|0.84 (0.0)|0.27 (0.0)| 0.16 (0.0) |  0.24 (0.0)  | 0.01 (0.0)|\n+-------------------------------------------------------------+```"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([std_metrics_val])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "```\n+--------------------------------------------------------------------------------------------------+\n|     loss_test    |     dice_test     |    jaccard_test   |  precision_test  |     recall_test    |\n+------------------+-------------------+-------------------+------------------+--------------------+\n|0.9262468218803406|0.05762256309390068|0.03073793463408947|0.9211751818656921|0.034407466650009155|\n+--------------------------------------------------------------------------------------------------+\n```"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([mean_metrics_test])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "```\n+-----------------------------------------------------------+\n|loss_test|dice_test|jaccard_test|precision_test|recall_test|\n+---------+---------+------------+--------------+-----------+\n|   0.0   |   0.0   |     0.0    |      0.0     |    0.0    |\n+-----------------------------------------------------------+\n```"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([std_metrics_test])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "for evaluate in list_evaluate:\n",
    "    filename_fold = os.path.join(path, str(evaluate[\"fold\"]), \"metrics.md\")\n",
    "\n",
    "    info = {\n",
    "        \"fold\": evaluate[\"fold\"],\n",
    "        \"time\": evaluate[\"time\"]\n",
    "    }\n",
    "\n",
    "    metrics_train = {\n",
    "        \"loss_train\": evaluate[\"loss_train\"],\n",
    "        \"dice_train\": evaluate[\"dice_train\"],\n",
    "        \"jaccard_train\": evaluate[\"jaccard_train\"],\n",
    "        \"precision_train\": evaluate[\"precision_train\"],\n",
    "        \"recall_train\": evaluate[\"recall_train\"],\n",
    "    }\n",
    "\n",
    "    metrics_val = {\n",
    "        \"loss_val\": evaluate[\"loss_val\"],\n",
    "        \"dice_val\": evaluate[\"dice_val\"],\n",
    "        \"jaccard_val\": evaluate[\"jaccard_val\"],\n",
    "        \"precision_val\": evaluate[\"precision_val\"],\n",
    "        \"recall_val\": evaluate[\"recall_val\"],\n",
    "    }\n",
    "\n",
    "    metrics_test = {\n",
    "        \"loss_test\": evaluate[\"loss_test\"],\n",
    "        \"dice_test\": evaluate[\"dice_test\"],\n",
    "        \"jaccard_test\": evaluate[\"jaccard_test\"],\n",
    "        \"precision_test\": evaluate[\"precision_test\"],\n",
    "        \"recall_test\": evaluate[\"recall_test\"],\n",
    "    }\n",
    "\n",
    "    with open(filename_fold, \"w\") as file:\n",
    "        file.write(\"### info\\n\\n\")\n",
    "        file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([info])).getMarkdown()))\n",
    "        file.write(\"\\n\\n### train\\n\\n\")\n",
    "        file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([metrics_train])).getMarkdown()))\n",
    "        file.write(\"\\n\\n### val\\n\\n\")\n",
    "        file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([metrics_val])).getMarkdown()))\n",
    "        file.write(\"\\n\\n### test\\n\\n\")\n",
    "        file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([metrics_test])).getMarkdown()))\n",
    "        file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}