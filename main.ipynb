{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import collections\n",
    "import cv2\n",
    "import datetime\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import sklearn.model_selection\n",
    "import tensorflow\n",
    "import time\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma\n",
    ")\n",
    "from IPython.display import Markdown as md\n",
    "from markdownTable import markdownTable\n",
    "\n",
    "from files import create_folder, save_fit_history, save_lossgraph, save_figs\n",
    "from metrics import dice_coef, jaccard_distance\n",
    "from model import evaluate, unet_model, get_loss_function\n",
    "from AugmentationSequence import AugmentationSequence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpus = tensorflow.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            print(f\"GPU: {gpu.name}\")\n",
    "            tensorflow.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"channel\": 3,\n",
    "    \"batch_size\": 4,\n",
    "    \"fold\": 5,\n",
    "    \"epochs\": 75,\n",
    "    \"image_size\": 400,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"random_state\": 1234,\n",
    "    \"test_size\": 0.2,\n",
    "    \"val_size\": 0.05,\n",
    "    \"path_dataset\": \"dataset\",\n",
    "    \"path_out\": \"out\",\n",
    "    \"loss_function\": \"dice\"\n",
    "}\n",
    "images_folder = os.path.join(cfg[\"path_dataset\"], \"original\")\n",
    "masks_folder = os.path.join(cfg[\"path_dataset\"], \"mask\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_labels = list([])\n",
    "list_images = list([])\n",
    "list_images_names = list([])\n",
    "for file in pathlib.Path(masks_folder).rglob(\"*\"):\n",
    "    mask = skimage.io.imread(str(file.resolve()))\n",
    "    mask = skimage.transform.resize(mask, (cfg[\"image_size\"], cfg[\"image_size\"]), anti_aliasing=True)\n",
    "    mask = numpy.float32(mask > 200)\n",
    "    list_labels.append(mask)\n",
    "\n",
    "    image = skimage.io.imread(os.path.join(images_folder, file.name))\n",
    "    image = skimage.transform.resize(image, (cfg[\"image_size\"], cfg[\"image_size\"]), anti_aliasing=True)\n",
    "    if cfg[\"channel\"] == 1:\n",
    "        image = skimage.color.rgb2gray(image)\n",
    "    image = numpy.float32(image)\n",
    "    list_images.append(image)\n",
    "\n",
    "    list_images_names.append(str(file.stem))\n",
    "\n",
    "print(len(list_labels), len(list_images), len(list_images_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = numpy.array(list_images).reshape((len(list_images), cfg[\"image_size\"], cfg[\"image_size\"], cfg[\"channel\"]))\n",
    "y = numpy.array(list_labels).reshape((len(list_labels), cfg[\"image_size\"], cfg[\"image_size\"], 1))\n",
    "\n",
    "print(x.shape, y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kf = sklearn.model_selection.KFold(n_splits=cfg[\"fold\"], shuffle=True, random_state=cfg[\"random_state\"])\n",
    "l = list([])\n",
    "for (train_index, test_index) in kf.split(x):\n",
    "    l = l + test_index.tolist()\n",
    "print(len(list(set(l))))\n",
    "print(collections.Counter(sorted(l)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = []\n",
    "list_evaluate = list([])\n",
    "current_datetime = datetime.datetime.now().strftime('%d-%m-%Y-%H-%M-%S')\n",
    "path = os.path.join(cfg[\"path_out\"], current_datetime)\n",
    "create_folder(list([path]))\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(x_train, y_train, test_size=cfg[\"val_size\"], random_state=cfg[\"random_state\"])\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(x_val.shape)\n",
    "    print(x_test.shape)\n",
    "    print(x.shape)\n",
    "\n",
    "    path_fold = os.path.join(path, str(fold))\n",
    "    create_folder(list([path_fold]))\n",
    "\n",
    "    augment = Compose([\n",
    "        HorizontalFlip(),\n",
    "        ShiftScaleRotate(rotate_limit=45, border_mode=cv2.BORDER_CONSTANT),\n",
    "        ElasticTransform(border_mode=cv2.BORDER_CONSTANT),\n",
    "        RandomBrightness(),\n",
    "        RandomContrast(),\n",
    "        RandomGamma()\n",
    "    ])\n",
    "    steps_per_epoch = math.ceil(x_train.shape[0] / cfg[\"batch_size\"])\n",
    "    train_generator = AugmentationSequence(x_train, y_train, cfg[\"batch_size\"], augment)\n",
    "    reduce_learning_rate = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=3, verbose=1)\n",
    "    filename_model = os.path.join(path_fold, \"unet.h5\")\n",
    "    checkpointer = tensorflow.keras.callbacks.ModelCheckpoint(filename_model, verbose=1, save_best_only=True)\n",
    "    strategy = tensorflow.distribute.MirroredStrategy()\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = unet_model(cfg)\n",
    "        adam_opt = tensorflow.keras.optimizers.Adam(learning_rate=cfg[\"learning_rate\"])\n",
    "        model.compile(optimizer=adam_opt, loss=get_loss_function(cfg[\"loss_function\"]),\n",
    "                      metrics=[dice_coef, jaccard_distance, tensorflow.keras.metrics.Precision(),\n",
    "                               tensorflow.keras.metrics.Recall()])\n",
    "\n",
    "    tensorflow.keras.backend.clear_session()\n",
    "    start_time = time.time()\n",
    "    fit = model.fit(train_generator,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              epochs=cfg[\"epochs\"],\n",
    "              validation_data=(x_val, y_val),\n",
    "               callbacks=[checkpointer, reduce_learning_rate]\n",
    "              )\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    save_fit_history(fold, fit, path_fold)\n",
    "    save_lossgraph(fold, fit, path_fold)\n",
    "    list_evaluate.append(evaluate(end_time, fold, model, x_train, x_val, x_test, y_train, y_val, y_test))\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "    # model = tensorflow.keras.models.load_model(\"unet_rgb.h5\", custom_objects = {\"dice_loss\": dice_loss, \"dice_coef\": dice_coef, \"jaccard_distance\": jaccard_distance })\n",
    "\n",
    "    save_figs(cfg, list_images_names, test_index, model, path_fold, x)\n",
    "tensorflow.keras.backend.clear_session()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    \"batch_size\": str(cfg[\"batch_size\"]),\n",
    "    \"epochs\": str(cfg[\"epochs\"]),\n",
    "    \"learning_rate\": str(cfg[\"learning_rate\"]), # sem converter nao imprime o 0.001\n",
    "    \"loss_function\": cfg[\"loss_function\"]\n",
    "}\n",
    "\n",
    "image_cfg = {\n",
    "    \"channel\": str(cfg[\"channel\"]),\n",
    "    \"image_size\": str(cfg[\"image_size\"]),\n",
    "}\n",
    "\n",
    "test_cfg = {\n",
    "    \"fold\": str(cfg[\"fold\"]),\n",
    "    \"test_size\": str(cfg[\"test_size\"]),\n",
    "    \"val_size\": str(cfg[\"val_size\"]),\n",
    "    \"random_state\": str(cfg[\"random_state\"]),\n",
    "}\n",
    "\n",
    "other_cfg = {\n",
    "    \"path_dataset\": cfg[\"path_dataset\"],\n",
    "    \"path_out\": cfg[\"path_out\"]\n",
    "}\n",
    "\n",
    "filename_cfg = os.path.join(path, \"cfg.md\")\n",
    "with open(filename_cfg, \"w\") as file:\n",
    "    file.write(\"### model\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([model_cfg])).getMarkdown()))\n",
    "    file.write(\"\\n\\n### image\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([image_cfg])).getMarkdown()))\n",
    "    file.write(\"\\n\\n### test\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([test_cfg])).getMarkdown()))\n",
    "    file.write(\"\\n\\n### other\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([other_cfg])).getMarkdown()))\n",
    "    file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_mean(key, list_evaluate):\n",
    "    return str(numpy.mean(list([evaluate[key] for evaluate in list_evaluate])))\n",
    "\n",
    "def get_std(key, list_evaluate):\n",
    "    return str(numpy.std(list([evaluate[key] for evaluate in list_evaluate])))\n",
    "\n",
    "mean_metrics_train = {\n",
    "    \"loss_train\": get_mean(\"loss_train\", list_evaluate),\n",
    "    \"dice_train\": get_mean(\"dice_train\", list_evaluate),\n",
    "    \"jaccard_train\": get_mean(\"jaccard_train\", list_evaluate),\n",
    "    \"precision_train\": get_mean(\"precision_train\", list_evaluate),\n",
    "    \"recall_train\": get_mean(\"recall_train\", list_evaluate)\n",
    "}\n",
    "\n",
    "std_metrics_train = {\n",
    "    \"loss_train\": get_std(\"loss_train\", list_evaluate),\n",
    "    \"dice_train\": get_std(\"dice_train\", list_evaluate),\n",
    "    \"jaccard_train\": get_std(\"jaccard_train\", list_evaluate),\n",
    "    \"precision_train\": get_std(\"precision_train\", list_evaluate),\n",
    "    \"recall_train\": get_std(\"recall_train\", list_evaluate)\n",
    "}\n",
    "\n",
    "mean_metrics_val = {\n",
    "    \"loss_val\": get_mean(\"loss_val\", list_evaluate),\n",
    "    \"dice_val\": get_mean(\"dice_val\", list_evaluate),\n",
    "    \"jaccard_val\": get_mean(\"jaccard_val\", list_evaluate),\n",
    "    \"precision_val\": get_mean(\"precision_val\", list_evaluate),\n",
    "    \"recall_val\": get_mean(\"recall_val\", list_evaluate)\n",
    "}\n",
    "\n",
    "std_metrics_val = {\n",
    "    \"loss_val\": get_std(\"loss_val\", list_evaluate),\n",
    "    \"dice_val\": get_std(\"dice_val\", list_evaluate),\n",
    "    \"jaccard_val\": get_std(\"jaccard_val\", list_evaluate),\n",
    "    \"precision_val\": get_std(\"precision_val\", list_evaluate),\n",
    "    \"recall_val\": get_std(\"recall_val\", list_evaluate)\n",
    "}\n",
    "\n",
    "mean_metrics_test = {\n",
    "    \"loss_test\": get_mean(\"loss_test\", list_evaluate),\n",
    "    \"dice_test\": get_mean(\"dice_test\", list_evaluate),\n",
    "    \"jaccard_test\": get_mean(\"jaccard_test\", list_evaluate),\n",
    "    \"precision_test\": get_mean(\"precision_test\", list_evaluate),\n",
    "    \"recall_test\": get_mean(\"recall_test\", list_evaluate)\n",
    "}\n",
    "\n",
    "std_metrics_test = {\n",
    "    \"loss_test\": get_std(\"loss_test\", list_evaluate),\n",
    "    \"dice_test\": get_std(\"dice_test\", list_evaluate),\n",
    "    \"jaccard_test\": get_std(\"jaccard_test\", list_evaluate),\n",
    "    \"precision_test\": get_std(\"precision_test\", list_evaluate),\n",
    "    \"recall_test\": get_std(\"recall_test\", list_evaluate)\n",
    "}\n",
    "\n",
    "filename_mean_std = os.path.join(path, \"mean_std.md\")\n",
    "with open(filename_mean_std, \"w\") as file:\n",
    "    file.write(\"### train\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([mean_metrics_train])).getMarkdown()))\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([std_metrics_train])).getMarkdown()))\n",
    "    file.write(\"\\n\\n### val\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([mean_metrics_val])).getMarkdown()))\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([std_metrics_val])).getMarkdown()))\n",
    "    file.write(\"\\n\\n### test\\n\\n\")\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([mean_metrics_test])).getMarkdown()))\n",
    "    file.write(re.sub(r\"```$\", \"\\n```\\n\", markdownTable(list([std_metrics_test])).getMarkdown()))\n",
    "    file.close()\n",
    "\n",
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([mean_metrics_train])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([std_metrics_train])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([mean_metrics_val])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([std_metrics_val])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([mean_metrics_test])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "md(re.sub(r\"```$\", \"\\n```\", markdownTable(list([std_metrics_test])).getMarkdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for evaluate in list_evaluate:\n",
    "    filename_fold = os.path.join(path, str(evaluate[\"fold\"]), \"metrics.md\")\n",
    "\n",
    "    info = {\n",
    "        \"fold\": evaluate[\"fold\"],\n",
    "        \"time\": evaluate[\"time\"]\n",
    "    }\n",
    "\n",
    "    metrics_train = {\n",
    "        \"loss_train\": str(evaluate[\"loss_train\"]),\n",
    "        \"dice_train\": str(evaluate[\"dice_train\"]),\n",
    "        \"jaccard_train\": str(evaluate[\"jaccard_train\"]),\n",
    "        \"precision_train\": str(evaluate[\"precision_train\"]),\n",
    "        \"recall_train\": str(evaluate[\"recall_train\"]),\n",
    "    }\n",
    "\n",
    "    metrics_val = {\n",
    "        \"loss_val\": str(evaluate[\"loss_val\"]),\n",
    "        \"dice_val\": str(evaluate[\"dice_val\"]),\n",
    "        \"jaccard_val\": str(evaluate[\"jaccard_val\"]),\n",
    "        \"precision_val\": str(evaluate[\"precision_val\"]),\n",
    "        \"recall_val\": str(evaluate[\"recall_val\"]),\n",
    "    }\n",
    "\n",
    "    metrics_test = {\n",
    "        \"loss_test\": str(evaluate[\"loss_test\"]),\n",
    "        \"dice_test\": str(evaluate[\"dice_test\"]),\n",
    "        \"jaccard_test\": str(evaluate[\"jaccard_test\"]),\n",
    "        \"precision_test\": str(evaluate[\"precision_test\"]),\n",
    "        \"recall_test\": str(evaluate[\"recall_test\"]),\n",
    "    }\n",
    "\n",
    "    with open(filename_fold, \"w\") as file:\n",
    "        file.write(\"### info\\n\\n\")\n",
    "        file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([info])).getMarkdown()))\n",
    "        file.write(\"\\n\\n### train\\n\\n\")\n",
    "        file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([metrics_train])).getMarkdown()))\n",
    "        file.write(\"\\n\\n### val\\n\\n\")\n",
    "        file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([metrics_val])).getMarkdown()))\n",
    "        file.write(\"\\n\\n### test\\n\\n\")\n",
    "        file.write(re.sub(r\"```$\", \"\\n```\", markdownTable(list([metrics_test])).getMarkdown()))\n",
    "        file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}