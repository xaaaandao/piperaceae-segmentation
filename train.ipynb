{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import datetime\n",
    "import ipynbname\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import pathlib\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import sklearn.model_selection\n",
    "import tensorflow\n",
    "import time\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma\n",
    ")\n",
    "\n",
    "from metrics import dice_coef, jaccard_distance\n",
    "from model import unet_model, get_loss_function\n",
    "from AugmentationSequence import AugmentationSequence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpus = tensorflow.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            print(f\"GPU: {gpu.name}\")\n",
    "            tensorflow.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"channel\": 3,\n",
    "    \"batch_size\": 4,\n",
    "    \"fold\": 5,\n",
    "    \"epochs\": 75,\n",
    "    \"image_size\": 256,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"random_state\": 1234,\n",
    "    \"test_size\": 0.2,\n",
    "    \"val_size\": 0.05,\n",
    "    \"path_dataset\": \"dataset\",\n",
    "    \"path_out\": \"out\",\n",
    "    \"loss_function\": \"dice\",\n",
    "    \"data_augmentation\": True\n",
    "}\n",
    "images_folder = os.path.join(cfg[\"path_dataset\"], \"IMAGEM_ORIGINAL\", \"CONVERTIDAS\", \"RGB\", \"256\", \"OUT\")\n",
    "masks_folder = os.path.join(cfg[\"path_dataset\"], \"MASK\", \"BITMAP\", \"256\", \"OUT\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_labels = list([])\n",
    "list_images = list([])\n",
    "list_images_names = list([])\n",
    "def load_files():\n",
    "    for file in sorted(pathlib.Path(masks_folder).rglob(\"*\")):\n",
    "        mask = skimage.io.imread(file.resolve())\n",
    "        mask = numpy.float32(mask/255)\n",
    "        list_labels.append(mask)\n",
    "\n",
    "        image = skimage.io.imread(os.path.join(images_folder, f\"{file.stem}.png\"))\n",
    "        image = numpy.float32(image/255)\n",
    "        list_images.append(image)\n",
    "\n",
    "        list_images_names.append(str(file.stem))\n",
    "\n",
    "load_files()\n",
    "print(len(list_labels), len(list_images), len(list_images_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = numpy.array(list_images).reshape((len(list_images), cfg[\"image_size\"], cfg[\"image_size\"], cfg[\"channel\"]))\n",
    "y = numpy.array(list_labels).reshape((len(list_labels), cfg[\"image_size\"], cfg[\"image_size\"], 1))\n",
    "\n",
    "x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(x, y, test_size=cfg[\"val_size\"], random_state=cfg[\"random_state\"])\n",
    "\n",
    "print(x.shape, y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_datetime = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "path_model = os.path.join(cfg[\"path_out\"], \"train\", current_datetime)\n",
    "pathlib.Path(path_model).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "augment = Compose([\n",
    "    HorizontalFlip(),\n",
    "    ShiftScaleRotate(rotate_limit=45, border_mode=cv2.BORDER_CONSTANT),\n",
    "    ElasticTransform(border_mode=cv2.BORDER_CONSTANT),\n",
    "    RandomBrightness(),\n",
    "    RandomContrast(),\n",
    "    RandomGamma()\n",
    "])\n",
    "steps_per_epoch = math.ceil(x_train.shape[0] / cfg[\"batch_size\"])\n",
    "train_generator = AugmentationSequence(x_train, y_train, cfg[\"batch_size\"], augment)\n",
    "reduce_learning_rate = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=3, verbose=1)\n",
    "filename_model = os.path.join(path_model, \"unet.h5\")\n",
    "checkpointer = tensorflow.keras.callbacks.ModelCheckpoint(filename_model, verbose=1, save_best_only=True)\n",
    "strategy = tensorflow.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = unet_model(cfg)\n",
    "    adam_opt = tensorflow.keras.optimizers.Adam(learning_rate=cfg[\"learning_rate\"])\n",
    "    model.compile(optimizer=adam_opt, loss=get_loss_function(cfg[\"loss_function\"]), metrics=[dice_coef, jaccard_distance, tensorflow.keras.metrics.Precision(), tensorflow.keras.metrics.Recall()])\n",
    "\n",
    "tensorflow.keras.backend.clear_session()\n",
    "start_time = time.time()\n",
    "fit = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cfg[\"epochs\"], validation_data=(x_val, y_val), callbacks=[checkpointer, reduce_learning_rate])\n",
    "end_time = time.time() - start_time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = [\"batch_size\", \"epochs\", \"learning_rate\", \"loss_function\", \"images\", \"masks\", \"len_images\", \"len_masks\", \"channel\", \"image_size\", \"fold\", \"test_size\", \"val_size\", \"random_state\", \"path_dataset\", \"path_out\", \"data_augmentation\", \"filename_script\", \"time\"]\n",
    "data = [cfg[\"batch_size\"], cfg[\"epochs\"], cfg[\"learning_rate\"], cfg[\"loss_function\"], images_folder, masks_folder, len(list_images), len(list_labels), cfg[\"channel\"], cfg[\"image_size\"], cfg[\"fold\"], cfg[\"test_size\"], cfg[\"val_size\"], cfg[\"random_state\"], cfg[\"path_dataset\"], cfg[\"path_out\"], cfg[\"data_augmentation\"], ipynbname.name(), time.strftime(\"%H:%M:%S\", time.gmtime(end_time))]\n",
    "\n",
    "dataframe_cfg = pandas.DataFrame(data, columns)\n",
    "dataframe_cfg = dataframe_cfg.applymap(lambda x: str(x).replace(\".\", \",\") if isinstance(x,float) else x)\n",
    "dataframe_cfg.to_csv(os.path.join(path_model, \"cfg.csv\"), decimal=\",\", sep=\";\", na_rep=\" \", header=False, quoting=csv.QUOTE_ALL)\n",
    "dataframe_cfg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}