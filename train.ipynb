{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 20:43:24.340538: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-12 20:43:24.505706: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-12 20:43:25.109186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/xandao/miniconda3/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-09-12 20:43:25.109246: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/xandao/miniconda3/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-09-12 20:43:25.109253: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import datetime\n",
    "import ipynbname\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import pathlib\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import sklearn.model_selection\n",
    "import tensorflow\n",
    "import time\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma\n",
    ")\n",
    "\n",
    "from metrics import dice_coef, jaccard_distance\n",
    "from model import unet_model, get_loss_function\n",
    "from AugmentationSequence import AugmentationSequence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: /physical_device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 20:43:25.894225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-12 20:43:25.949768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-12 20:43:25.949955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tensorflow.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            print(f\"GPU: {gpu.name}\")\n",
    "            tensorflow.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"channel\": 3,\n",
    "    \"batch_size\": 4,\n",
    "    \"fold\": 5,\n",
    "    \"epochs\": 75,\n",
    "    \"image_size\": 512,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"random_state\": 1234,\n",
    "    \"test_size\": 0.2,\n",
    "    \"val_size\": 0.05,\n",
    "    \"path_dataset\": \"dataset\",\n",
    "    \"path_out\": \"out\",\n",
    "    \"loss_function\": \"dice\",\n",
    "    \"data_augmentation\": True\n",
    "}\n",
    "images_folder = os.path.join(cfg[\"path_dataset\"], \"IMAGEM_ORIGINAL\", \"CONVERTIDAS\", \"RGB\", \"512\", \"OUT\")\n",
    "masks_folder = os.path.join(cfg[\"path_dataset\"], \"MASK\", \"BITMAP\", \"512\", \"OUT\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 375 375\n"
     ]
    }
   ],
   "source": [
    "list_labels = list([])\n",
    "list_images = list([])\n",
    "list_images_names = list([])\n",
    "def load_files():\n",
    "    for file in sorted(pathlib.Path(masks_folder).rglob(\"*\")):\n",
    "        mask = skimage.io.imread(file.resolve())\n",
    "        mask = numpy.float32(mask/255)\n",
    "        list_labels.append(mask)\n",
    "\n",
    "        image = skimage.io.imread(os.path.join(images_folder, f\"{file.stem}.png\"))\n",
    "        image = numpy.float32(image/255)\n",
    "        list_images.append(image)\n",
    "\n",
    "        list_images_names.append(str(file.stem))\n",
    "\n",
    "load_files()\n",
    "print(len(list_labels), len(list_images), len(list_images_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 512, 512, 3) (375, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "x = numpy.array(list_images).reshape((len(list_images), cfg[\"image_size\"], cfg[\"image_size\"], cfg[\"channel\"]))\n",
    "y = numpy.array(list_labels).reshape((len(list_labels), cfg[\"image_size\"], cfg[\"image_size\"], 1))\n",
    "\n",
    "x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(x, y, test_size=cfg[\"val_size\"], random_state=cfg[\"random_state\"])\n",
    "\n",
    "print(x.shape, y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xandao/miniconda3/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1613: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/xandao/miniconda3/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1639: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "2022-09-12 20:43:29.971014: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-12 20:43:29.971625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-12 20:43:29.971818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-12 20:43:29.971926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-12 20:43:30.266869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-12 20:43:30.267645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-12 20:43:30.268075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-12 20:43:30.268170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9772 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 20:43:30.956782: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_2408\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:1\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-09-12 20:43:38.177326: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n",
      "2022-09-12 20:43:38.689968: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-09-12 20:43:39.499005: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - ETA: 0s - loss: 0.4547 - dice_coef: 0.5453 - jaccard_distance: 0.3863 - precision: 0.4836 - recall: 0.9590\n",
      "Epoch 1: val_loss improved from inf to 0.35091, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 70s 680ms/step - loss: 0.4547 - dice_coef: 0.5453 - jaccard_distance: 0.3863 - precision: 0.4836 - recall: 0.9590 - val_loss: 0.3509 - val_dice_coef: 0.6491 - val_jaccard_distance: 0.4805 - val_precision: 0.7104 - val_recall: 0.8943 - lr: 0.0010\n",
      "Epoch 2/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.2645 - dice_coef: 0.7355 - jaccard_distance: 0.5922 - precision: 0.8269 - recall: 0.9542\n",
      "Epoch 2: val_loss did not improve from 0.35091\n",
      "89/89 [==============================] - 60s 676ms/step - loss: 0.2645 - dice_coef: 0.7355 - jaccard_distance: 0.5922 - precision: 0.8269 - recall: 0.9542 - val_loss: 0.6566 - val_dice_coef: 0.3434 - val_jaccard_distance: 0.2073 - val_precision: 0.1928 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1867 - dice_coef: 0.8133 - jaccard_distance: 0.6975 - precision: 0.8636 - recall: 0.9210\n",
      "Epoch 3: val_loss did not improve from 0.35091\n",
      "89/89 [==============================] - 58s 641ms/step - loss: 0.1867 - dice_coef: 0.8133 - jaccard_distance: 0.6975 - precision: 0.8636 - recall: 0.9210 - val_loss: 0.6266 - val_dice_coef: 0.3734 - val_jaccard_distance: 0.2296 - val_precision: 0.2242 - val_recall: 0.9998 - lr: 0.0010\n",
      "Epoch 4/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1598 - dice_coef: 0.8402 - jaccard_distance: 0.7377 - precision: 0.8548 - recall: 0.9076\n",
      "Epoch 4: val_loss did not improve from 0.35091\n",
      "89/89 [==============================] - 60s 681ms/step - loss: 0.1598 - dice_coef: 0.8402 - jaccard_distance: 0.7377 - precision: 0.8548 - recall: 0.9076 - val_loss: 0.4959 - val_dice_coef: 0.5041 - val_jaccard_distance: 0.3370 - val_precision: 0.3019 - val_recall: 0.9999 - lr: 0.0010\n",
      "Epoch 5/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1307 - dice_coef: 0.8693 - jaccard_distance: 0.7791 - precision: 0.8861 - recall: 0.9009\n",
      "Epoch 5: val_loss improved from 0.35091 to 0.12408, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 57s 647ms/step - loss: 0.1307 - dice_coef: 0.8693 - jaccard_distance: 0.7791 - precision: 0.8861 - recall: 0.9009 - val_loss: 0.1241 - val_dice_coef: 0.8759 - val_jaccard_distance: 0.7792 - val_precision: 0.8385 - val_recall: 0.9569 - lr: 0.0010\n",
      "Epoch 6/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1119 - dice_coef: 0.8881 - jaccard_distance: 0.8089 - precision: 0.9091 - recall: 0.9131\n",
      "Epoch 6: val_loss did not improve from 0.12408\n",
      "89/89 [==============================] - 58s 655ms/step - loss: 0.1119 - dice_coef: 0.8881 - jaccard_distance: 0.8089 - precision: 0.9091 - recall: 0.9131 - val_loss: 0.1282 - val_dice_coef: 0.8718 - val_jaccard_distance: 0.7727 - val_precision: 0.8495 - val_recall: 0.9792 - lr: 0.0010\n",
      "Epoch 7/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0912 - dice_coef: 0.9088 - jaccard_distance: 0.8410 - precision: 0.9222 - recall: 0.9228\n",
      "Epoch 7: val_loss improved from 0.12408 to 0.09972, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 58s 642ms/step - loss: 0.0912 - dice_coef: 0.9088 - jaccard_distance: 0.8410 - precision: 0.9222 - recall: 0.9228 - val_loss: 0.0997 - val_dice_coef: 0.9003 - val_jaccard_distance: 0.8187 - val_precision: 0.8350 - val_recall: 0.9934 - lr: 0.0010\n",
      "Epoch 8/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0987 - dice_coef: 0.9013 - jaccard_distance: 0.8301 - precision: 0.9107 - recall: 0.9214\n",
      "Epoch 8: val_loss improved from 0.09972 to 0.06737, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 62s 691ms/step - loss: 0.0987 - dice_coef: 0.9013 - jaccard_distance: 0.8301 - precision: 0.9107 - recall: 0.9214 - val_loss: 0.0674 - val_dice_coef: 0.9326 - val_jaccard_distance: 0.8738 - val_precision: 0.9779 - val_recall: 0.8987 - lr: 0.0010\n",
      "Epoch 9/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0878 - dice_coef: 0.9122 - jaccard_distance: 0.8498 - precision: 0.9171 - recall: 0.9252\n",
      "Epoch 9: val_loss did not improve from 0.06737\n",
      "89/89 [==============================] - 57s 640ms/step - loss: 0.0878 - dice_coef: 0.9122 - jaccard_distance: 0.8498 - precision: 0.9171 - recall: 0.9252 - val_loss: 0.0783 - val_dice_coef: 0.9217 - val_jaccard_distance: 0.8548 - val_precision: 0.8885 - val_recall: 0.9656 - lr: 0.0010\n",
      "Epoch 10/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0972 - dice_coef: 0.9028 - jaccard_distance: 0.8327 - precision: 0.9080 - recall: 0.9202\n",
      "Epoch 10: val_loss did not improve from 0.06737\n",
      "89/89 [==============================] - 57s 639ms/step - loss: 0.0972 - dice_coef: 0.9028 - jaccard_distance: 0.8327 - precision: 0.9080 - recall: 0.9202 - val_loss: 0.0932 - val_dice_coef: 0.9068 - val_jaccard_distance: 0.8295 - val_precision: 0.8441 - val_recall: 0.9885 - lr: 0.0010\n",
      "Epoch 11/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1021 - dice_coef: 0.8979 - jaccard_distance: 0.8247 - precision: 0.9099 - recall: 0.9045\n",
      "Epoch 11: val_loss did not improve from 0.06737\n",
      "89/89 [==============================] - 59s 657ms/step - loss: 0.1021 - dice_coef: 0.8979 - jaccard_distance: 0.8247 - precision: 0.9099 - recall: 0.9045 - val_loss: 0.0939 - val_dice_coef: 0.9061 - val_jaccard_distance: 0.8283 - val_precision: 0.8437 - val_recall: 0.9907 - lr: 0.0010\n",
      "Epoch 12/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0882 - dice_coef: 0.9118 - jaccard_distance: 0.8493 - precision: 0.9096 - recall: 0.9290\n",
      "Epoch 12: val_loss did not improve from 0.06737\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "89/89 [==============================] - 59s 660ms/step - loss: 0.0882 - dice_coef: 0.9118 - jaccard_distance: 0.8493 - precision: 0.9096 - recall: 0.9290 - val_loss: 0.0937 - val_dice_coef: 0.9063 - val_jaccard_distance: 0.8287 - val_precision: 0.8542 - val_recall: 0.9740 - lr: 0.0010\n",
      "Epoch 13/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0829 - dice_coef: 0.9171 - jaccard_distance: 0.8562 - precision: 0.9333 - recall: 0.9193\n",
      "Epoch 13: val_loss did not improve from 0.06737\n",
      "89/89 [==============================] - 58s 653ms/step - loss: 0.0829 - dice_coef: 0.9171 - jaccard_distance: 0.8562 - precision: 0.9333 - recall: 0.9193 - val_loss: 0.0724 - val_dice_coef: 0.9276 - val_jaccard_distance: 0.8650 - val_precision: 0.8878 - val_recall: 0.9763 - lr: 5.0000e-04\n",
      "Epoch 14/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0828 - dice_coef: 0.9172 - jaccard_distance: 0.8546 - precision: 0.9233 - recall: 0.9215\n",
      "Epoch 14: val_loss improved from 0.06737 to 0.05704, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 63s 710ms/step - loss: 0.0828 - dice_coef: 0.9172 - jaccard_distance: 0.8546 - precision: 0.9233 - recall: 0.9215 - val_loss: 0.0570 - val_dice_coef: 0.9430 - val_jaccard_distance: 0.8921 - val_precision: 0.9143 - val_recall: 0.9786 - lr: 5.0000e-04\n",
      "Epoch 15/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0768 - dice_coef: 0.9232 - jaccard_distance: 0.8676 - precision: 0.9242 - recall: 0.9277\n",
      "Epoch 15: val_loss did not improve from 0.05704\n",
      "89/89 [==============================] - 56s 625ms/step - loss: 0.0768 - dice_coef: 0.9232 - jaccard_distance: 0.8676 - precision: 0.9242 - recall: 0.9277 - val_loss: 0.0588 - val_dice_coef: 0.9412 - val_jaccard_distance: 0.8890 - val_precision: 0.9246 - val_recall: 0.9625 - lr: 5.0000e-04\n",
      "Epoch 16/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0882 - dice_coef: 0.9118 - jaccard_distance: 0.8453 - precision: 0.9230 - recall: 0.9141\n",
      "Epoch 16: val_loss improved from 0.05704 to 0.05212, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 57s 641ms/step - loss: 0.0882 - dice_coef: 0.9118 - jaccard_distance: 0.8453 - precision: 0.9230 - recall: 0.9141 - val_loss: 0.0521 - val_dice_coef: 0.9479 - val_jaccard_distance: 0.9009 - val_precision: 0.9801 - val_recall: 0.9215 - lr: 5.0000e-04\n",
      "Epoch 17/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0823 - dice_coef: 0.9177 - jaccard_distance: 0.8557 - precision: 0.9286 - recall: 0.9189\n",
      "Epoch 17: val_loss improved from 0.05212 to 0.04786, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 55s 621ms/step - loss: 0.0823 - dice_coef: 0.9177 - jaccard_distance: 0.8557 - precision: 0.9286 - recall: 0.9189 - val_loss: 0.0479 - val_dice_coef: 0.9521 - val_jaccard_distance: 0.9086 - val_precision: 0.9471 - val_recall: 0.9624 - lr: 5.0000e-04\n",
      "Epoch 18/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0666 - dice_coef: 0.9334 - jaccard_distance: 0.8803 - precision: 0.9429 - recall: 0.9381\n",
      "Epoch 18: val_loss improved from 0.04786 to 0.04305, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 54s 612ms/step - loss: 0.0666 - dice_coef: 0.9334 - jaccard_distance: 0.8803 - precision: 0.9429 - recall: 0.9381 - val_loss: 0.0431 - val_dice_coef: 0.9569 - val_jaccard_distance: 0.9174 - val_precision: 0.9750 - val_recall: 0.9429 - lr: 5.0000e-04\n",
      "Epoch 19/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0652 - dice_coef: 0.9348 - jaccard_distance: 0.8835 - precision: 0.9391 - recall: 0.9400\n",
      "Epoch 19: val_loss improved from 0.04305 to 0.03881, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 56s 628ms/step - loss: 0.0652 - dice_coef: 0.9348 - jaccard_distance: 0.8835 - precision: 0.9391 - recall: 0.9400 - val_loss: 0.0388 - val_dice_coef: 0.9612 - val_jaccard_distance: 0.9253 - val_precision: 0.9790 - val_recall: 0.9471 - lr: 5.0000e-04\n",
      "Epoch 20/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0753 - dice_coef: 0.9247 - jaccard_distance: 0.8668 - precision: 0.9270 - recall: 0.9332\n",
      "Epoch 20: val_loss did not improve from 0.03881\n",
      "89/89 [==============================] - 55s 616ms/step - loss: 0.0753 - dice_coef: 0.9247 - jaccard_distance: 0.8668 - precision: 0.9270 - recall: 0.9332 - val_loss: 0.1275 - val_dice_coef: 0.8725 - val_jaccard_distance: 0.7739 - val_precision: 0.8094 - val_recall: 0.9949 - lr: 5.0000e-04\n",
      "Epoch 21/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0804 - dice_coef: 0.9196 - jaccard_distance: 0.8589 - precision: 0.9270 - recall: 0.9204\n",
      "Epoch 21: val_loss did not improve from 0.03881\n",
      "89/89 [==============================] - 54s 609ms/step - loss: 0.0804 - dice_coef: 0.9196 - jaccard_distance: 0.8589 - precision: 0.9270 - recall: 0.9204 - val_loss: 0.0649 - val_dice_coef: 0.9351 - val_jaccard_distance: 0.8781 - val_precision: 0.8934 - val_recall: 0.9839 - lr: 5.0000e-04\n",
      "Epoch 22/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0714 - dice_coef: 0.9286 - jaccard_distance: 0.8744 - precision: 0.9378 - recall: 0.9338\n",
      "Epoch 22: val_loss did not improve from 0.03881\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "89/89 [==============================] - 57s 626ms/step - loss: 0.0714 - dice_coef: 0.9286 - jaccard_distance: 0.8744 - precision: 0.9378 - recall: 0.9338 - val_loss: 0.0552 - val_dice_coef: 0.9448 - val_jaccard_distance: 0.8954 - val_precision: 0.9736 - val_recall: 0.9208 - lr: 5.0000e-04\n",
      "Epoch 23/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0575 - dice_coef: 0.9425 - jaccard_distance: 0.8945 - precision: 0.9550 - recall: 0.9408\n",
      "Epoch 23: val_loss improved from 0.03881 to 0.03226, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 56s 628ms/step - loss: 0.0575 - dice_coef: 0.9425 - jaccard_distance: 0.8945 - precision: 0.9550 - recall: 0.9408 - val_loss: 0.0323 - val_dice_coef: 0.9677 - val_jaccard_distance: 0.9375 - val_precision: 0.9662 - val_recall: 0.9724 - lr: 2.5000e-04\n",
      "Epoch 24/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0539 - dice_coef: 0.9461 - jaccard_distance: 0.9019 - precision: 0.9449 - recall: 0.9539\n",
      "Epoch 24: val_loss improved from 0.03226 to 0.02868, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 56s 624ms/step - loss: 0.0539 - dice_coef: 0.9461 - jaccard_distance: 0.9019 - precision: 0.9449 - recall: 0.9539 - val_loss: 0.0287 - val_dice_coef: 0.9713 - val_jaccard_distance: 0.9442 - val_precision: 0.9680 - val_recall: 0.9775 - lr: 2.5000e-04\n",
      "Epoch 25/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0536 - dice_coef: 0.9464 - jaccard_distance: 0.9015 - precision: 0.9551 - recall: 0.9464\n",
      "Epoch 25: val_loss did not improve from 0.02868\n",
      "89/89 [==============================] - 60s 674ms/step - loss: 0.0536 - dice_coef: 0.9464 - jaccard_distance: 0.9015 - precision: 0.9551 - recall: 0.9464 - val_loss: 0.0477 - val_dice_coef: 0.9523 - val_jaccard_distance: 0.9089 - val_precision: 0.9690 - val_recall: 0.9383 - lr: 2.5000e-04\n",
      "Epoch 26/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0590 - dice_coef: 0.9410 - jaccard_distance: 0.8932 - precision: 0.9426 - recall: 0.9476\n",
      "Epoch 26: val_loss did not improve from 0.02868\n",
      "89/89 [==============================] - 61s 685ms/step - loss: 0.0590 - dice_coef: 0.9410 - jaccard_distance: 0.8932 - precision: 0.9426 - recall: 0.9476 - val_loss: 0.0307 - val_dice_coef: 0.9693 - val_jaccard_distance: 0.9404 - val_precision: 0.9620 - val_recall: 0.9794 - lr: 2.5000e-04\n",
      "Epoch 27/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0581 - dice_coef: 0.9419 - jaccard_distance: 0.8935 - precision: 0.9467 - recall: 0.9465\n",
      "Epoch 27: val_loss did not improve from 0.02868\n",
      "89/89 [==============================] - 58s 651ms/step - loss: 0.0581 - dice_coef: 0.9419 - jaccard_distance: 0.8935 - precision: 0.9467 - recall: 0.9465 - val_loss: 0.0324 - val_dice_coef: 0.9676 - val_jaccard_distance: 0.9373 - val_precision: 0.9514 - val_recall: 0.9865 - lr: 2.5000e-04\n",
      "Epoch 28/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0586 - dice_coef: 0.9414 - jaccard_distance: 0.8931 - precision: 0.9509 - recall: 0.9401\n",
      "Epoch 28: val_loss did not improve from 0.02868\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "89/89 [==============================] - 55s 615ms/step - loss: 0.0586 - dice_coef: 0.9414 - jaccard_distance: 0.8931 - precision: 0.9509 - recall: 0.9401 - val_loss: 0.0435 - val_dice_coef: 0.9565 - val_jaccard_distance: 0.9166 - val_precision: 0.9709 - val_recall: 0.9450 - lr: 2.5000e-04\n",
      "Epoch 29/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0509 - dice_coef: 0.9491 - jaccard_distance: 0.9055 - precision: 0.9562 - recall: 0.9503\n",
      "Epoch 29: val_loss did not improve from 0.02868\n",
      "89/89 [==============================] - 61s 684ms/step - loss: 0.0509 - dice_coef: 0.9491 - jaccard_distance: 0.9055 - precision: 0.9562 - recall: 0.9503 - val_loss: 0.0298 - val_dice_coef: 0.9702 - val_jaccard_distance: 0.9421 - val_precision: 0.9671 - val_recall: 0.9756 - lr: 1.2500e-04\n",
      "Epoch 30/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0521 - dice_coef: 0.9479 - jaccard_distance: 0.9044 - precision: 0.9491 - recall: 0.9556\n",
      "Epoch 30: val_loss improved from 0.02868 to 0.02817, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 55s 616ms/step - loss: 0.0521 - dice_coef: 0.9479 - jaccard_distance: 0.9044 - precision: 0.9491 - recall: 0.9556 - val_loss: 0.0282 - val_dice_coef: 0.9718 - val_jaccard_distance: 0.9452 - val_precision: 0.9654 - val_recall: 0.9807 - lr: 1.2500e-04\n",
      "Epoch 31/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0449 - dice_coef: 0.9551 - jaccard_distance: 0.9151 - precision: 0.9617 - recall: 0.9563\n",
      "Epoch 31: val_loss improved from 0.02817 to 0.02780, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 58s 650ms/step - loss: 0.0449 - dice_coef: 0.9551 - jaccard_distance: 0.9151 - precision: 0.9617 - recall: 0.9563 - val_loss: 0.0278 - val_dice_coef: 0.9722 - val_jaccard_distance: 0.9459 - val_precision: 0.9717 - val_recall: 0.9749 - lr: 1.2500e-04\n",
      "Epoch 32/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0518 - dice_coef: 0.9482 - jaccard_distance: 0.9044 - precision: 0.9554 - recall: 0.9470\n",
      "Epoch 32: val_loss improved from 0.02780 to 0.02777, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 57s 632ms/step - loss: 0.0518 - dice_coef: 0.9482 - jaccard_distance: 0.9044 - precision: 0.9554 - recall: 0.9470 - val_loss: 0.0278 - val_dice_coef: 0.9722 - val_jaccard_distance: 0.9460 - val_precision: 0.9733 - val_recall: 0.9732 - lr: 1.2500e-04\n",
      "Epoch 33/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0498 - dice_coef: 0.9502 - jaccard_distance: 0.9071 - precision: 0.9584 - recall: 0.9520\n",
      "Epoch 33: val_loss improved from 0.02777 to 0.02618, saving model to out/train/12-09-2022-20-43-29/unet.h5\n",
      "89/89 [==============================] - 59s 662ms/step - loss: 0.0498 - dice_coef: 0.9502 - jaccard_distance: 0.9071 - precision: 0.9584 - recall: 0.9520 - val_loss: 0.0262 - val_dice_coef: 0.9738 - val_jaccard_distance: 0.9490 - val_precision: 0.9704 - val_recall: 0.9795 - lr: 1.2500e-04\n",
      "Epoch 34/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0483 - dice_coef: 0.9517 - jaccard_distance: 0.9101 - precision: 0.9608 - recall: 0.9524\n",
      "Epoch 34: val_loss did not improve from 0.02618\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "89/89 [==============================] - 61s 680ms/step - loss: 0.0483 - dice_coef: 0.9517 - jaccard_distance: 0.9101 - precision: 0.9608 - recall: 0.9524 - val_loss: 0.0277 - val_dice_coef: 0.9723 - val_jaccard_distance: 0.9461 - val_precision: 0.9744 - val_recall: 0.9720 - lr: 1.2500e-04\n",
      "Epoch 35/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0468 - dice_coef: 0.9532 - jaccard_distance: 0.9123 - precision: 0.9612 - recall: 0.9528\n",
      "Epoch 35: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 59s 655ms/step - loss: 0.0468 - dice_coef: 0.9532 - jaccard_distance: 0.9123 - precision: 0.9612 - recall: 0.9528 - val_loss: 0.0305 - val_dice_coef: 0.9695 - val_jaccard_distance: 0.9408 - val_precision: 0.9763 - val_recall: 0.9649 - lr: 6.2500e-05\n",
      "Epoch 36/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0414 - dice_coef: 0.9586 - jaccard_distance: 0.9218 - precision: 0.9611 - recall: 0.9645\n",
      "Epoch 36: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 59s 664ms/step - loss: 0.0414 - dice_coef: 0.9586 - jaccard_distance: 0.9218 - precision: 0.9611 - recall: 0.9645 - val_loss: 0.0266 - val_dice_coef: 0.9734 - val_jaccard_distance: 0.9481 - val_precision: 0.9730 - val_recall: 0.9758 - lr: 6.2500e-05\n",
      "Epoch 37/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0494 - dice_coef: 0.9506 - jaccard_distance: 0.9084 - precision: 0.9598 - recall: 0.9472\n",
      "Epoch 37: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 55s 613ms/step - loss: 0.0494 - dice_coef: 0.9506 - jaccard_distance: 0.9084 - precision: 0.9598 - recall: 0.9472 - val_loss: 0.0298 - val_dice_coef: 0.9702 - val_jaccard_distance: 0.9421 - val_precision: 0.9772 - val_recall: 0.9652 - lr: 6.2500e-05\n",
      "Epoch 38/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0448 - dice_coef: 0.9552 - jaccard_distance: 0.9156 - precision: 0.9640 - recall: 0.9543\n",
      "Epoch 38: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 58s 657ms/step - loss: 0.0448 - dice_coef: 0.9552 - jaccard_distance: 0.9156 - precision: 0.9640 - recall: 0.9543 - val_loss: 0.0283 - val_dice_coef: 0.9717 - val_jaccard_distance: 0.9449 - val_precision: 0.9753 - val_recall: 0.9700 - lr: 6.2500e-05\n",
      "Epoch 39/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0476 - dice_coef: 0.9524 - jaccard_distance: 0.9115 - precision: 0.9589 - recall: 0.9538\n",
      "Epoch 39: val_loss did not improve from 0.02618\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "89/89 [==============================] - 54s 605ms/step - loss: 0.0476 - dice_coef: 0.9524 - jaccard_distance: 0.9115 - precision: 0.9589 - recall: 0.9538 - val_loss: 0.0273 - val_dice_coef: 0.9727 - val_jaccard_distance: 0.9469 - val_precision: 0.9765 - val_recall: 0.9709 - lr: 6.2500e-05\n",
      "Epoch 40/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0468 - dice_coef: 0.9532 - jaccard_distance: 0.9128 - precision: 0.9628 - recall: 0.9510\n",
      "Epoch 40: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 56s 635ms/step - loss: 0.0468 - dice_coef: 0.9532 - jaccard_distance: 0.9128 - precision: 0.9628 - recall: 0.9510 - val_loss: 0.0273 - val_dice_coef: 0.9727 - val_jaccard_distance: 0.9469 - val_precision: 0.9745 - val_recall: 0.9729 - lr: 3.1250e-05\n",
      "Epoch 41/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0442 - dice_coef: 0.9558 - jaccard_distance: 0.9168 - precision: 0.9626 - recall: 0.9565\n",
      "Epoch 41: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 58s 648ms/step - loss: 0.0442 - dice_coef: 0.9558 - jaccard_distance: 0.9168 - precision: 0.9626 - recall: 0.9565 - val_loss: 0.0273 - val_dice_coef: 0.9727 - val_jaccard_distance: 0.9469 - val_precision: 0.9738 - val_recall: 0.9737 - lr: 3.1250e-05\n",
      "Epoch 42/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0447 - dice_coef: 0.9553 - jaccard_distance: 0.9163 - precision: 0.9655 - recall: 0.9525\n",
      "Epoch 42: val_loss did not improve from 0.02618\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "89/89 [==============================] - 53s 598ms/step - loss: 0.0447 - dice_coef: 0.9553 - jaccard_distance: 0.9163 - precision: 0.9655 - recall: 0.9525 - val_loss: 0.0283 - val_dice_coef: 0.9717 - val_jaccard_distance: 0.9450 - val_precision: 0.9755 - val_recall: 0.9698 - lr: 3.1250e-05\n",
      "Epoch 43/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0436 - dice_coef: 0.9564 - jaccard_distance: 0.9182 - precision: 0.9619 - recall: 0.9568\n",
      "Epoch 43: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 52s 588ms/step - loss: 0.0436 - dice_coef: 0.9564 - jaccard_distance: 0.9182 - precision: 0.9619 - recall: 0.9568 - val_loss: 0.0280 - val_dice_coef: 0.9720 - val_jaccard_distance: 0.9456 - val_precision: 0.9747 - val_recall: 0.9712 - lr: 1.5625e-05\n",
      "Epoch 44/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0471 - dice_coef: 0.9529 - jaccard_distance: 0.9119 - precision: 0.9618 - recall: 0.9503\n",
      "Epoch 44: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 57s 636ms/step - loss: 0.0471 - dice_coef: 0.9529 - jaccard_distance: 0.9119 - precision: 0.9618 - recall: 0.9503 - val_loss: 0.0282 - val_dice_coef: 0.9718 - val_jaccard_distance: 0.9451 - val_precision: 0.9767 - val_recall: 0.9687 - lr: 1.5625e-05\n",
      "Epoch 45/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0403 - dice_coef: 0.9597 - jaccard_distance: 0.9232 - precision: 0.9683 - recall: 0.9570\n",
      "Epoch 45: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 56s 620ms/step - loss: 0.0403 - dice_coef: 0.9597 - jaccard_distance: 0.9232 - precision: 0.9683 - recall: 0.9570 - val_loss: 0.0277 - val_dice_coef: 0.9723 - val_jaccard_distance: 0.9462 - val_precision: 0.9772 - val_recall: 0.9694 - lr: 1.5625e-05\n",
      "Epoch 46/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0454 - dice_coef: 0.9546 - jaccard_distance: 0.9146 - precision: 0.9644 - recall: 0.9533\n",
      "Epoch 46: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 62s 690ms/step - loss: 0.0454 - dice_coef: 0.9546 - jaccard_distance: 0.9146 - precision: 0.9644 - recall: 0.9533 - val_loss: 0.0277 - val_dice_coef: 0.9723 - val_jaccard_distance: 0.9461 - val_precision: 0.9761 - val_recall: 0.9704 - lr: 1.5625e-05\n",
      "Epoch 47/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0485 - dice_coef: 0.9515 - jaccard_distance: 0.9107 - precision: 0.9655 - recall: 0.9456\n",
      "Epoch 47: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 61s 692ms/step - loss: 0.0485 - dice_coef: 0.9515 - jaccard_distance: 0.9107 - precision: 0.9655 - recall: 0.9456 - val_loss: 0.0277 - val_dice_coef: 0.9723 - val_jaccard_distance: 0.9461 - val_precision: 0.9756 - val_recall: 0.9709 - lr: 1.5625e-05\n",
      "Epoch 48/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0468 - dice_coef: 0.9532 - jaccard_distance: 0.9131 - precision: 0.9567 - recall: 0.9568\n",
      "Epoch 48: val_loss did not improve from 0.02618\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "89/89 [==============================] - 59s 661ms/step - loss: 0.0468 - dice_coef: 0.9532 - jaccard_distance: 0.9131 - precision: 0.9567 - recall: 0.9568 - val_loss: 0.0275 - val_dice_coef: 0.9725 - val_jaccard_distance: 0.9465 - val_precision: 0.9760 - val_recall: 0.9709 - lr: 1.5625e-05\n",
      "Epoch 49/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0455 - dice_coef: 0.9545 - jaccard_distance: 0.9159 - precision: 0.9613 - recall: 0.9549\n",
      "Epoch 49: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 57s 637ms/step - loss: 0.0455 - dice_coef: 0.9545 - jaccard_distance: 0.9159 - precision: 0.9613 - recall: 0.9549 - val_loss: 0.0273 - val_dice_coef: 0.9727 - val_jaccard_distance: 0.9469 - val_precision: 0.9745 - val_recall: 0.9728 - lr: 7.8125e-06\n",
      "Epoch 50/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0484 - dice_coef: 0.9516 - jaccard_distance: 0.9102 - precision: 0.9572 - recall: 0.9536\n",
      "Epoch 50: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 61s 678ms/step - loss: 0.0484 - dice_coef: 0.9516 - jaccard_distance: 0.9102 - precision: 0.9572 - recall: 0.9536 - val_loss: 0.0274 - val_dice_coef: 0.9726 - val_jaccard_distance: 0.9467 - val_precision: 0.9748 - val_recall: 0.9723 - lr: 7.8125e-06\n",
      "Epoch 51/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0462 - dice_coef: 0.9538 - jaccard_distance: 0.9139 - precision: 0.9587 - recall: 0.9548\n",
      "Epoch 51: val_loss did not improve from 0.02618\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "89/89 [==============================] - 60s 674ms/step - loss: 0.0462 - dice_coef: 0.9538 - jaccard_distance: 0.9139 - precision: 0.9587 - recall: 0.9548 - val_loss: 0.0271 - val_dice_coef: 0.9729 - val_jaccard_distance: 0.9473 - val_precision: 0.9751 - val_recall: 0.9725 - lr: 7.8125e-06\n",
      "Epoch 52/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0439 - dice_coef: 0.9561 - jaccard_distance: 0.9172 - precision: 0.9646 - recall: 0.9569\n",
      "Epoch 52: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 58s 653ms/step - loss: 0.0439 - dice_coef: 0.9561 - jaccard_distance: 0.9172 - precision: 0.9646 - recall: 0.9569 - val_loss: 0.0272 - val_dice_coef: 0.9728 - val_jaccard_distance: 0.9470 - val_precision: 0.9755 - val_recall: 0.9719 - lr: 3.9063e-06\n",
      "Epoch 53/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0493 - dice_coef: 0.9507 - jaccard_distance: 0.9083 - precision: 0.9580 - recall: 0.9533\n",
      "Epoch 53: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 63s 702ms/step - loss: 0.0493 - dice_coef: 0.9507 - jaccard_distance: 0.9083 - precision: 0.9580 - recall: 0.9533 - val_loss: 0.0269 - val_dice_coef: 0.9731 - val_jaccard_distance: 0.9476 - val_precision: 0.9762 - val_recall: 0.9717 - lr: 3.9063e-06\n",
      "Epoch 54/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0441 - dice_coef: 0.9559 - jaccard_distance: 0.9171 - precision: 0.9621 - recall: 0.9548\n",
      "Epoch 54: val_loss did not improve from 0.02618\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "89/89 [==============================] - 69s 766ms/step - loss: 0.0441 - dice_coef: 0.9559 - jaccard_distance: 0.9171 - precision: 0.9621 - recall: 0.9548 - val_loss: 0.0265 - val_dice_coef: 0.9735 - val_jaccard_distance: 0.9484 - val_precision: 0.9768 - val_recall: 0.9721 - lr: 3.9063e-06\n",
      "Epoch 55/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0452 - dice_coef: 0.9548 - jaccard_distance: 0.9164 - precision: 0.9582 - recall: 0.9601\n",
      "Epoch 55: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 55s 614ms/step - loss: 0.0452 - dice_coef: 0.9548 - jaccard_distance: 0.9164 - precision: 0.9582 - recall: 0.9601 - val_loss: 0.0269 - val_dice_coef: 0.9731 - val_jaccard_distance: 0.9476 - val_precision: 0.9766 - val_recall: 0.9714 - lr: 1.9531e-06\n",
      "Epoch 56/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0429 - dice_coef: 0.9571 - jaccard_distance: 0.9189 - precision: 0.9658 - recall: 0.9553\n",
      "Epoch 56: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 54s 612ms/step - loss: 0.0429 - dice_coef: 0.9571 - jaccard_distance: 0.9189 - precision: 0.9658 - recall: 0.9553 - val_loss: 0.0270 - val_dice_coef: 0.9730 - val_jaccard_distance: 0.9474 - val_precision: 0.9758 - val_recall: 0.9720 - lr: 1.9531e-06\n",
      "Epoch 57/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0487 - dice_coef: 0.9513 - jaccard_distance: 0.9107 - precision: 0.9608 - recall: 0.9511\n",
      "Epoch 57: val_loss did not improve from 0.02618\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "89/89 [==============================] - 58s 654ms/step - loss: 0.0487 - dice_coef: 0.9513 - jaccard_distance: 0.9107 - precision: 0.9608 - recall: 0.9511 - val_loss: 0.0273 - val_dice_coef: 0.9727 - val_jaccard_distance: 0.9468 - val_precision: 0.9761 - val_recall: 0.9711 - lr: 1.9531e-06\n",
      "Epoch 58/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0393 - dice_coef: 0.9607 - jaccard_distance: 0.9254 - precision: 0.9667 - recall: 0.9640\n",
      "Epoch 58: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 59s 659ms/step - loss: 0.0393 - dice_coef: 0.9607 - jaccard_distance: 0.9254 - precision: 0.9667 - recall: 0.9640 - val_loss: 0.0273 - val_dice_coef: 0.9727 - val_jaccard_distance: 0.9468 - val_precision: 0.9756 - val_recall: 0.9715 - lr: 9.7656e-07\n",
      "Epoch 59/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0452 - dice_coef: 0.9548 - jaccard_distance: 0.9166 - precision: 0.9606 - recall: 0.9581\n",
      "Epoch 59: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 60s 673ms/step - loss: 0.0452 - dice_coef: 0.9548 - jaccard_distance: 0.9166 - precision: 0.9606 - recall: 0.9581 - val_loss: 0.0274 - val_dice_coef: 0.9726 - val_jaccard_distance: 0.9467 - val_precision: 0.9757 - val_recall: 0.9714 - lr: 9.7656e-07\n",
      "Epoch 60/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0397 - dice_coef: 0.9603 - jaccard_distance: 0.9243 - precision: 0.9677 - recall: 0.9595\n",
      "Epoch 60: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 64s 721ms/step - loss: 0.0397 - dice_coef: 0.9603 - jaccard_distance: 0.9243 - precision: 0.9677 - recall: 0.9595 - val_loss: 0.0269 - val_dice_coef: 0.9731 - val_jaccard_distance: 0.9476 - val_precision: 0.9757 - val_recall: 0.9723 - lr: 9.7656e-07\n",
      "Epoch 61/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0421 - dice_coef: 0.9579 - jaccard_distance: 0.9203 - precision: 0.9656 - recall: 0.9586\n",
      "Epoch 61: val_loss did not improve from 0.02618\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "89/89 [==============================] - 56s 624ms/step - loss: 0.0421 - dice_coef: 0.9579 - jaccard_distance: 0.9203 - precision: 0.9656 - recall: 0.9586 - val_loss: 0.0271 - val_dice_coef: 0.9729 - val_jaccard_distance: 0.9473 - val_precision: 0.9761 - val_recall: 0.9715 - lr: 9.7656e-07\n",
      "Epoch 62/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0427 - dice_coef: 0.9573 - jaccard_distance: 0.9193 - precision: 0.9651 - recall: 0.9563\n",
      "Epoch 62: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 61s 685ms/step - loss: 0.0427 - dice_coef: 0.9573 - jaccard_distance: 0.9193 - precision: 0.9651 - recall: 0.9563 - val_loss: 0.0273 - val_dice_coef: 0.9727 - val_jaccard_distance: 0.9469 - val_precision: 0.9758 - val_recall: 0.9715 - lr: 4.8828e-07\n",
      "Epoch 63/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0420 - dice_coef: 0.9580 - jaccard_distance: 0.9206 - precision: 0.9618 - recall: 0.9628\n",
      "Epoch 63: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 61s 684ms/step - loss: 0.0420 - dice_coef: 0.9580 - jaccard_distance: 0.9206 - precision: 0.9618 - recall: 0.9628 - val_loss: 0.0271 - val_dice_coef: 0.9729 - val_jaccard_distance: 0.9473 - val_precision: 0.9759 - val_recall: 0.9718 - lr: 4.8828e-07\n",
      "Epoch 64/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0429 - dice_coef: 0.9571 - jaccard_distance: 0.9188 - precision: 0.9654 - recall: 0.9559\n",
      "Epoch 64: val_loss did not improve from 0.02618\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "89/89 [==============================] - 67s 750ms/step - loss: 0.0429 - dice_coef: 0.9571 - jaccard_distance: 0.9188 - precision: 0.9654 - recall: 0.9559 - val_loss: 0.0272 - val_dice_coef: 0.9728 - val_jaccard_distance: 0.9471 - val_precision: 0.9771 - val_recall: 0.9704 - lr: 4.8828e-07\n",
      "Epoch 65/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0440 - dice_coef: 0.9560 - jaccard_distance: 0.9173 - precision: 0.9648 - recall: 0.9523\n",
      "Epoch 65: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 57s 648ms/step - loss: 0.0440 - dice_coef: 0.9560 - jaccard_distance: 0.9173 - precision: 0.9648 - recall: 0.9523 - val_loss: 0.0271 - val_dice_coef: 0.9729 - val_jaccard_distance: 0.9473 - val_precision: 0.9761 - val_recall: 0.9716 - lr: 2.4414e-07\n",
      "Epoch 66/75\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0488 - dice_coef: 0.9512 - jaccard_distance: 0.9100 - precision: 0.9581 - recall: 0.9536\n",
      "Epoch 66: val_loss did not improve from 0.02618\n",
      "89/89 [==============================] - 57s 638ms/step - loss: 0.0488 - dice_coef: 0.9512 - jaccard_distance: 0.9100 - precision: 0.9581 - recall: 0.9536 - val_loss: 0.0272 - val_dice_coef: 0.9728 - val_jaccard_distance: 0.9470 - val_precision: 0.9756 - val_recall: 0.9718 - lr: 2.4414e-07\n",
      "Epoch 67/75\n",
      "52/89 [================>.............] - ETA: 26s - loss: 0.0416 - dice_coef: 0.9584 - jaccard_distance: 0.9211 - precision: 0.9650 - recall: 0.9579"
     ]
    }
   ],
   "source": [
    "current_datetime = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "path_model = os.path.join(cfg[\"path_out\"], \"train\", current_datetime)\n",
    "pathlib.Path(path_model).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "augment = Compose([\n",
    "    HorizontalFlip(),\n",
    "    ShiftScaleRotate(rotate_limit=45, border_mode=cv2.BORDER_CONSTANT),\n",
    "    ElasticTransform(border_mode=cv2.BORDER_CONSTANT),\n",
    "    RandomBrightness(),\n",
    "    RandomContrast(),\n",
    "    RandomGamma()\n",
    "])\n",
    "steps_per_epoch = math.ceil(x_train.shape[0] / cfg[\"batch_size\"])\n",
    "train_generator = AugmentationSequence(x_train, y_train, cfg[\"batch_size\"], augment)\n",
    "reduce_learning_rate = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=3, verbose=1)\n",
    "filename_model = os.path.join(path_model, \"unet.h5\")\n",
    "checkpointer = tensorflow.keras.callbacks.ModelCheckpoint(filename_model, verbose=1, save_best_only=True)\n",
    "strategy = tensorflow.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = unet_model(cfg)\n",
    "    adam_opt = tensorflow.keras.optimizers.Adam(learning_rate=cfg[\"learning_rate\"])\n",
    "    model.compile(optimizer=adam_opt, loss=get_loss_function(cfg[\"loss_function\"]), metrics=[dice_coef, jaccard_distance, tensorflow.keras.metrics.Precision(), tensorflow.keras.metrics.Recall()])\n",
    "\n",
    "tensorflow.keras.backend.clear_session()\n",
    "start_time = time.time()\n",
    "fit = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cfg[\"epochs\"], validation_data=(x_val, y_val), callbacks=[checkpointer, reduce_learning_rate])\n",
    "end_time = time.time() - start_time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = [\"batch_size\", \"epochs\", \"learning_rate\", \"loss_function\", \"images\", \"masks\", \"len_images\", \"len_masks\", \"channel\", \"image_size\", \"fold\", \"test_size\", \"val_size\", \"random_state\", \"path_dataset\", \"path_out\", \"data_augmentation\", \"filename_script\", \"time\"]\n",
    "data = [cfg[\"batch_size\"], cfg[\"epochs\"], cfg[\"learning_rate\"], cfg[\"loss_function\"], images_folder, masks_folder, len(list_images), len(list_labels), cfg[\"channel\"], cfg[\"image_size\"], cfg[\"fold\"], cfg[\"test_size\"], cfg[\"val_size\"], cfg[\"random_state\"], cfg[\"path_dataset\"], cfg[\"path_out\"], cfg[\"data_augmentation\"], ipynbname.name(), time.strftime(\"%H:%M:%S\", time.gmtime(end_time))]\n",
    "\n",
    "dataframe_cfg = pandas.DataFrame(data, columns)\n",
    "dataframe_cfg = dataframe_cfg.applymap(lambda x: str(x).replace(\".\", \",\") if isinstance(x,float) else x)\n",
    "dataframe_cfg.to_csv(os.path.join(path_model, \"cfg.csv\"), decimal=\",\", sep=\";\", na_rep=\" \", header=False, quoting=csv.QUOTE_ALL)\n",
    "dataframe_cfg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}