{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import ipynbname\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "import pathlib\n",
    "import skimage.io\n",
    "import sklearn.model_selection\n",
    "import tensorflow\n",
    "import time\n",
    "\n",
    "from metrics import dice_coef, jaccard_distance\n",
    "from model import unet_model, get_loss_function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"channel\": 3,\n",
    "    \"batch_size\": 4,\n",
    "    \"fold\": 5,\n",
    "    \"epochs\": 75,\n",
    "    \"image_size\": 512,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"random_state\": 1234,\n",
    "    \"test_size\": 0.2,\n",
    "    \"val_size\": 0.05,\n",
    "    \"path_dataset\": \"dataset\",\n",
    "    \"path_out\": \"out\",\n",
    "    \"loss_function\": \"dice\",\n",
    "    \"data_augmentation\": False\n",
    "}\n",
    "images_folder = os.path.join(cfg[\"path_dataset\"], \"IMAGEM_ORIGINAL\", \"CONVERTIDAS\", \"RGB\", \"512\", \"OUT\")\n",
    "masks_folder = os.path.join(cfg[\"path_dataset\"], \"MASK\", \"BITMAP\", \"512\", \"OUT\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(300, 75)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_images = sorted(list([file for file in pathlib.Path(images_folder).rglob(\"*\")]))\n",
    "list_masks = sorted(list([file for file in pathlib.Path(masks_folder).rglob(\"*\")]))\n",
    "\n",
    "x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(list_images, list_masks, test_size=cfg[\"test_size\"], random_state=cfg[\"random_state\"])\n",
    "len(x_train), len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class CreateSequence(tensorflow.keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
    "        x = numpy.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            img = skimage.io.imread(path)\n",
    "            img = numpy.float32(img/255)\n",
    "            x[j] = img\n",
    "        y = numpy.zeros((self.batch_size,) + self.img_size, dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            img = skimage.io.imread(path)\n",
    "            img = numpy.float32(img/255)\n",
    "            y[j] = img\n",
    "        return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_data = CreateSequence(cfg[\"batch_size\"], (cfg[\"image_size\"], cfg[\"image_size\"]), list_images, list_masks)\n",
    "val_data = CreateSequence(cfg[\"batch_size\"], (cfg[\"image_size\"], cfg[\"image_size\"]), x_val, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 19:15:45.636781: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_83038\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\023FlatMapDataset:1525\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - ETA: 0s - loss: 0.6058 - dice_coef: 0.3942 - jaccard_distance: 0.2551 - precision: 0.3768 - recall: 0.9559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 19:15:52.140092: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_88499\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\023FlatMapDataset:1547\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.71720, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 9s 418ms/step - loss: 0.6058 - dice_coef: 0.3942 - jaccard_distance: 0.2551 - precision: 0.3768 - recall: 0.9559 - val_loss: 0.7172 - val_dice_coef: 0.2828 - val_jaccard_distance: 0.1658 - val_precision: 0.4646 - val_recall: 0.1234 - lr: 0.0010\n",
      "Epoch 2/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5109 - dice_coef: 0.4891 - jaccard_distance: 0.3340 - precision: 0.5642 - recall: 0.9685\n",
      "Epoch 2: val_loss improved from 0.71720 to 0.71691, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 280ms/step - loss: 0.5109 - dice_coef: 0.4891 - jaccard_distance: 0.3340 - precision: 0.5642 - recall: 0.9685 - val_loss: 0.7169 - val_dice_coef: 0.2831 - val_jaccard_distance: 0.1665 - val_precision: 0.2916 - val_recall: 0.0557 - lr: 0.0010\n",
      "Epoch 3/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4961 - dice_coef: 0.5039 - jaccard_distance: 0.3502 - precision: 0.5921 - recall: 0.9755\n",
      "Epoch 3: val_loss did not improve from 0.71691\n",
      "12/12 [==============================] - 3s 229ms/step - loss: 0.4961 - dice_coef: 0.5039 - jaccard_distance: 0.3502 - precision: 0.5921 - recall: 0.9755 - val_loss: 0.7195 - val_dice_coef: 0.2805 - val_jaccard_distance: 0.1650 - val_precision: 0.3901 - val_recall: 0.0887 - lr: 0.0010\n",
      "Epoch 4/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4649 - dice_coef: 0.5351 - jaccard_distance: 0.3812 - precision: 0.6298 - recall: 0.9756\n",
      "Epoch 4: val_loss improved from 0.71691 to 0.70762, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 0.4649 - dice_coef: 0.5351 - jaccard_distance: 0.3812 - precision: 0.6298 - recall: 0.9756 - val_loss: 0.7076 - val_dice_coef: 0.2924 - val_jaccard_distance: 0.1742 - val_precision: 0.4777 - val_recall: 0.1589 - lr: 0.0010\n",
      "Epoch 5/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4469 - dice_coef: 0.5531 - jaccard_distance: 0.4023 - precision: 0.6340 - recall: 0.9941\n",
      "Epoch 5: val_loss improved from 0.70762 to 0.66372, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 272ms/step - loss: 0.4469 - dice_coef: 0.5531 - jaccard_distance: 0.4023 - precision: 0.6340 - recall: 0.9941 - val_loss: 0.6637 - val_dice_coef: 0.3363 - val_jaccard_distance: 0.2067 - val_precision: 0.5617 - val_recall: 0.2906 - lr: 0.0010\n",
      "Epoch 6/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3564 - dice_coef: 0.6436 - jaccard_distance: 0.4804 - precision: 0.7135 - recall: 0.9449\n",
      "Epoch 6: val_loss improved from 0.66372 to 0.61910, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 0.3564 - dice_coef: 0.6436 - jaccard_distance: 0.4804 - precision: 0.7135 - recall: 0.9449 - val_loss: 0.6191 - val_dice_coef: 0.3809 - val_jaccard_distance: 0.2406 - val_precision: 0.6206 - val_recall: 0.3843 - lr: 0.0010\n",
      "Epoch 7/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4801 - dice_coef: 0.5199 - jaccard_distance: 0.3714 - precision: 0.6459 - recall: 0.9831\n",
      "Epoch 7: val_loss improved from 0.61910 to 0.51596, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.4801 - dice_coef: 0.5199 - jaccard_distance: 0.3714 - precision: 0.6459 - recall: 0.9831 - val_loss: 0.5160 - val_dice_coef: 0.4840 - val_jaccard_distance: 0.3284 - val_precision: 0.6788 - val_recall: 0.6652 - lr: 0.0010\n",
      "Epoch 8/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3907 - dice_coef: 0.6093 - jaccard_distance: 0.4480 - precision: 0.6975 - recall: 0.9644\n",
      "Epoch 8: val_loss improved from 0.51596 to 0.50267, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 266ms/step - loss: 0.3907 - dice_coef: 0.6093 - jaccard_distance: 0.4480 - precision: 0.6975 - recall: 0.9644 - val_loss: 0.5027 - val_dice_coef: 0.4973 - val_jaccard_distance: 0.3394 - val_precision: 0.5895 - val_recall: 0.7508 - lr: 0.0010\n",
      "Epoch 9/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3198 - dice_coef: 0.6802 - jaccard_distance: 0.5445 - precision: 0.7827 - recall: 0.9831\n",
      "Epoch 9: val_loss improved from 0.50267 to 0.46904, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 250ms/step - loss: 0.3198 - dice_coef: 0.6802 - jaccard_distance: 0.5445 - precision: 0.7827 - recall: 0.9831 - val_loss: 0.4690 - val_dice_coef: 0.5310 - val_jaccard_distance: 0.3718 - val_precision: 0.7037 - val_recall: 0.7335 - lr: 0.0010\n",
      "Epoch 10/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3556 - dice_coef: 0.6444 - jaccard_distance: 0.5054 - precision: 0.7770 - recall: 0.9861\n",
      "Epoch 10: val_loss improved from 0.46904 to 0.42683, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 261ms/step - loss: 0.3556 - dice_coef: 0.6444 - jaccard_distance: 0.5054 - precision: 0.7770 - recall: 0.9861 - val_loss: 0.4268 - val_dice_coef: 0.5732 - val_jaccard_distance: 0.4119 - val_precision: 0.7260 - val_recall: 0.8082 - lr: 0.0010\n",
      "Epoch 11/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3952 - dice_coef: 0.6048 - jaccard_distance: 0.4541 - precision: 0.7167 - recall: 0.9448\n",
      "Epoch 11: val_loss improved from 0.42683 to 0.42585, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 258ms/step - loss: 0.3952 - dice_coef: 0.6048 - jaccard_distance: 0.4541 - precision: 0.7167 - recall: 0.9448 - val_loss: 0.4259 - val_dice_coef: 0.5741 - val_jaccard_distance: 0.4082 - val_precision: 0.5447 - val_recall: 0.9425 - lr: 0.0010\n",
      "Epoch 12/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3785 - dice_coef: 0.6215 - jaccard_distance: 0.4744 - precision: 0.7160 - recall: 0.9543\n",
      "Epoch 12: val_loss improved from 0.42585 to 0.38902, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "12/12 [==============================] - 3s 254ms/step - loss: 0.3785 - dice_coef: 0.6215 - jaccard_distance: 0.4744 - precision: 0.7160 - recall: 0.9543 - val_loss: 0.3890 - val_dice_coef: 0.6110 - val_jaccard_distance: 0.4479 - val_precision: 0.6624 - val_recall: 0.8998 - lr: 0.0010\n",
      "Epoch 13/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3735 - dice_coef: 0.6265 - jaccard_distance: 0.4900 - precision: 0.7242 - recall: 0.9517\n",
      "Epoch 13: val_loss improved from 0.38902 to 0.37424, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 268ms/step - loss: 0.3735 - dice_coef: 0.6265 - jaccard_distance: 0.4900 - precision: 0.7242 - recall: 0.9517 - val_loss: 0.3742 - val_dice_coef: 0.6258 - val_jaccard_distance: 0.4632 - val_precision: 0.6656 - val_recall: 0.9113 - lr: 5.0000e-04\n",
      "Epoch 14/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3012 - dice_coef: 0.6988 - jaccard_distance: 0.5628 - precision: 0.7958 - recall: 0.9729\n",
      "Epoch 14: val_loss improved from 0.37424 to 0.35079, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 251ms/step - loss: 0.3012 - dice_coef: 0.6988 - jaccard_distance: 0.5628 - precision: 0.7958 - recall: 0.9729 - val_loss: 0.3508 - val_dice_coef: 0.6492 - val_jaccard_distance: 0.4880 - val_precision: 0.6846 - val_recall: 0.9350 - lr: 5.0000e-04\n",
      "Epoch 15/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3308 - dice_coef: 0.6692 - jaccard_distance: 0.5359 - precision: 0.7990 - recall: 0.9728\n",
      "Epoch 15: val_loss improved from 0.35079 to 0.33310, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 261ms/step - loss: 0.3308 - dice_coef: 0.6692 - jaccard_distance: 0.5359 - precision: 0.7990 - recall: 0.9728 - val_loss: 0.3331 - val_dice_coef: 0.6669 - val_jaccard_distance: 0.5078 - val_precision: 0.7146 - val_recall: 0.9426 - lr: 5.0000e-04\n",
      "Epoch 16/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2358 - dice_coef: 0.7642 - jaccard_distance: 0.6415 - precision: 0.8194 - recall: 0.9863\n",
      "Epoch 16: val_loss improved from 0.33310 to 0.31321, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 257ms/step - loss: 0.2358 - dice_coef: 0.7642 - jaccard_distance: 0.6415 - precision: 0.8194 - recall: 0.9863 - val_loss: 0.3132 - val_dice_coef: 0.6868 - val_jaccard_distance: 0.5300 - val_precision: 0.7104 - val_recall: 0.9590 - lr: 5.0000e-04\n",
      "Epoch 17/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3566 - dice_coef: 0.6434 - jaccard_distance: 0.5101 - precision: 0.7806 - recall: 0.9583\n",
      "Epoch 17: val_loss improved from 0.31321 to 0.27663, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 261ms/step - loss: 0.3566 - dice_coef: 0.6434 - jaccard_distance: 0.5101 - precision: 0.7806 - recall: 0.9583 - val_loss: 0.2766 - val_dice_coef: 0.7234 - val_jaccard_distance: 0.5716 - val_precision: 0.7876 - val_recall: 0.9731 - lr: 5.0000e-04\n",
      "Epoch 18/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2305 - dice_coef: 0.7695 - jaccard_distance: 0.6452 - precision: 0.8876 - recall: 0.9564\n",
      "Epoch 18: val_loss improved from 0.27663 to 0.26641, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 262ms/step - loss: 0.2305 - dice_coef: 0.7695 - jaccard_distance: 0.6452 - precision: 0.8876 - recall: 0.9564 - val_loss: 0.2664 - val_dice_coef: 0.7336 - val_jaccard_distance: 0.5858 - val_precision: 0.8162 - val_recall: 0.9591 - lr: 5.0000e-04\n",
      "Epoch 19/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2811 - dice_coef: 0.7189 - jaccard_distance: 0.5882 - precision: 0.8319 - recall: 0.9576\n",
      "Epoch 19: val_loss did not improve from 0.26641\n",
      "12/12 [==============================] - 3s 255ms/step - loss: 0.2811 - dice_coef: 0.7189 - jaccard_distance: 0.5882 - precision: 0.8319 - recall: 0.9576 - val_loss: 0.2811 - val_dice_coef: 0.7189 - val_jaccard_distance: 0.5675 - val_precision: 0.7336 - val_recall: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 20/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2487 - dice_coef: 0.7513 - jaccard_distance: 0.6362 - precision: 0.8827 - recall: 0.9753\n",
      "Epoch 20: val_loss improved from 0.26641 to 0.24322, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 299ms/step - loss: 0.2487 - dice_coef: 0.7513 - jaccard_distance: 0.6362 - precision: 0.8827 - recall: 0.9753 - val_loss: 0.2432 - val_dice_coef: 0.7568 - val_jaccard_distance: 0.6144 - val_precision: 0.8251 - val_recall: 0.9723 - lr: 5.0000e-04\n",
      "Epoch 21/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2449 - dice_coef: 0.7551 - jaccard_distance: 0.6296 - precision: 0.8603 - recall: 0.9662\n",
      "Epoch 21: val_loss improved from 0.24322 to 0.22924, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "12/12 [==============================] - 3s 269ms/step - loss: 0.2449 - dice_coef: 0.7551 - jaccard_distance: 0.6296 - precision: 0.8603 - recall: 0.9662 - val_loss: 0.2292 - val_dice_coef: 0.7708 - val_jaccard_distance: 0.6321 - val_precision: 0.8419 - val_recall: 0.9721 - lr: 5.0000e-04\n",
      "Epoch 22/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2277 - dice_coef: 0.7723 - jaccard_distance: 0.6535 - precision: 0.8870 - recall: 0.9541\n",
      "Epoch 22: val_loss improved from 0.22924 to 0.21984, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 259ms/step - loss: 0.2277 - dice_coef: 0.7723 - jaccard_distance: 0.6535 - precision: 0.8870 - recall: 0.9541 - val_loss: 0.2198 - val_dice_coef: 0.7802 - val_jaccard_distance: 0.6444 - val_precision: 0.8814 - val_recall: 0.9557 - lr: 2.5000e-04\n",
      "Epoch 23/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2399 - dice_coef: 0.7601 - jaccard_distance: 0.6438 - precision: 0.8596 - recall: 0.9933\n",
      "Epoch 23: val_loss improved from 0.21984 to 0.21178, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 270ms/step - loss: 0.2399 - dice_coef: 0.7601 - jaccard_distance: 0.6438 - precision: 0.8596 - recall: 0.9933 - val_loss: 0.2118 - val_dice_coef: 0.7882 - val_jaccard_distance: 0.6542 - val_precision: 0.8679 - val_recall: 0.9705 - lr: 2.5000e-04\n",
      "Epoch 24/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2363 - dice_coef: 0.7637 - jaccard_distance: 0.6513 - precision: 0.8988 - recall: 0.9712\n",
      "Epoch 24: val_loss improved from 0.21178 to 0.20731, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 243ms/step - loss: 0.2363 - dice_coef: 0.7637 - jaccard_distance: 0.6513 - precision: 0.8988 - recall: 0.9712 - val_loss: 0.2073 - val_dice_coef: 0.7927 - val_jaccard_distance: 0.6597 - val_precision: 0.8582 - val_recall: 0.9836 - lr: 2.5000e-04\n",
      "Epoch 25/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1949 - dice_coef: 0.8051 - jaccard_distance: 0.6945 - precision: 0.9110 - recall: 0.9623\n",
      "Epoch 25: val_loss improved from 0.20731 to 0.20317, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 256ms/step - loss: 0.1949 - dice_coef: 0.8051 - jaccard_distance: 0.6945 - precision: 0.9110 - recall: 0.9623 - val_loss: 0.2032 - val_dice_coef: 0.7968 - val_jaccard_distance: 0.6662 - val_precision: 0.8744 - val_recall: 0.9732 - lr: 2.5000e-04\n",
      "Epoch 26/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2488 - dice_coef: 0.7512 - jaccard_distance: 0.6280 - precision: 0.8701 - recall: 0.9840\n",
      "Epoch 26: val_loss improved from 0.20317 to 0.19165, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 264ms/step - loss: 0.2488 - dice_coef: 0.7512 - jaccard_distance: 0.6280 - precision: 0.8701 - recall: 0.9840 - val_loss: 0.1916 - val_dice_coef: 0.8084 - val_jaccard_distance: 0.6815 - val_precision: 0.8969 - val_recall: 0.9739 - lr: 2.5000e-04\n",
      "Epoch 27/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2696 - dice_coef: 0.7304 - jaccard_distance: 0.6106 - precision: 0.8470 - recall: 0.9820\n",
      "Epoch 27: val_loss improved from 0.19165 to 0.18868, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 3s 265ms/step - loss: 0.2696 - dice_coef: 0.7304 - jaccard_distance: 0.6106 - precision: 0.8470 - recall: 0.9820 - val_loss: 0.1887 - val_dice_coef: 0.8113 - val_jaccard_distance: 0.6856 - val_precision: 0.9045 - val_recall: 0.9673 - lr: 2.5000e-04\n",
      "Epoch 28/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1352 - dice_coef: 0.8648 - jaccard_distance: 0.7668 - precision: 0.9421 - recall: 0.9656\n",
      "Epoch 28: val_loss did not improve from 0.18868\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 0.1352 - dice_coef: 0.8648 - jaccard_distance: 0.7668 - precision: 0.9421 - recall: 0.9656 - val_loss: 0.2210 - val_dice_coef: 0.7790 - val_jaccard_distance: 0.6442 - val_precision: 0.9162 - val_recall: 0.8805 - lr: 2.5000e-04\n",
      "Epoch 29/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1742 - dice_coef: 0.8258 - jaccard_distance: 0.7288 - precision: 0.9156 - recall: 0.9770\n",
      "Epoch 29: val_loss did not improve from 0.18868\n",
      "12/12 [==============================] - 3s 273ms/step - loss: 0.1742 - dice_coef: 0.8258 - jaccard_distance: 0.7288 - precision: 0.9156 - recall: 0.9770 - val_loss: 0.1907 - val_dice_coef: 0.8093 - val_jaccard_distance: 0.6839 - val_precision: 0.9102 - val_recall: 0.9351 - lr: 2.5000e-04\n",
      "Epoch 30/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2168 - dice_coef: 0.7832 - jaccard_distance: 0.6591 - precision: 0.8918 - recall: 0.9620\n",
      "Epoch 30: val_loss improved from 0.18868 to 0.17220, saving model to out/train/12-09-2022-19-15-44/unet.h5\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 0.2168 - dice_coef: 0.7832 - jaccard_distance: 0.6591 - precision: 0.8918 - recall: 0.9620 - val_loss: 0.1722 - val_dice_coef: 0.8278 - val_jaccard_distance: 0.7094 - val_precision: 0.9163 - val_recall: 0.9697 - lr: 2.5000e-04\n",
      "Epoch 31/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2763 - dice_coef: 0.7237 - jaccard_distance: 0.6077 - precision: 0.8706 - recall: 0.9644\n",
      "Epoch 31: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "12/12 [==============================] - 3s 224ms/step - loss: 0.2763 - dice_coef: 0.7237 - jaccard_distance: 0.6077 - precision: 0.8706 - recall: 0.9644 - val_loss: 0.1753 - val_dice_coef: 0.8247 - val_jaccard_distance: 0.7055 - val_precision: 0.9403 - val_recall: 0.9498 - lr: 2.5000e-04\n",
      "Epoch 32/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1526 - dice_coef: 0.8474 - jaccard_distance: 0.7527 - precision: 0.9569 - recall: 0.9237\n",
      "Epoch 32: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 272ms/step - loss: 0.1526 - dice_coef: 0.8474 - jaccard_distance: 0.7527 - precision: 0.9569 - recall: 0.9237 - val_loss: 0.2069 - val_dice_coef: 0.7931 - val_jaccard_distance: 0.6634 - val_precision: 0.9494 - val_recall: 0.8730 - lr: 1.2500e-04\n",
      "Epoch 33/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2563 - dice_coef: 0.7437 - jaccard_distance: 0.6219 - precision: 0.8669 - recall: 0.9909\n",
      "Epoch 33: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 257ms/step - loss: 0.2563 - dice_coef: 0.7437 - jaccard_distance: 0.6219 - precision: 0.8669 - recall: 0.9909 - val_loss: 0.2676 - val_dice_coef: 0.7324 - val_jaccard_distance: 0.5854 - val_precision: 0.9387 - val_recall: 0.7582 - lr: 1.2500e-04\n",
      "Epoch 34/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2459 - dice_coef: 0.7541 - jaccard_distance: 0.6378 - precision: 0.9250 - recall: 0.9163\n",
      "Epoch 34: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "12/12 [==============================] - 3s 241ms/step - loss: 0.2459 - dice_coef: 0.7541 - jaccard_distance: 0.6378 - precision: 0.9250 - recall: 0.9163 - val_loss: 0.3308 - val_dice_coef: 0.6692 - val_jaccard_distance: 0.5107 - val_precision: 0.9211 - val_recall: 0.6479 - lr: 1.2500e-04\n",
      "Epoch 35/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2702 - dice_coef: 0.7298 - jaccard_distance: 0.6004 - precision: 0.8477 - recall: 0.9580\n",
      "Epoch 35: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 246ms/step - loss: 0.2702 - dice_coef: 0.7298 - jaccard_distance: 0.6004 - precision: 0.8477 - recall: 0.9580 - val_loss: 0.3700 - val_dice_coef: 0.6300 - val_jaccard_distance: 0.4681 - val_precision: 0.9204 - val_recall: 0.5854 - lr: 6.2500e-05\n",
      "Epoch 36/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1372 - dice_coef: 0.8628 - jaccard_distance: 0.7777 - precision: 0.9509 - recall: 0.9644\n",
      "Epoch 36: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 0.1372 - dice_coef: 0.8628 - jaccard_distance: 0.7777 - precision: 0.9509 - recall: 0.9644 - val_loss: 0.4281 - val_dice_coef: 0.5719 - val_jaccard_distance: 0.4081 - val_precision: 0.9218 - val_recall: 0.4929 - lr: 6.2500e-05\n",
      "Epoch 37/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2005 - dice_coef: 0.7995 - jaccard_distance: 0.6900 - precision: 0.8935 - recall: 0.9819\n",
      "Epoch 37: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 0.2005 - dice_coef: 0.7995 - jaccard_distance: 0.6900 - precision: 0.8935 - recall: 0.9819 - val_loss: 0.4438 - val_dice_coef: 0.5562 - val_jaccard_distance: 0.3925 - val_precision: 0.9229 - val_recall: 0.4692 - lr: 6.2500e-05\n",
      "Epoch 38/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2232 - dice_coef: 0.7768 - jaccard_distance: 0.6581 - precision: 0.8967 - recall: 0.9779\n",
      "Epoch 38: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 248ms/step - loss: 0.2232 - dice_coef: 0.7768 - jaccard_distance: 0.6581 - precision: 0.8967 - recall: 0.9779 - val_loss: 0.4212 - val_dice_coef: 0.5788 - val_jaccard_distance: 0.4146 - val_precision: 0.9234 - val_recall: 0.5023 - lr: 3.1250e-05\n",
      "Epoch 39/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1877 - dice_coef: 0.8123 - jaccard_distance: 0.7028 - precision: 0.9293 - recall: 0.9812\n",
      "Epoch 39: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 237ms/step - loss: 0.1877 - dice_coef: 0.8123 - jaccard_distance: 0.7028 - precision: 0.9293 - recall: 0.9812 - val_loss: 0.4046 - val_dice_coef: 0.5954 - val_jaccard_distance: 0.4311 - val_precision: 0.9224 - val_recall: 0.5264 - lr: 3.1250e-05\n",
      "Epoch 40/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1636 - dice_coef: 0.8364 - jaccard_distance: 0.7366 - precision: 0.9281 - recall: 0.9879\n",
      "Epoch 40: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 0.1636 - dice_coef: 0.8364 - jaccard_distance: 0.7366 - precision: 0.9281 - recall: 0.9879 - val_loss: 0.3771 - val_dice_coef: 0.6229 - val_jaccard_distance: 0.4598 - val_precision: 0.9253 - val_recall: 0.5675 - lr: 3.1250e-05\n",
      "Epoch 41/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1596 - dice_coef: 0.8404 - jaccard_distance: 0.7349 - precision: 0.9430 - recall: 0.9547\n",
      "Epoch 41: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 0.1596 - dice_coef: 0.8404 - jaccard_distance: 0.7349 - precision: 0.9430 - recall: 0.9547 - val_loss: 0.3734 - val_dice_coef: 0.6266 - val_jaccard_distance: 0.4637 - val_precision: 0.9272 - val_recall: 0.5715 - lr: 1.5625e-05\n",
      "Epoch 42/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1974 - dice_coef: 0.8026 - jaccard_distance: 0.7088 - precision: 0.9220 - recall: 0.9794\n",
      "Epoch 42: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 258ms/step - loss: 0.1974 - dice_coef: 0.8026 - jaccard_distance: 0.7088 - precision: 0.9220 - recall: 0.9794 - val_loss: 0.3671 - val_dice_coef: 0.6329 - val_jaccard_distance: 0.4703 - val_precision: 0.9272 - val_recall: 0.5792 - lr: 1.5625e-05\n",
      "Epoch 43/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1979 - dice_coef: 0.8021 - jaccard_distance: 0.6939 - precision: 0.9132 - recall: 0.9886\n",
      "Epoch 43: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "12/12 [==============================] - 3s 283ms/step - loss: 0.1979 - dice_coef: 0.8021 - jaccard_distance: 0.6939 - precision: 0.9132 - recall: 0.9886 - val_loss: 0.3544 - val_dice_coef: 0.6456 - val_jaccard_distance: 0.4839 - val_precision: 0.9261 - val_recall: 0.5994 - lr: 1.5625e-05\n",
      "Epoch 44/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2248 - dice_coef: 0.7752 - jaccard_distance: 0.6581 - precision: 0.9057 - recall: 0.9888\n",
      "Epoch 44: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 274ms/step - loss: 0.2248 - dice_coef: 0.7752 - jaccard_distance: 0.6581 - precision: 0.9057 - recall: 0.9888 - val_loss: 0.3453 - val_dice_coef: 0.6547 - val_jaccard_distance: 0.4937 - val_precision: 0.9256 - val_recall: 0.6150 - lr: 7.8125e-06\n",
      "Epoch 45/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1440 - dice_coef: 0.8560 - jaccard_distance: 0.7666 - precision: 0.9360 - recall: 0.9712\n",
      "Epoch 45: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 269ms/step - loss: 0.1440 - dice_coef: 0.8560 - jaccard_distance: 0.7666 - precision: 0.9360 - recall: 0.9712 - val_loss: 0.3273 - val_dice_coef: 0.6727 - val_jaccard_distance: 0.5137 - val_precision: 0.9285 - val_recall: 0.6406 - lr: 7.8125e-06\n",
      "Epoch 46/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2475 - dice_coef: 0.7525 - jaccard_distance: 0.6354 - precision: 0.8814 - recall: 0.9766\n",
      "Epoch 46: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 0.2475 - dice_coef: 0.7525 - jaccard_distance: 0.6354 - precision: 0.8814 - recall: 0.9766 - val_loss: 0.3134 - val_dice_coef: 0.6866 - val_jaccard_distance: 0.5291 - val_precision: 0.9274 - val_recall: 0.6650 - lr: 7.8125e-06\n",
      "Epoch 47/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2407 - dice_coef: 0.7593 - jaccard_distance: 0.6332 - precision: 0.8908 - recall: 0.9736\n",
      "Epoch 47: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 0.2407 - dice_coef: 0.7593 - jaccard_distance: 0.6332 - precision: 0.8908 - recall: 0.9736 - val_loss: 0.3040 - val_dice_coef: 0.6960 - val_jaccard_distance: 0.5397 - val_precision: 0.9265 - val_recall: 0.6836 - lr: 3.9063e-06\n",
      "Epoch 48/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2979 - dice_coef: 0.7021 - jaccard_distance: 0.5800 - precision: 0.8212 - recall: 0.9919\n",
      "Epoch 48: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 0.2979 - dice_coef: 0.7021 - jaccard_distance: 0.5800 - precision: 0.8212 - recall: 0.9919 - val_loss: 0.3001 - val_dice_coef: 0.6999 - val_jaccard_distance: 0.5442 - val_precision: 0.9238 - val_recall: 0.6941 - lr: 3.9063e-06\n",
      "Epoch 49/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2353 - dice_coef: 0.7647 - jaccard_distance: 0.6470 - precision: 0.8958 - recall: 0.9238\n",
      "Epoch 49: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "12/12 [==============================] - 3s 271ms/step - loss: 0.2353 - dice_coef: 0.7647 - jaccard_distance: 0.6470 - precision: 0.8958 - recall: 0.9238 - val_loss: 0.2948 - val_dice_coef: 0.7052 - val_jaccard_distance: 0.5503 - val_precision: 0.9230 - val_recall: 0.7033 - lr: 3.9063e-06\n",
      "Epoch 50/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1719 - dice_coef: 0.8281 - jaccard_distance: 0.7326 - precision: 0.9514 - recall: 0.9795\n",
      "Epoch 50: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 269ms/step - loss: 0.1719 - dice_coef: 0.8281 - jaccard_distance: 0.7326 - precision: 0.9514 - recall: 0.9795 - val_loss: 0.2920 - val_dice_coef: 0.7080 - val_jaccard_distance: 0.5535 - val_precision: 0.9239 - val_recall: 0.7069 - lr: 1.9531e-06\n",
      "Epoch 51/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1438 - dice_coef: 0.8562 - jaccard_distance: 0.7536 - precision: 0.9521 - recall: 0.9894\n",
      "Epoch 51: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 0.1438 - dice_coef: 0.8562 - jaccard_distance: 0.7536 - precision: 0.9521 - recall: 0.9894 - val_loss: 0.2870 - val_dice_coef: 0.7130 - val_jaccard_distance: 0.5594 - val_precision: 0.9244 - val_recall: 0.7156 - lr: 1.9531e-06\n",
      "Epoch 52/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2749 - dice_coef: 0.7251 - jaccard_distance: 0.6027 - precision: 0.8707 - recall: 0.9941\n",
      "Epoch 52: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "12/12 [==============================] - 3s 264ms/step - loss: 0.2749 - dice_coef: 0.7251 - jaccard_distance: 0.6027 - precision: 0.8707 - recall: 0.9941 - val_loss: 0.2839 - val_dice_coef: 0.7161 - val_jaccard_distance: 0.5629 - val_precision: 0.9227 - val_recall: 0.7247 - lr: 1.9531e-06\n",
      "Epoch 53/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2520 - dice_coef: 0.7480 - jaccard_distance: 0.6249 - precision: 0.8786 - recall: 0.9293\n",
      "Epoch 53: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 224ms/step - loss: 0.2520 - dice_coef: 0.7480 - jaccard_distance: 0.6249 - precision: 0.8786 - recall: 0.9293 - val_loss: 0.2789 - val_dice_coef: 0.7211 - val_jaccard_distance: 0.5689 - val_precision: 0.9220 - val_recall: 0.7357 - lr: 9.7656e-07\n",
      "Epoch 54/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2212 - dice_coef: 0.7788 - jaccard_distance: 0.6651 - precision: 0.8977 - recall: 0.9850\n",
      "Epoch 54: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 0.2212 - dice_coef: 0.7788 - jaccard_distance: 0.6651 - precision: 0.8977 - recall: 0.9850 - val_loss: 0.2776 - val_dice_coef: 0.7224 - val_jaccard_distance: 0.5704 - val_precision: 0.9215 - val_recall: 0.7387 - lr: 9.7656e-07\n",
      "Epoch 55/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1897 - dice_coef: 0.8103 - jaccard_distance: 0.7076 - precision: 0.9336 - recall: 0.9359\n",
      "Epoch 55: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "12/12 [==============================] - 3s 238ms/step - loss: 0.1897 - dice_coef: 0.8103 - jaccard_distance: 0.7076 - precision: 0.9336 - recall: 0.9359 - val_loss: 0.2702 - val_dice_coef: 0.7298 - val_jaccard_distance: 0.5794 - val_precision: 0.9234 - val_recall: 0.7499 - lr: 9.7656e-07\n",
      "Epoch 56/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1488 - dice_coef: 0.8512 - jaccard_distance: 0.7642 - precision: 0.9485 - recall: 0.9719\n",
      "Epoch 56: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 245ms/step - loss: 0.1488 - dice_coef: 0.8512 - jaccard_distance: 0.7642 - precision: 0.9485 - recall: 0.9719 - val_loss: 0.2712 - val_dice_coef: 0.7288 - val_jaccard_distance: 0.5783 - val_precision: 0.9251 - val_recall: 0.7446 - lr: 4.8828e-07\n",
      "Epoch 57/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1459 - dice_coef: 0.8541 - jaccard_distance: 0.7509 - precision: 0.9546 - recall: 0.9899\n",
      "Epoch 57: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 247ms/step - loss: 0.1459 - dice_coef: 0.8541 - jaccard_distance: 0.7509 - precision: 0.9546 - recall: 0.9899 - val_loss: 0.2735 - val_dice_coef: 0.7265 - val_jaccard_distance: 0.5755 - val_precision: 0.9245 - val_recall: 0.7406 - lr: 4.8828e-07\n",
      "Epoch 58/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2771 - dice_coef: 0.7229 - jaccard_distance: 0.6055 - precision: 0.8524 - recall: 0.9676\n",
      "Epoch 58: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "12/12 [==============================] - 3s 232ms/step - loss: 0.2771 - dice_coef: 0.7229 - jaccard_distance: 0.6055 - precision: 0.8524 - recall: 0.9676 - val_loss: 0.2755 - val_dice_coef: 0.7245 - val_jaccard_distance: 0.5731 - val_precision: 0.9242 - val_recall: 0.7367 - lr: 4.8828e-07\n",
      "Epoch 59/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2106 - dice_coef: 0.7894 - jaccard_distance: 0.6927 - precision: 0.9330 - recall: 0.9873\n",
      "Epoch 59: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 241ms/step - loss: 0.2106 - dice_coef: 0.7894 - jaccard_distance: 0.6927 - precision: 0.9330 - recall: 0.9873 - val_loss: 0.2737 - val_dice_coef: 0.7263 - val_jaccard_distance: 0.5752 - val_precision: 0.9233 - val_recall: 0.7403 - lr: 2.4414e-07\n",
      "Epoch 60/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1956 - dice_coef: 0.8044 - jaccard_distance: 0.7001 - precision: 0.8892 - recall: 0.9868\n",
      "Epoch 60: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 0.1956 - dice_coef: 0.8044 - jaccard_distance: 0.7001 - precision: 0.8892 - recall: 0.9868 - val_loss: 0.2777 - val_dice_coef: 0.7223 - val_jaccard_distance: 0.5704 - val_precision: 0.9240 - val_recall: 0.7318 - lr: 2.4414e-07\n",
      "Epoch 61/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2838 - dice_coef: 0.7162 - jaccard_distance: 0.5943 - precision: 0.8522 - recall: 0.9915\n",
      "Epoch 61: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "12/12 [==============================] - 3s 223ms/step - loss: 0.2838 - dice_coef: 0.7162 - jaccard_distance: 0.5943 - precision: 0.8522 - recall: 0.9915 - val_loss: 0.2800 - val_dice_coef: 0.7200 - val_jaccard_distance: 0.5676 - val_precision: 0.9209 - val_recall: 0.7316 - lr: 2.4414e-07\n",
      "Epoch 62/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2683 - dice_coef: 0.7317 - jaccard_distance: 0.6035 - precision: 0.8636 - recall: 0.9886\n",
      "Epoch 62: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 229ms/step - loss: 0.2683 - dice_coef: 0.7317 - jaccard_distance: 0.6035 - precision: 0.8636 - recall: 0.9886 - val_loss: 0.2847 - val_dice_coef: 0.7153 - val_jaccard_distance: 0.5621 - val_precision: 0.9196 - val_recall: 0.7264 - lr: 1.2207e-07\n",
      "Epoch 63/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1887 - dice_coef: 0.8113 - jaccard_distance: 0.7056 - precision: 0.9278 - recall: 0.9363\n",
      "Epoch 63: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 226ms/step - loss: 0.1887 - dice_coef: 0.8113 - jaccard_distance: 0.7056 - precision: 0.9278 - recall: 0.9363 - val_loss: 0.2805 - val_dice_coef: 0.7195 - val_jaccard_distance: 0.5670 - val_precision: 0.9208 - val_recall: 0.7318 - lr: 1.2207e-07\n",
      "Epoch 64/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2055 - dice_coef: 0.7945 - jaccard_distance: 0.6718 - precision: 0.9168 - recall: 0.9281\n",
      "Epoch 64: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "12/12 [==============================] - 3s 224ms/step - loss: 0.2055 - dice_coef: 0.7945 - jaccard_distance: 0.6718 - precision: 0.9168 - recall: 0.9281 - val_loss: 0.2797 - val_dice_coef: 0.7203 - val_jaccard_distance: 0.5680 - val_precision: 0.9202 - val_recall: 0.7343 - lr: 1.2207e-07\n",
      "Epoch 65/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2518 - dice_coef: 0.7482 - jaccard_distance: 0.6390 - precision: 0.8832 - recall: 0.9863\n",
      "Epoch 65: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 223ms/step - loss: 0.2518 - dice_coef: 0.7482 - jaccard_distance: 0.6390 - precision: 0.8832 - recall: 0.9863 - val_loss: 0.2770 - val_dice_coef: 0.7230 - val_jaccard_distance: 0.5712 - val_precision: 0.9192 - val_recall: 0.7402 - lr: 6.1035e-08\n",
      "Epoch 66/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1503 - dice_coef: 0.8497 - jaccard_distance: 0.7539 - precision: 0.9536 - recall: 0.9844\n",
      "Epoch 66: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 227ms/step - loss: 0.1503 - dice_coef: 0.8497 - jaccard_distance: 0.7539 - precision: 0.9536 - recall: 0.9844 - val_loss: 0.2786 - val_dice_coef: 0.7214 - val_jaccard_distance: 0.5692 - val_precision: 0.9197 - val_recall: 0.7352 - lr: 6.1035e-08\n",
      "Epoch 67/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1869 - dice_coef: 0.8131 - jaccard_distance: 0.7105 - precision: 0.8910 - recall: 0.9811\n",
      "Epoch 67: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "12/12 [==============================] - 3s 232ms/step - loss: 0.1869 - dice_coef: 0.8131 - jaccard_distance: 0.7105 - precision: 0.8910 - recall: 0.9811 - val_loss: 0.2757 - val_dice_coef: 0.7243 - val_jaccard_distance: 0.5728 - val_precision: 0.9212 - val_recall: 0.7377 - lr: 6.1035e-08\n",
      "Epoch 68/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2324 - dice_coef: 0.7676 - jaccard_distance: 0.6510 - precision: 0.9079 - recall: 0.9786\n",
      "Epoch 68: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 242ms/step - loss: 0.2324 - dice_coef: 0.7676 - jaccard_distance: 0.6510 - precision: 0.9079 - recall: 0.9786 - val_loss: 0.2761 - val_dice_coef: 0.7239 - val_jaccard_distance: 0.5722 - val_precision: 0.9205 - val_recall: 0.7387 - lr: 3.0518e-08\n",
      "Epoch 69/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2270 - dice_coef: 0.7730 - jaccard_distance: 0.6594 - precision: 0.8720 - recall: 0.9635\n",
      "Epoch 69: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 226ms/step - loss: 0.2270 - dice_coef: 0.7730 - jaccard_distance: 0.6594 - precision: 0.8720 - recall: 0.9635 - val_loss: 0.2773 - val_dice_coef: 0.7227 - val_jaccard_distance: 0.5708 - val_precision: 0.9212 - val_recall: 0.7347 - lr: 3.0518e-08\n",
      "Epoch 70/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2338 - dice_coef: 0.7662 - jaccard_distance: 0.6568 - precision: 0.9036 - recall: 0.9885\n",
      "Epoch 70: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "12/12 [==============================] - 3s 225ms/step - loss: 0.2338 - dice_coef: 0.7662 - jaccard_distance: 0.6568 - precision: 0.9036 - recall: 0.9885 - val_loss: 0.2791 - val_dice_coef: 0.7209 - val_jaccard_distance: 0.5686 - val_precision: 0.9210 - val_recall: 0.7322 - lr: 3.0518e-08\n",
      "Epoch 71/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1662 - dice_coef: 0.8338 - jaccard_distance: 0.7360 - precision: 0.9502 - recall: 0.9686\n",
      "Epoch 71: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 245ms/step - loss: 0.1662 - dice_coef: 0.8338 - jaccard_distance: 0.7360 - precision: 0.9502 - recall: 0.9686 - val_loss: 0.2783 - val_dice_coef: 0.7217 - val_jaccard_distance: 0.5696 - val_precision: 0.9222 - val_recall: 0.7317 - lr: 1.5259e-08\n",
      "Epoch 72/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1779 - dice_coef: 0.8221 - jaccard_distance: 0.7271 - precision: 0.9115 - recall: 0.9865\n",
      "Epoch 72: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 224ms/step - loss: 0.1779 - dice_coef: 0.8221 - jaccard_distance: 0.7271 - precision: 0.9115 - recall: 0.9865 - val_loss: 0.2798 - val_dice_coef: 0.7202 - val_jaccard_distance: 0.5678 - val_precision: 0.9223 - val_recall: 0.7271 - lr: 1.5259e-08\n",
      "Epoch 73/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3054 - dice_coef: 0.6946 - jaccard_distance: 0.5646 - precision: 0.8255 - recall: 0.9919\n",
      "Epoch 73: val_loss did not improve from 0.17220\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "12/12 [==============================] - 3s 269ms/step - loss: 0.3054 - dice_coef: 0.6946 - jaccard_distance: 0.5646 - precision: 0.8255 - recall: 0.9919 - val_loss: 0.2798 - val_dice_coef: 0.7202 - val_jaccard_distance: 0.5678 - val_precision: 0.9202 - val_recall: 0.7319 - lr: 1.5259e-08\n",
      "Epoch 74/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1922 - dice_coef: 0.8078 - jaccard_distance: 0.6965 - precision: 0.9133 - recall: 0.9692\n",
      "Epoch 74: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 241ms/step - loss: 0.1922 - dice_coef: 0.8078 - jaccard_distance: 0.6965 - precision: 0.9133 - recall: 0.9692 - val_loss: 0.2788 - val_dice_coef: 0.7212 - val_jaccard_distance: 0.5689 - val_precision: 0.9208 - val_recall: 0.7329 - lr: 7.6294e-09\n",
      "Epoch 75/75\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1689 - dice_coef: 0.8311 - jaccard_distance: 0.7287 - precision: 0.9313 - recall: 0.9801\n",
      "Epoch 75: val_loss did not improve from 0.17220\n",
      "12/12 [==============================] - 3s 253ms/step - loss: 0.1689 - dice_coef: 0.8311 - jaccard_distance: 0.7287 - precision: 0.9313 - recall: 0.9801 - val_loss: 0.2812 - val_dice_coef: 0.7188 - val_jaccard_distance: 0.5660 - val_precision: 0.9215 - val_recall: 0.7271 - lr: 7.6294e-09\n"
     ]
    }
   ],
   "source": [
    "current_datetime = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "path_model = os.path.join(cfg[\"path_out\"], \"train\", current_datetime)\n",
    "pathlib.Path(path_model).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "steps_per_epoch = math.ceil(len(images_folder) / cfg[\"batch_size\"])\n",
    "reduce_learning_rate = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=3, verbose=1)\n",
    "filename_model = os.path.join(path_model, \"unet.h5\")\n",
    "checkpointer = tensorflow.keras.callbacks.ModelCheckpoint(filename_model, verbose=1, save_best_only=True)\n",
    "strategy = tensorflow.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = unet_model(cfg)\n",
    "    adam_opt = tensorflow.keras.optimizers.Adam(learning_rate=cfg[\"learning_rate\"])\n",
    "    model.compile(optimizer=adam_opt, loss=get_loss_function(cfg[\"loss_function\"]), metrics=[dice_coef, jaccard_distance, tensorflow.keras.metrics.Precision(), tensorflow.keras.metrics.Recall()])\n",
    "\n",
    "tensorflow.keras.backend.clear_session()\n",
    "start_time = time.time()\n",
    "fit = model.fit(train_data, steps_per_epoch=steps_per_epoch, epochs=cfg[\"epochs\"], validation_data=val_data, callbacks=[checkpointer, reduce_learning_rate])\n",
    "end_time = time.time() - start_time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                 0\nbatch_size                                                       4\nepochs                                                          75\nlearning_rate                                                0,001\nloss_function                                                 dice\nimages             dataset/IMAGEM_ORIGINAL/CONVERTIDAS/RGB/512/OUT\nmasks                                  dataset/MASK/BITMAP/512/OUT\nlen_images                                                     375\nlen_masks                                                      375\nchannel                                                          3\nimage_size                                                     512\nfold                                                             5\ntest_size                                                      0,2\nval_size                                                      0,05\nrandom_state                                                  1234\npath_dataset                                               dataset\npath_out                                                       out\ndata_augmentation                                            False\nfilename_script                                  train_no_data_aug\ntime                                                      00:03:53",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>batch_size</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>epochs</th>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>learning_rate</th>\n      <td>0,001</td>\n    </tr>\n    <tr>\n      <th>loss_function</th>\n      <td>dice</td>\n    </tr>\n    <tr>\n      <th>images</th>\n      <td>dataset/IMAGEM_ORIGINAL/CONVERTIDAS/RGB/512/OUT</td>\n    </tr>\n    <tr>\n      <th>masks</th>\n      <td>dataset/MASK/BITMAP/512/OUT</td>\n    </tr>\n    <tr>\n      <th>len_images</th>\n      <td>375</td>\n    </tr>\n    <tr>\n      <th>len_masks</th>\n      <td>375</td>\n    </tr>\n    <tr>\n      <th>channel</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>image_size</th>\n      <td>512</td>\n    </tr>\n    <tr>\n      <th>fold</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>test_size</th>\n      <td>0,2</td>\n    </tr>\n    <tr>\n      <th>val_size</th>\n      <td>0,05</td>\n    </tr>\n    <tr>\n      <th>random_state</th>\n      <td>1234</td>\n    </tr>\n    <tr>\n      <th>path_dataset</th>\n      <td>dataset</td>\n    </tr>\n    <tr>\n      <th>path_out</th>\n      <td>out</td>\n    </tr>\n    <tr>\n      <th>data_augmentation</th>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>filename_script</th>\n      <td>train_no_data_aug</td>\n    </tr>\n    <tr>\n      <th>time</th>\n      <td>00:03:53</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"batch_size\", \"epochs\", \"learning_rate\", \"loss_function\", \"images\", \"masks\", \"len_images\", \"len_masks\", \"channel\", \"image_size\", \"fold\", \"test_size\", \"val_size\", \"random_state\", \"path_dataset\", \"path_out\", \"data_augmentation\", \"filename_script\", \"time\"]\n",
    "data = [cfg[\"batch_size\"], cfg[\"epochs\"], cfg[\"learning_rate\"], cfg[\"loss_function\"], images_folder, masks_folder, len(list_images), len(list_masks), cfg[\"channel\"], cfg[\"image_size\"], cfg[\"fold\"], cfg[\"test_size\"], cfg[\"val_size\"], cfg[\"random_state\"], cfg[\"path_dataset\"], cfg[\"path_out\"], cfg[\"data_augmentation\"], ipynbname.name(), time.strftime(\"%H:%M:%S\", time.gmtime(end_time))]\n",
    "\n",
    "dataframe_cfg = pandas.DataFrame(data, columns)\n",
    "dataframe_cfg = dataframe_cfg.applymap(lambda x: str(x).replace(\".\", \",\") if isinstance(x,float) else x)\n",
    "dataframe_cfg.to_csv(os.path.join(path_model, \"cfg.csv\"), decimal=\",\", sep=\";\", na_rep=\" \", header=False, quoting=csv.QUOTE_ALL)\n",
    "dataframe_cfg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}